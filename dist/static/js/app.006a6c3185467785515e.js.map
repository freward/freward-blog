{"version":3,"sources":["webpack:///./src/components/vi/ViEntry.vue?65cf","webpack:///./src/components/vi/ViEntry.vue","webpack:///./src/pages/en/theoricalRL/En1DDPG.md?949a","webpack:///./src/pages/en/theoricalRL/En1DDPG.md?0b5e","webpack:///src/components/vi/ViComponents.vue","webpack:///./src/components/vi/ViComponents.vue?7811","webpack:///./src/components/vi/ViComponents.vue","webpack:///./src/pages/fr/FrIntroduction.md?7b66","webpack:///./src/pages/fr/FrIntroduction.md?93c6","webpack:///./src/pages/en/EnIntroduction.md","webpack:///./src/components/vi/ViSideMenu.vue?0ff7","webpack:///./src/components/vi/ViSideMenu.vue","webpack:///./src/pages/vi/ViIntroduction.md","webpack:///./src/components/en/EnSideMenu.vue?2be0","webpack:///./src/components/en/EnSideMenu.vue","webpack:///src/components/fr/FrIndex.vue","webpack:///./src/components/fr/FrIndex.vue?660b","webpack:///./src/components/fr/FrIndex.vue","webpack:///./src/pages/fr/FrIntroduction.md","webpack:///src/components/en/EnIndex.vue","webpack:///./src/components/en/EnIndex.vue?0f87","webpack:///./src/components/en/EnIndex.vue","webpack:///./src/pages/en/EnIntroduction.md?b521","webpack:///./src/pages/en/EnIntroduction.md?dbf3","webpack:///./src/pages/fr/theoricalRL/Fr1DDPG.md?9ea4","webpack:///./src/pages/fr/theoricalRL/Fr1DDPG.md?fe93","webpack:///src/components/fr/FrComponents.vue","webpack:///./src/components/fr/FrComponents.vue?6098","webpack:///./src/components/fr/FrComponents.vue","webpack:///./src/App.vue?b131","webpack:///./src/App.vue","webpack:///src/App.vue","webpack:///./src/router/router.en.js","webpack:///./src/router/router.vi.js","webpack:///./src/router/router.fr.js","webpack:///./src/router/index.js","webpack:///./src/main.js","webpack:///./src/pages/en/theoricalRL/En1DDPG.md","webpack:///src/components/en/EnComponents.vue","webpack:///./src/components/en/EnComponents.vue?9c83","webpack:///./src/components/en/EnComponents.vue","webpack:///./src/pages/vi/theoricalRL/Vi1DDPG.md","webpack:///./src/pages/fr/theoricalRL/Fr1DDPG.md","webpack:///src/components/vi/ViIndex.vue","webpack:///./src/components/vi/ViIndex.vue?3896","webpack:///./src/components/vi/ViIndex.vue","webpack:///./src/components/fr/FrSideMenu.vue?5267","webpack:///./src/components/fr/FrSideMenu.vue","webpack:///./src/pages/vi/ViIntroduction.md?0a1a","webpack:///./src/pages/vi/ViIntroduction.md?26ba","webpack:///./src/components/en/EnEntry.vue?c128","webpack:///./src/components/en/EnEntry.vue","webpack:///./src/components/fr/FrEntry.vue?b770","webpack:///./src/components/fr/FrEntry.vue","webpack:///./src/pages/vi/theoricalRL/Vi1DDPG.md?c060","webpack:///./src/pages/vi/theoricalRL/Vi1DDPG.md?a963"],"names":["ViEntry","render","_h","this","$createElement","_self","_c","staticRenderFns","Component","__webpack_require__","normalizeComponent","__webpack_exports__","En1DDPG","_vm","_v","_m","staticClass","staticStyle","width","font-size","text-align","attrs","src","align","href","padding-bottom","alt","ViComponents","components","SideMenu","vi_ViComponents","id","to","data-target","target","ssrContext","FrIntroduction","module","exports","ViSideMenu","exact","EnSideMenu","FrIndex","fr_FrIndex","EnIndex","en_EnIndex","EnIntroduction","Fr1DDPG","FrComponents","fr_FrComponents","selectortype_template_index_0_src_App","src_App","name","router_en","path","component","require","default","children","router_vi","router_fr","Vue","use","Router","router","concat","EnRouter","ViRouter","FrRouter","src_router","routes","VueMathjax","config","productionTip","mode","el","App","template","EnComponents","en_EnComponents","ViIndex","vi_ViIndex","FrSideMenu","ViIntroduction","EnEntry","FrEntry","Vi1DDPG"],"mappings":"uGAAA,IAGeA,GADEC,OAFjB,WAA0B,IAAaC,EAAbC,KAAaC,eAAkD,OAA/DD,KAAuCE,MAAAC,IAAAJ,GAAwB,gBAExEK,oBCWjBC,EAbyBC,EAAQ,OAajCC,CAXA,KAaEV,GATF,EAEA,KAEA,KAEA,MAUeW,EAAA,QAAAH,EAAiB,qHCtBhC,IAGeI,GADEX,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,WAAAA,EAAA,KAAAA,EAAA,mBAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6FAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,qDAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,uMAAmgBD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,yBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4EAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,kIAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,qJAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sTAA+jCD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4GAAqGD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,oOAAsTD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mLAAqOD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,8KAAgOD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,+DAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wVAAoeD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,+WAAiaD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mUAA8VD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,+JAA0LD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6BAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4EAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gHAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,8BAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6BAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sCAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gLAA+uBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,iHAA+GD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,0OAAkSD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,8DAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gKAA8QD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,0oBAA2qBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,6yBAAw0BD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,6iBAAwkBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wQAAmSD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,mBAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iCAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,ynBAAq0BD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,gCAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,yIAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,oDAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,uHAAAR,EAAA,MAAAO,EAAAC,GAAA,0CAAAR,EAAA,MAAAO,EAAAC,GAAA,2DAAAR,EAAA,MAAAO,EAAAC,GAAA,4CAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sGAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4FAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mQAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gFAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wBAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,mEAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wtBAAy2DD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,saAAijCD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mIAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sCAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,qBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gFAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gBAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,OAEl1WR,iBADjB,WAAoC,IAAAM,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,oEAAAR,EAAA,QAAqGU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,SAAAR,EAAA,QAA2CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,4RAAAR,EAAA,QAA8TU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,8BAAAR,EAAA,QAAgEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,mFAAAR,EAAA,QAAqHU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,oBAAAR,EAAA,QAAsDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,QAA8B,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,iTAAAR,EAAA,QAAkVU,YAAA,mBAAjZb,KAA8aW,GAAA,OAA9aX,KAA8aW,GAAA,OAAAR,EAAA,QAAyCU,YAAA,mBAAvdb,KAAofW,GAAA,OAApfX,KAAofW,GAAA,8CAAoE,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,iFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,WAAAD,EAAAC,GAAA,+EAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,yDAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,mFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,WAAAD,EAAAC,GAAA,8DAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,aAAAD,EAAAC,GAAA,yFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,yBAAAD,EAAAC,GAAA,4DAA25B,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYe,OAAOC,IAAA,kCAAAC,MAAA,YAAlLpB,KAA4OW,GAAA,KAAAR,EAAA,OAA5OH,KAA4OW,GAAA,qEAAmG,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,8DAAAR,EAAA,KAA4Fe,OAAOG,KAAA,iEAAlKrB,KAAwOW,GAAA,8BAAxOX,KAAwOW,GAAA,QAAqD,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYW,aAAaQ,iBAAA,SAAyBJ,OAAQC,IAAA,kCAAAI,IAAA,8BAAzNvB,KAAmSW,GAAA,KAAAR,EAAA,OAAnSH,KAAmSW,GAAA,yDAAuF,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,UAAAD,EAAAC,GAAA,wFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,sCAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,WAAAD,EAAAC,GAAA,2JAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,uOAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,kPAAi4BD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,+EAA6R,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYe,OAAOC,IAAA,0DAAAC,MAAA,YAAlLpB,KAAoQW,GAAA,KAAAR,EAAA,OAApQH,KAAoQW,GAAA,gCAA8D,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,+HAAAR,EAAA,QAAgKU,YAAA,mBAA/Nb,KAA4PW,GAAA,OAA5PX,KAA4PW,GAAA,6GAAAR,EAAA,QAA+IU,YAAA,mBAA3Yb,KAAwaW,GAAA,OAAxaX,KAAwaW,GAAA,oUAA0V,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAA,EAAA,UAA/DH,KAA+DW,GAAA,2EAA6G,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,0NAAAR,EAAA,MAA/DH,KAA+DW,GAAA,4HAA2X,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,yEAAAR,EAAA,MAA/DH,KAA+DW,GAAA,qGAAmN,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,kcAA+cR,EAAA,UAA9gBH,KAA8gBW,GAAA,UAA9gBX,KAA8gBW,GAAA,2SAAwV,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,iOAA8KR,EAAA,QAAoFU,YAAA,mBAAjUb,KAA8VW,GAAA,OAA9VX,KAA8VW,GAAA,SAAAR,EAAA,QAA2CU,YAAA,mBAAzYb,KAAsaW,GAAA,OAAtaX,KAAsaW,GAAA,sPAA4Q,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,oEAA/DX,KAA+HW,GAAA,KAAAR,EAAA,MAA/HH,KAA+HW,GAAA,0NAA/HX,KAA0YW,GAAA,KAAAR,EAAA,MAA1YH,KAA0YW,GAAA,0EAAoH,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,iNAA4KR,EAAA,KAAmEe,OAAOG,KAAA,iEAArTrB,KAA2XW,GAAA,SAA3XX,KAA2XW,GAAA,yLAAiN,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,4EAAAR,EAAA,MAA/DH,KAA+DW,GAAA,sGAAAR,EAAA,MAA/DH,KAA+DW,GAAA,4NAAgUR,EAAA,MAA/XH,KAA+XW,GAAA,mKAAqSR,EAAA,MAApqBH,KAAoqBW,GAAA,sTAAuV,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,0oBAA+MR,EAAA,MAA9QH,KAA8QW,GAAA,2rBAA2pC,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,oKAAAR,EAAA,MAA/DH,KAA+DW,GAAA,iGAA0S,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,+KAAAR,EAAA,QAAgNU,YAAA,mBAA/Qb,KAA4SW,GAAA,OAA5SX,KAA4SW,GAAA,2BAAAR,EAAA,QAA6DU,YAAA,mBAAzWb,KAAsYW,GAAA,OAAtYX,KAAsYW,GAAA,sQAA4R,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,mNAAAR,EAAA,MAA/DH,KAA+DW,GAAA,sIAA8X,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,uBAAAR,EAAA,MAAAO,EAAAC,GAAA,gFAAAR,EAAA,MAAAO,EAAAC,GAAA,mDAAwMR,EAAA,MAAAO,EAAAC,GAAA,oFAAuGR,EAAA,MAAAO,EAAAC,GAAA,2GAAAR,EAAA,MAAAO,EAAAC,GAAA,mFAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,yJAAAR,EAAA,MAAAO,EAAAC,GAAA,0BAAAR,EAAA,MAAAO,EAAAC,GAAA,sGAAAR,EAAA,MAAAO,EAAAC,GAAA,iDAAAR,EAAA,MAAAO,EAAAC,GAAA,oFAAsvBR,EAAA,MAAAO,EAAAC,GAAA,sGAAAR,EAAA,MAAAO,EAAAC,GAAA,mFAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,gGAAuX,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,ivBAA8vBR,EAAA,MAA7zBH,KAA6zBW,GAAA,2ZAAmb,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYe,OAAOC,IAAA,kCAAAC,MAAA,YAAlLpB,KAA4OW,GAAA,KAAAR,EAAA,OAA5OH,KAA4OW,GAAA,oDAAkF,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,2PAAAR,EAAA,MAA/DH,KAA+DW,GAAA,mCAAmU,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,iGAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,uGAAmQ,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,gGAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,oDAA+M,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,uFAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,iFAAmO,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,gFAA/DX,KAAwJW,GAAA,KAAAR,EAAA,MAAxJH,KAAwJW,GAAA,sFAAwI,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,+cAAAR,EAAA,QAAgfU,YAAA,mBAA/iBb,KAA4kBW,GAAA,OAA5kBX,KAA4kBW,GAAA,sCAAAR,EAAA,QAAwEU,YAAA,mBAAppBb,KAAirBW,GAAA,OAAjrBX,KAAirBW,GAAA,kDAAwE,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,iDAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,8EAA/DX,KAAmOW,GAAA,KAAAR,EAAA,MAAnOH,KAAmOW,GAAA,4GAA8J,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,oKAAAR,EAAA,QAAqMU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,iCAAAR,EAAA,QAAmEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,gNAAAR,EAAA,MAAAO,EAAAC,GAAA,oMAAAR,EAAA,MAAAO,EAAAC,GAAA,iPAAAR,EAAA,QAAusBU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,SAAAR,EAAA,QAA2CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,8NAAoP,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,qDAA/DX,KAA6IW,GAAA,KAAAR,EAAA,MAA7IH,KAA6IW,GAAA,2BAA6D,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,sFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,+EAAkUR,EAAA,QAAwBU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,6BAAAR,EAAA,QAA+DU,YAAA,mBAA6BH,EAAAC,GAAA,SAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iIAAgID,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6EAAAR,EAAA,QAAmKU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,iEAAAR,EAAA,QAAmGU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,uCAAAR,EAAA,QAAmHU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,OAAAR,EAAA,QAAyCU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,UAAgC,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,uCAAAR,EAAA,QAAwEU,YAAA,mBAAvIb,KAAoKW,GAAA,OAApKX,KAAoKW,GAAA,QAAAR,EAAA,QAA0CU,YAAA,mBAA9Mb,KAA2OW,GAAA,OAA3OX,KAA2OW,GAAA,+JAAqL,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,sFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,4EAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iGAA4UR,EAAA,QAA0BU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,6CAAAR,EAAA,QAA+EU,YAAA,mBAA6BH,EAAAC,GAAA,SAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iIAAgID,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kIAA+LD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,2IAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,8CAAuQ,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,sFAAAR,EAAA,QAAiIU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,sHAAAR,EAAA,QAAwJU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,2FAAAR,EAAA,KAA0He,OAAOG,KAAA,sCAA2CX,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,8DAAAR,EAAA,QAA6GU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,cAAAR,EAAA,QAAgDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,qNAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kDAAAR,EAAA,KAAkUe,OAAOG,KAAA,0CAA+CX,EAAAC,GAAA,cAAAD,EAAAC,GAAA,2HAAAR,EAAA,QAAoKU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,8BAAAR,EAAA,QAAgEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,kLAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6JAAAR,EAAA,KAA0Ye,OAAOG,KAAA,sEAA2EX,EAAAC,GAAA,UAAAD,EAAAC,GAAA,8EAAAR,EAAA,KAAgHe,OAAOG,KAAA,qGAA0GX,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,UAA+C,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,8DAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,sEAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,8ECYjwzBN,EAbyBC,EAAQ,OAajCC,CAXA,KAaEE,GATF,EAEA,KAEA,KAEA,MAUeD,EAAA,QAAAH,EAAiB,kGCoEhCmB,GACAC,YAAAC,mBAAA,ICxFeC,GADE7B,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAAA,EAAA,OAA2BU,YAAA,yCAAmDH,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,OAAkCU,YAAA,cAAAK,OAAiCU,GAAA,oBAAuBzB,EAAA,OAAYU,YAAA,iBAA2BV,EAAA,OAAYU,YAAA,0CAAoDV,EAAA,KAAUU,YAAA,gBAA0BH,EAAAC,GAAA,0DAAAD,EAAAC,GAAA,KAAAR,EAAA,OAAyFU,YAAA,6BAAuCV,EAAA,KAAUU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,OAAU1B,EAAA,QAAAO,EAAAC,GAAA,qBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA6DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA8DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,4BAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,OAAAF,EAAAC,GAAA,KAAAR,EAAA,WAAoGU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,yBAAmCV,EAAA,iBAAAO,EAAAC,GAAA,KAAAR,EAAA,OAA4CU,YAAA,0BAAoCV,EAAA,yBAAAO,EAAAC,GAAA,KAAAD,EAAAE,GAAA,MAEhoCR,iBADjB,WAAoC,IAAaL,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,iBAA2BV,EAAA,KAAUU,YAAA,cAAAK,OAAiCG,KAAA,MAAWlB,EAAA,QAAaU,YAAA,SAA9Kb,KAAiMW,GAAA,4BAAAR,EAAA,KAA6CU,YAAA,2BAA9Ob,KAAmRW,GAAA,0BAAnRX,KAAmRW,GAAA,KAAAR,EAAA,OAAyDU,YAAA,uBAAAK,OAA0CY,cAAA,oBAAgC3B,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,aAA+D,WAAc,IAAaJ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,eAAyBV,EAAA,OAAYU,YAAA,gBAA0BV,EAAA,OAAYU,YAAA,qBAA+BV,EAAA,KAAUU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,mCAAwClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,wBAA/Vb,KAA2XW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,uDAA4DlB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,0BAAtkBb,KAAomBW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,yCAA8ClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,iCAA4C,WAAc,IAAAH,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,UAAoBU,YAAA,WAAqBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,8BAAwCV,EAAA,KAAAA,EAAA,UAAAO,EAAAC,GAAA,QAAAR,EAAA,KAA8CU,YAAA,2BAAqCH,EAAAC,GAAA,QAAAD,EAAAC,GAAA,QAAAR,EAAA,KAAwCe,OAAOG,KAAA,sCAAAU,OAAA,YAAgErB,EAAAC,GAAA,aAAAD,EAAAC,GAAA,oCAAAR,EAAA,KAAyEe,OAAOG,KAAA,oDAAyDX,EAAAC,GAAA,SAAAD,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAA,EAAA,KAAsEU,YAAA,OAAAK,OAA0BG,KAAA,mCAAwClB,EAAA,KAAUU,YAAA,+BCE//D,IAcAR,EAdyBC,EAAQ,OAcjCC,CACEiB,EACAG,GATF,EAVA,SAAAK,GACE1B,EAAQ,SAaV,kBAEA,MAUeE,EAAA,QAAAH,EAAiB,8FC1BhC,IAGe4B,GADEnC,OAFjB,WAA0BE,KAAaC,eAAbD,KAAuCE,MAAAC,GAAwB,OAA/DH,KAA+DY,GAAA,IAExER,iBADjB,WAAoC,IAAAM,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,WAAAA,EAAA,MAAAO,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,siBAAAR,EAAA,KAAgoBe,OAAOG,KAAA,iDAAsDX,EAAAC,GAAA,SAAAD,EAAAC,GAAA,kBAAAR,EAAA,KAAmDe,OAAOG,KAAA,2DAAgEX,EAAAC,GAAA,SAAAD,EAAAC,GAAA,OAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,qEAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,cAAAR,EAAA,KAAkLU,YAAA,2BAAqCH,EAAAC,GAAA,QAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wVAAAR,EAAA,KAA4YU,YAAA,2BAAqCH,EAAAC,GAAA,sBAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,QAAAO,EAAAC,GAAA,KAAAR,EAAA,KAA6HW,aAAaE,YAAA,QAAmBE,OAAQE,MAAA,YAAkBV,EAAAC,GAAA,wCAAAR,EAAA,KAAyDU,YAAA,2BAAqCH,EAAAC,GAAA,cCYvzDN,EAbyBC,EAAQ,OAajCC,CAXA,KAaE0B,GATF,EAEA,KAEA,KAEA,MAUezB,EAAA,QAAAH,EAAiB,gCCtBhC6B,EAAAC,QAAiB7B,EAAQ,6CCAzB,IAGe8B,GADEtC,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,SAAmBU,YAAA,eAAyBV,EAAA,MAAAA,EAAA,MAAAA,EAAA,eAAsCU,YAAA,kBAAAK,OAAqCW,GAAA,IAAAQ,MAAA,MAAqB3B,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,KAAAR,EAAA,OAAqDU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,eAAyBH,EAAAC,GAAA,eAAAD,EAAAC,GAAA,KAAAR,EAAA,MAA6CU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,kBAAAQ,MAAA,MAAmC3B,EAAAC,GAAA,cAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA8De,OAAOW,GAAA,wBAAAQ,MAAA,MAAyC3B,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAkEe,OAAOW,GAAA,wBAAAQ,MAAA,MAAyC3B,EAAAC,GAAA,aAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA6De,OAAOW,GAAA,sBAAAQ,MAAA,MAAuC3B,EAAAC,GAAA,qBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAkDU,YAAA,eAAyBH,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAgDU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAoEe,OAAOW,GAAA,0BAAAQ,MAAA,MAA2C3B,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAoEe,OAAOW,GAAA,4BAAAQ,MAAA,MAA6C3B,EAAAC,GAAA,cAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA8De,OAAOW,GAAA,4BAAAQ,MAAA,MAA6C3B,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAkEe,OAAOW,GAAA,4BAAAQ,MAAA,MAA6C3B,EAAAC,GAAA,eAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA4CU,YAAA,eAAyBH,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAA+CU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,0BAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA0Ee,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,0BAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA0Ee,OAAOW,GAAA,0BAAAQ,MAAA,MAA2C3B,EAAAC,GAAA,mBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAmEe,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,2BAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAwDU,YAAA,eAAyBH,EAAAC,GAAA,cAAAD,EAAAC,GAAA,KAAAR,EAAA,MAA4CU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,sBAAAQ,MAAA,MAAuC3B,EAAAC,GAAA,QAAAR,EAAA,KAAyBU,YAAA,2BAAqCH,EAAAC,GAAA,gBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAgEe,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,QAAAR,EAAA,KAAyBU,YAAA,2BAAqCH,EAAAC,GAAA,uBAEr9EP,oBCCjB,IAaAC,EAbyBC,EAAQ,OAajCC,CAXA,KAaE6B,GATF,EATA,SAAAJ,GACE1B,EAAQ,SAYV,kBAEA,MAUeE,EAAA,EAAAH,EAAiB,8BCzBhC6B,EAAAC,QAAiB7B,EAAQ,2CCAzB,IAGegC,GADExC,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,SAAmBU,YAAA,eAAyBV,EAAA,MAAAA,EAAA,MAAAA,EAAA,eAAsCU,YAAA,kBAAAK,OAAqCW,GAAA,IAAAQ,MAAA,MAAqB3B,EAAAC,GAAA,wBAAAD,EAAAC,GAAA,KAAAR,EAAA,OAAuDU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,eAAyBH,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAgDU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,eAAAQ,MAAA,MAAgC3B,EAAAC,GAAA,cAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA8De,OAAOW,GAAA,qBAAAQ,MAAA,MAAsC3B,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAkEe,OAAOW,GAAA,qBAAAQ,MAAA,MAAsC3B,EAAAC,GAAA,aAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA6De,OAAOW,GAAA,mBAAAQ,MAAA,MAAoC3B,EAAAC,GAAA,qBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAkDU,YAAA,eAAyBH,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAgDU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAoEe,OAAOW,GAAA,0BAAAQ,MAAA,MAA2C3B,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAoEe,OAAOW,GAAA,4BAAAQ,MAAA,MAA6C3B,EAAAC,GAAA,cAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA8De,OAAOW,GAAA,4BAAAQ,MAAA,MAA6C3B,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAkEe,OAAOW,GAAA,4BAAAQ,MAAA,MAA6C3B,EAAAC,GAAA,eAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA4CU,YAAA,eAAyBH,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAkDU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,0BAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA0Ee,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,0BAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA0Ee,OAAOW,GAAA,0BAAAQ,MAAA,MAA2C3B,EAAAC,GAAA,mBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAmEe,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,2BAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAwDU,YAAA,eAAyBH,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAA+CU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,sBAAAQ,MAAA,MAAuC3B,EAAAC,GAAA,QAAAR,EAAA,KAAyBU,YAAA,2BAAqCH,EAAAC,GAAA,gBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAgEe,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,QAAAR,EAAA,KAAyBU,YAAA,2BAAqCH,EAAAC,GAAA,uBAEp9EP,oBCCjB,IAaAC,EAbyBC,EAAQ,OAajCC,CAXA,KAaE+B,GATF,EATA,SAAAN,GACE1B,EAAQ,SAYV,kBAEA,MAUeE,EAAA,EAAAH,EAAiB,gGCyEhCkC,GACAd,YAAAC,mBAAA,IChGec,GADE1C,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAAA,EAAA,OAA2BU,YAAA,yCAAmDH,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,OAAkCU,YAAA,cAAAK,OAAiCU,GAAA,oBAAuBzB,EAAA,OAAYU,YAAA,iBAA2BV,EAAA,OAAYU,YAAA,0CAAoDV,EAAA,KAAUU,YAAA,gBAA0BH,EAAAC,GAAA,wDAAAD,EAAAC,GAAA,KAAAR,EAAA,OAAuFU,YAAA,6BAAuCV,EAAA,KAAUU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,OAAU1B,EAAA,QAAAO,EAAAC,GAAA,mBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA2DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA8DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,0BAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,OAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,WAAwHU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,yBAAmCV,EAAA,iBAAAO,EAAAC,GAAA,KAAAR,EAAA,OAA4CU,YAAA,0BAAoCV,EAAA,yBAAAO,EAAAC,GAAA,KAAAD,EAAAE,GAAA,MAEhpCR,iBADjB,WAAoC,IAAaL,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,iBAA2BV,EAAA,KAAUU,YAAA,cAAAK,OAAiCG,KAAA,MAAWlB,EAAA,QAAaU,YAAA,SAA9Kb,KAAiMW,GAAA,4BAAAR,EAAA,KAA6CU,YAAA,2BAA9Ob,KAAmRW,GAAA,0BAAnRX,KAAmRW,GAAA,KAAAR,EAAA,OAAyDU,YAAA,uBAAAK,OAA0CY,cAAA,oBAAgC3B,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,aAA+D,WAAc,IAAaJ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,eAAyBV,EAAA,OAAYU,YAAA,gBAA0BV,EAAA,OAAYU,YAAA,qBAA+BV,EAAA,KAAUU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,mCAAwClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,wBAA/Vb,KAA2XW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,uDAA4DlB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,0BAAtkBb,KAAomBW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,yCAA8ClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,iCAA4C,WAAc,IAAad,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,WAAqBU,YAAA,2BAAqCV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,QAAaU,YAAA,gBAA0BV,EAAA,KAAUU,YAAA,mBAAlPb,KAA6QW,GAAA,KAAAR,EAAA,QAA2BU,YAAA,YAAxSb,KAA8TW,GAAA,oBAAAR,EAAA,KAAqCU,YAAA,2BAAnWb,KAAwYW,GAAA,eAAuB,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,UAAoBU,YAAA,WAAqBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,8BAAwCV,EAAA,KAAAA,EAAA,UAAAO,EAAAC,GAAA,QAAAR,EAAA,KAA8CU,YAAA,2BAAqCH,EAAAC,GAAA,QAAAD,EAAAC,GAAA,SAAAR,EAAA,KAAyCe,OAAOG,KAAA,sCAAAU,OAAA,YAAgErB,EAAAC,GAAA,aAAAD,EAAAC,GAAA,iDAAAR,EAAA,KAAsFe,OAAOG,KAAA,oDAAyDX,EAAAC,GAAA,SAAAD,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAA,EAAA,KAAsEU,YAAA,OAAAK,OAA0BG,KAAA,mCAAwClB,EAAA,KAAUU,YAAA,+BCE17E,IAcAR,EAdyBC,EAAQ,OAcjCC,CACEgC,EACAC,GATF,EAVA,SAAAR,GACE1B,EAAQ,SAaV,kBAEA,MAUeE,EAAA,QAAAH,EAAiB,8BC1BhC6B,EAAAC,QAAiB7B,EAAQ,qHCqGzBmC,GACAhB,YAAAC,mBAAA,ICnGegB,GADE5C,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAAA,EAAA,OAA2BU,YAAA,yCAAmDH,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,OAAkCU,YAAA,cAAAK,OAAiCU,GAAA,oBAAuBzB,EAAA,OAAYU,YAAA,iBAA2BV,EAAA,OAAYU,YAAA,0CAAoDV,EAAA,KAAUU,YAAA,gBAA0BH,EAAAC,GAAA,0DAAAD,EAAAC,GAAA,KAAAR,EAAA,OAAyFU,YAAA,6BAAuCV,EAAA,KAAUU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,OAAU1B,EAAA,QAAAO,EAAAC,GAAA,mBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA2DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA8DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,wBAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,OAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,WAAsHU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,yBAAmCV,EAAA,iBAAAO,EAAAC,GAAA,KAAAR,EAAA,OAA4CU,YAAA,0BAAoCV,EAAA,yBAAAO,EAAAC,GAAA,KAAAD,EAAAE,GAAA,MAEhpCR,iBADjB,WAAoC,IAAaL,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,iBAA2BV,EAAA,KAAUU,YAAA,cAAAK,OAAiCG,KAAA,MAAWlB,EAAA,QAAaU,YAAA,SAA9Kb,KAAiMW,GAAA,4BAAAR,EAAA,KAA6CU,YAAA,2BAA9Ob,KAAmRW,GAAA,0BAAnRX,KAAmRW,GAAA,KAAAR,EAAA,OAAyDU,YAAA,uBAAAK,OAA0CY,cAAA,oBAAgC3B,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,aAA+D,WAAc,IAAaJ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,eAAyBV,EAAA,OAAYU,YAAA,gBAA0BV,EAAA,OAAYU,YAAA,qBAA+BV,EAAA,KAAUU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,mCAAwClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,wBAA/Vb,KAA2XW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,uDAA4DlB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,0BAAtkBb,KAAomBW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,yCAA8ClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,iCAA4C,WAAc,IAAad,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,WAAqBU,YAAA,2BAAqCV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,QAAaU,YAAA,gBAA0BV,EAAA,KAAUU,YAAA,mBAAlPb,KAA6QW,GAAA,KAAAR,EAAA,QAA2BU,YAAA,YAAxSb,KAA8TW,GAAA,mBAAAR,EAAA,KAAoCU,YAAA,2BAAlWb,KAAuYW,GAAA,eAAuB,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,UAAoBU,YAAA,WAAqBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,8BAAwCV,EAAA,KAAAA,EAAA,UAAAO,EAAAC,GAAA,QAAAR,EAAA,KAA8CU,YAAA,2BAAqCH,EAAAC,GAAA,QAAAD,EAAAC,GAAA,QAAAR,EAAA,KAAwCe,OAAOG,KAAA,sCAAAU,OAAA,YAAgErB,EAAAC,GAAA,aAAAD,EAAAC,GAAA,6CAAAR,EAAA,KAAkFe,OAAOG,KAAA,oDAAyDX,EAAAC,GAAA,SAAAD,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAA,EAAA,KAAsEU,YAAA,OAAAK,OAA0BG,KAAA,mCAAwClB,EAAA,KAAUU,YAAA,+BCEp7E,IAcAR,EAdyBC,EAAQ,OAcjCC,CACEkC,EACAC,GATF,EAVA,SAAAV,GACE1B,EAAQ,SAaV,kBAEA,MAUeE,EAAA,QAAAH,EAAiB,iHC1BhC,IAGesC,GADE7C,OAFjB,WAA0BE,KAAaC,eAAbD,KAAuCE,MAAAC,GAAwB,OAA/DH,KAA+DY,GAAA,IAExER,iBADjB,WAAoC,IAAAM,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,WAAAA,EAAA,MAAAO,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,meAAAR,EAAA,KAA6jBe,OAAOG,KAAA,iDAAsDX,EAAAC,GAAA,UAAAD,EAAAC,GAAA,mBAAAR,EAAA,KAAqDe,OAAOG,KAAA,2DAAgEX,EAAAC,GAAA,UAAAD,EAAAC,GAAA,OAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,qEAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,cAAAR,EAAA,KAAmLU,YAAA,2BAAqCH,EAAAC,GAAA,QAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wVAAAR,EAAA,KAA4YU,YAAA,2BAAqCH,EAAAC,GAAA,sBAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,QAAAO,EAAAC,GAAA,KAAAR,EAAA,KAA6HW,aAAaE,YAAA,QAAmBE,OAAQE,MAAA,YAAkBV,EAAAC,GAAA,wCAAAR,EAAA,KAAyDU,YAAA,2BAAqCH,EAAAC,GAAA,cCYvvDN,EAbyBC,EAAQ,OAajCC,CAXA,KAaEoC,GATF,EAEA,KAEA,KAEA,MAUenC,EAAA,QAAAH,EAAiB,sICtBhC,IAGeuC,GADE9C,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,WAAAA,EAAA,KAAAA,EAAA,mBAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6FAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,qDAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,oOAA0hBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,+GAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,yBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wFAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,yIAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gKAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sTAA6uCD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,8GAAwGD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,oOAAqTD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mLAAqOD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,8KAAgOD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gEAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,6vBAAm3BD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,uLAA8LD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mLAAkOD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,oKAA+LD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,uXAAyaD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,0UAAqWD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,8KAAyMD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,gCAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,+FAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wIAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,wCAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,6TAAmjBD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,oCAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,0CAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gLAAulBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4HAAqHD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,0OAAuSD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wEAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,iKAAwRD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,ipBAAmrBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,kMAA6ND,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,qnBAAgpBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,ieAAsZD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,6SAA8aD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,uQAAkSD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,mBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,kMAA4QD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,whBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wNAA6zBD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iCAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gSAAsaD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,0WAAqYD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kCAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sLAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iDAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,uHAAAR,EAAA,MAAAO,EAAAC,GAAA,0CAAAR,EAAA,MAAAO,EAAAC,GAAA,2DAAAR,EAAA,MAAAO,EAAAC,GAAA,4CAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sGAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4FAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mQAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gFAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wBAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,gEAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wtBAAy6DD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,saAAijCD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mIAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sCAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,qBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gFAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gBAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,OAE52cR,iBADjB,WAAoC,IAAAM,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,wFAAAR,EAAA,QAAyHU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,SAAAR,EAAA,QAA2CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,kCAAAR,EAAA,QAAoEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,QAAAR,EAAA,QAA0CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,2CAAAR,EAAA,QAA6EU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,eAAAR,EAAA,QAAiDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,iCAAAR,EAAA,QAAmEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,UAAAR,EAAA,QAA4CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,yNAAAR,EAAA,QAA2PU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,qCAAAR,EAAA,QAAuEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,yFAAAR,EAAA,QAA2HU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,iBAAAR,EAAA,QAAmDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,QAA8B,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,gXAAAR,EAAA,QAAiZU,YAAA,mBAAhdb,KAA6eW,GAAA,OAA7eX,KAA6eW,GAAA,MAAAR,EAAA,QAAwCU,YAAA,mBAArhBb,KAAkjBW,GAAA,OAAljBX,KAAkjBW,GAAA,qDAA2E,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,gFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,WAAAD,EAAAC,GAAA,gFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,sDAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,yFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,WAAAD,EAAAC,GAAA,uDAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,aAAAD,EAAAC,GAAA,qFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,yBAAAD,EAAAC,GAAA,mEAA05B,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYe,OAAOC,IAAA,kCAAAC,MAAA,YAAlLpB,KAA4OW,GAAA,KAAAR,EAAA,OAA5OH,KAA4OW,GAAA,qEAAmG,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,8EAAAR,EAAA,KAA4Ge,OAAOG,KAAA,iEAAlLrB,KAAwPW,GAAA,8BAAxPX,KAAwPW,GAAA,QAAqD,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYW,aAAaQ,iBAAA,SAAyBJ,OAAQC,IAAA,kCAAAI,IAAA,8BAAzNvB,KAAmSW,GAAA,KAAAR,EAAA,OAAnSH,KAAmSW,GAAA,uDAAqF,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,UAAAD,EAAAC,GAAA,6GAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,gDAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,WAAAD,EAAAC,GAAA,uIAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,sPAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,+PAAi6BD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,sFAA2S,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYe,OAAOC,IAAA,0DAAAC,MAAA,YAAlLpB,KAAoQW,GAAA,KAAAR,EAAA,OAApQH,KAAoQW,GAAA,kCAAgE,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,yJAAAR,EAAA,QAA0LU,YAAA,mBAAzPb,KAAsRW,GAAA,QAAtRX,KAAsRW,GAAA,2GAAAR,EAAA,QAA8IU,YAAA,mBAApab,KAAicW,GAAA,QAAjcX,KAAicW,GAAA,gWAAuX,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAA,EAAA,UAA/DH,KAA+DW,GAAA,gFAAkH,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,yOAAAR,EAAA,MAA/DH,KAA+DW,GAAA,sIAAoZ,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,2EAAAR,EAAA,MAA/DH,KAA+DW,GAAA,0HAA0O,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,mEAAAR,EAAA,QAAoGU,YAAA,mBAAnKb,KAAgMW,GAAA,OAAhMX,KAAgMW,GAAA,SAAAR,EAAA,QAA2CU,YAAA,mBAA3Ob,KAAwQW,GAAA,OAAxQX,KAAwQW,GAAA,0OAAgQ,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,qEAA/DX,KAAgIW,GAAA,KAAAR,EAAA,MAAhIH,KAAgIW,GAAA,0NAAhIX,KAA2YW,GAAA,KAAAR,EAAA,MAA3YH,KAA2YW,GAAA,0EAAoH,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,yNAA4KR,EAAA,KAA2Ee,OAAOG,KAAA,4DAA7TrB,KAA8XW,GAAA,SAA9XX,KAA8XW,GAAA,sMAA8N,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,8EAAAR,EAAA,MAA/DH,KAA+DW,GAAA,+GAAAR,EAAA,MAA/DH,KAA+DW,GAAA,wNAAmUR,EAAA,MAAlYH,KAAkYW,GAAA,6KAAgTR,EAAA,MAAlrBH,KAAkrBW,GAAA,gTAAoV,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,+eAAAR,EAAA,SAAghB,WAAc,IAAaJ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,yKAAAR,EAAA,MAA/DH,KAA+DW,GAAA,uGAAqT,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,8LAAAR,EAAA,QAA+NU,YAAA,mBAA9Rb,KAA2TW,GAAA,OAA3TX,KAA2TW,GAAA,2BAAAR,EAAA,QAA6DU,YAAA,mBAAxXb,KAAqZW,GAAA,OAArZX,KAAqZW,GAAA,4SAAkU,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,qOAAAR,EAAA,MAA/DH,KAA+DW,GAAA,wJAAka,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,+NAAAR,EAAA,MAA/DH,KAA+DW,GAAA,mJAAuZ,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,uBAAAR,EAAA,MAAAO,EAAAC,GAAA,wFAAAR,EAAA,MAAAO,EAAAC,GAAA,mDAAgNR,EAAA,MAAAO,EAAAC,GAAA,sFAAyGR,EAAA,MAAAO,EAAAC,GAAA,6GAAAR,EAAA,MAAAO,EAAAC,GAAA,mFAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iLAAAR,EAAA,MAAAO,EAAAC,GAAA,0BAAAR,EAAA,MAAAO,EAAAC,GAAA,0GAAAR,EAAA,MAAAO,EAAAC,GAAA,iDAAAR,EAAA,MAAAO,EAAAC,GAAA,uFAAuxBR,EAAA,MAAAO,EAAAC,GAAA,yGAAAR,EAAA,MAAAO,EAAAC,GAAA,0FAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,wHAAyZ,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,4zBAAy0BR,EAAA,MAAx4BH,KAAw4BW,GAAA,sbAA8c,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYe,OAAOC,IAAA,kCAAAC,MAAA,YAAlLpB,KAA4OW,GAAA,KAAAR,EAAA,OAA5OH,KAA4OW,GAAA,+CAA6E,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,2PAAAR,EAAA,MAA/DH,KAA+DW,GAAA,mCAAmU,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,mGAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,uGAAqQ,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,gGAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,oDAA+M,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,uFAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,iFAAmO,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,gFAA/DX,KAAwJW,GAAA,KAAAR,EAAA,MAAxJH,KAAwJW,GAAA,sFAAwI,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,+cAAAR,EAAA,QAAgfU,YAAA,mBAA/iBb,KAA4kBW,GAAA,OAA5kBX,KAA4kBW,GAAA,sCAAAR,EAAA,QAAwEU,YAAA,mBAAppBb,KAAirBW,GAAA,OAAjrBX,KAAirBW,GAAA,kDAAwE,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,iDAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,8EAA/DX,KAAmOW,GAAA,KAAAR,EAAA,MAAnOH,KAAmOW,GAAA,4GAA8J,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,oKAAAR,EAAA,QAAqMU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,iCAAAR,EAAA,QAAmEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,gNAAAR,EAAA,MAAAO,EAAAC,GAAA,oMAAAR,EAAA,MAAAO,EAAAC,GAAA,iPAAAR,EAAA,QAAusBU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,SAAAR,EAAA,QAA2CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,8NAAoP,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,qDAA/DX,KAA6IW,GAAA,KAAAR,EAAA,MAA7IH,KAA6IW,GAAA,2BAA6D,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,sFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,+EAAkUR,EAAA,QAAwBU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,6BAAAR,EAAA,QAA+DU,YAAA,mBAA6BH,EAAAC,GAAA,SAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iIAAgID,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6EAAAR,EAAA,QAAmKU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,iEAAAR,EAAA,QAAmGU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,uCAAAR,EAAA,QAAmHU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,OAAAR,EAAA,QAAyCU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,UAAgC,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,uCAAAR,EAAA,QAAwEU,YAAA,mBAAvIb,KAAoKW,GAAA,OAApKX,KAAoKW,GAAA,QAAAR,EAAA,QAA0CU,YAAA,mBAA9Mb,KAA2OW,GAAA,OAA3OX,KAA2OW,GAAA,+JAAqL,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,sFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,4EAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iGAA4UR,EAAA,QAA0BU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,4CAAAR,EAAA,QAA8EU,YAAA,mBAA6BH,EAAAC,GAAA,SAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iIAAgID,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kIAA+LD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,0IAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,8CAAsQ,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,sFAAAR,EAAA,QAAiIU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,sHAAAR,EAAA,QAAwJU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,2FAAAR,EAAA,KAA0He,OAAOG,KAAA,sCAA2CX,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,8DAAAR,EAAA,QAA6GU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,cAAAR,EAAA,QAAgDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,qNAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kDAAAR,EAAA,KAAkUe,OAAOG,KAAA,0CAA+CX,EAAAC,GAAA,cAAAD,EAAAC,GAAA,2HAAAR,EAAA,QAAoKU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,8BAAAR,EAAA,QAAgEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,kLAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6JAAAR,EAAA,KAA0Ye,OAAOG,KAAA,sEAA2EX,EAAAC,GAAA,UAAAD,EAAAC,GAAA,8EAAAR,EAAA,KAAgHe,OAAOG,KAAA,qGAA0GX,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,UAA+C,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,8DAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,sEAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,8ECY52yBN,EAbyBC,EAAQ,OAajCC,CAXA,KAaEqC,GATF,EAEA,KAEA,KAEA,MAUepC,EAAA,QAAAH,EAAiB,gGCoEhCwC,GACApB,YAAAC,mBAAA,ICxFeoB,GADEhD,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAAA,EAAA,OAA2BU,YAAA,yCAAmDH,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,OAAkCU,YAAA,cAAAK,OAAiCU,GAAA,oBAAuBzB,EAAA,OAAYU,YAAA,iBAA2BV,EAAA,OAAYU,YAAA,0CAAoDV,EAAA,KAAUU,YAAA,gBAA0BH,EAAAC,GAAA,wDAAAD,EAAAC,GAAA,KAAAR,EAAA,OAAuFU,YAAA,6BAAuCV,EAAA,KAAUU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,OAAU1B,EAAA,QAAAO,EAAAC,GAAA,mBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA2DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA8DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,0BAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,OAAAF,EAAAC,GAAA,KAAAR,EAAA,WAAkGU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,yBAAmCV,EAAA,iBAAAO,EAAAC,GAAA,KAAAR,EAAA,OAA4CU,YAAA,0BAAoCV,EAAA,yBAAAO,EAAAC,GAAA,KAAAD,EAAAE,GAAA,MAE1nCR,iBADjB,WAAoC,IAAaL,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,iBAA2BV,EAAA,KAAUU,YAAA,cAAAK,OAAiCG,KAAA,MAAWlB,EAAA,QAAaU,YAAA,SAA9Kb,KAAiMW,GAAA,4BAAAR,EAAA,KAA6CU,YAAA,2BAA9Ob,KAAmRW,GAAA,0BAAnRX,KAAmRW,GAAA,KAAAR,EAAA,OAAyDU,YAAA,uBAAAK,OAA0CY,cAAA,oBAAgC3B,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,aAA+D,WAAc,IAAaJ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,eAAyBV,EAAA,OAAYU,YAAA,gBAA0BV,EAAA,OAAYU,YAAA,qBAA+BV,EAAA,KAAUU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,mCAAwClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,wBAA/Vb,KAA2XW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,uDAA4DlB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,0BAAtkBb,KAAomBW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,yCAA8ClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,iCAA4C,WAAc,IAAAH,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,UAAoBU,YAAA,WAAqBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,8BAAwCV,EAAA,KAAAA,EAAA,UAAAO,EAAAC,GAAA,QAAAR,EAAA,KAA8CU,YAAA,2BAAqCH,EAAAC,GAAA,QAAAD,EAAAC,GAAA,SAAAR,EAAA,KAAyCe,OAAOG,KAAA,sCAAAU,OAAA,YAAgErB,EAAAC,GAAA,aAAAD,EAAAC,GAAA,iDAAAR,EAAA,KAAsFe,OAAOG,KAAA,oDAAyDX,EAAAC,GAAA,SAAAD,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAA,EAAA,KAAsEU,YAAA,OAAAK,OAA0BG,KAAA,mCAAwClB,EAAA,KAAUU,YAAA,+BCE7gE,IAcAR,EAdyBC,EAAQ,OAcjCC,CACEsC,EACAC,GATF,EAVA,SAAAd,GACE1B,EAAQ,SAaV,kBAEA,MAUeE,EAAA,QAAAH,EAAiB,4GCvBjB0C,GADEjD,OAFjB,WAA0B,IAAaC,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBe,OAAOU,GAAA,SAAYzB,EAAA,oBAE5GC,oBCCjB,IAuBe4C,EAvBU1C,EAAQ,OAcjCC,ECTA0C,KAAA,ODWEF,GATF,EAVA,SAAAf,GACE1B,EAAQ,SAaV,KAEA,MAUgC,oBEzBhC4C,IAEIC,KAAM,IACNC,UAAWC,EAAQ,QAAgCC,QACnDC,WACEJ,KAAM,GACNC,UAAWC,EAAQ,QAAgCC,QACnDC,WACEJ,KAAM,GACNC,UAAWC,EAAQ,QAAiCC,YAKtDH,KAAK,YACLC,UAAWC,EAAQ,QAAqCC,QACxDC,WACEJ,KAAM,IACNC,UAAWC,EAAQ,QAAsCC,cClBjEE,IAEIL,KAAM,MACNC,UAAWC,EAAQ,QAAgCC,QACnDC,WACEJ,KAAM,GACNC,UAAWC,EAAQ,QAAgCC,QACnDC,WACEJ,KAAM,GACNC,UAAWC,EAAQ,QAAiCC,YAKtDH,KAAK,YACLC,UAAWC,EAAQ,QAAqCC,QACxDC,WACEJ,KAAM,IACNC,UAAWC,EAAQ,QAAsCC,cClBjEG,IAEIN,KAAM,MACNC,UAAWC,EAAQ,QAAgCC,QACnDC,WACEJ,KAAM,GACNC,UAAWC,EAAQ,QAAgCC,QACnDC,WACEJ,KAAM,GACNC,UAAWC,EAAQ,QAAiCC,YAKtDH,KAAK,YACLC,UAAWC,EAAQ,QAAqCC,QACxDC,WACEJ,KAAM,IACNC,UAAWC,EAAQ,QAAsCC,cCdjEI,IAAIC,IAAIC,KAER,IAAIC,KAGJA,GADAA,GADAA,EAASA,EAAOC,OAAOC,IACPD,OAAOE,IACPF,OAAOG,GAER,IAAAC,EAAA,IAAIN,KACjBO,OAAQN,gBCNVH,IAAIC,IAAIS,WACRV,IAAIW,OAAOC,eAAgB,EAG3B,IAAIZ,KACFa,KAAM,UACNC,GAAI,OACJX,SACApC,YAAcgD,OACdC,SAAU,sDChBZxC,EAAAC,QAAiB7B,EAAQ,gGC4FzBqE,GACAlD,YAAAC,mBAAA,IC1FekD,GADE9E,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAAA,EAAA,OAA2BU,YAAA,yCAAmDH,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,OAAkCU,YAAA,cAAAK,OAAiCU,GAAA,oBAAuBzB,EAAA,OAAYU,YAAA,iBAA2BV,EAAA,OAAYU,YAAA,0CAAoDV,EAAA,KAAUU,YAAA,gBAA0BH,EAAAC,GAAA,0DAAAD,EAAAC,GAAA,KAAAR,EAAA,OAAyFU,YAAA,6BAAuCV,EAAA,KAAUU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,OAAU1B,EAAA,QAAAO,EAAAC,GAAA,mBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA2DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA8DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,wBAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,OAAAF,EAAAC,GAAA,KAAAR,EAAA,WAAgGU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,yBAAmCV,EAAA,iBAAAO,EAAAC,GAAA,KAAAR,EAAA,OAA4CU,YAAA,0BAAoCV,EAAA,yBAAAO,EAAAC,GAAA,KAAAD,EAAAE,GAAA,MAE1nCR,iBADjB,WAAoC,IAAaL,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,iBAA2BV,EAAA,KAAUU,YAAA,cAAAK,OAAiCG,KAAA,MAAWlB,EAAA,QAAaU,YAAA,SAA9Kb,KAAiMW,GAAA,4BAAAR,EAAA,KAA6CU,YAAA,2BAA9Ob,KAAmRW,GAAA,0BAAnRX,KAAmRW,GAAA,KAAAR,EAAA,OAAyDU,YAAA,uBAAAK,OAA0CY,cAAA,oBAAgC3B,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,aAA+D,WAAc,IAAaJ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,eAAyBV,EAAA,OAAYU,YAAA,gBAA0BV,EAAA,OAAYU,YAAA,qBAA+BV,EAAA,KAAUU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,mCAAwClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,wBAA/Vb,KAA2XW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,uDAA4DlB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,0BAAtkBb,KAAomBW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,yCAA8ClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,iCAA4C,WAAc,IAAAH,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,UAAoBU,YAAA,WAAqBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,8BAAwCV,EAAA,KAAAA,EAAA,UAAAO,EAAAC,GAAA,QAAAR,EAAA,KAA8CU,YAAA,2BAAqCH,EAAAC,GAAA,QAAAD,EAAAC,GAAA,QAAAR,EAAA,KAAwCe,OAAOG,KAAA,sCAAAU,OAAA,YAAgErB,EAAAC,GAAA,aAAAD,EAAAC,GAAA,6CAAAR,EAAA,KAAkFe,OAAOG,KAAA,oDAAyDX,EAAAC,GAAA,SAAAD,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAA,EAAA,KAAsEU,YAAA,OAAAK,OAA0BG,KAAA,mCAAwClB,EAAA,KAAUU,YAAA,+BCExgE,IAcAR,EAdyBC,EAAQ,OAcjCC,CACEoE,EACAC,GATF,EAVA,SAAA5C,GACE1B,EAAQ,SAaV,kBAEA,MAUeE,EAAA,QAAAH,EAAiB,8BC1BhC6B,EAAAC,QAAiB7B,EAAQ,8BCAzB4B,EAAAC,QAAiB7B,EAAQ,0ICkGzBuE,GACApD,YAAAC,mBAAA,IChGeoD,GADEhF,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAAA,EAAA,OAA2BU,YAAA,yCAAmDH,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,OAAkCU,YAAA,cAAAK,OAAiCU,GAAA,oBAAuBzB,EAAA,OAAYU,YAAA,iBAA2BV,EAAA,OAAYU,YAAA,0CAAoDV,EAAA,KAAUU,YAAA,gBAA0BH,EAAAC,GAAA,0DAAAD,EAAAC,GAAA,KAAAR,EAAA,OAAyFU,YAAA,6BAAuCV,EAAA,KAAUU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,OAAU1B,EAAA,QAAAO,EAAAC,GAAA,qBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA6DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA8DU,YAAA,gBAA0BV,EAAA,eAAoBe,OAAOW,GAAA,SAAY1B,EAAA,QAAAO,EAAAC,GAAA,4BAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,OAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,WAA0HU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,YAAsBV,EAAA,OAAYU,YAAA,yBAAmCV,EAAA,iBAAAO,EAAAC,GAAA,KAAAR,EAAA,OAA4CU,YAAA,0BAAoCV,EAAA,yBAAAO,EAAAC,GAAA,KAAAD,EAAAE,GAAA,MAEtpCR,iBADjB,WAAoC,IAAaL,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,iBAA2BV,EAAA,KAAUU,YAAA,cAAAK,OAAiCG,KAAA,MAAWlB,EAAA,QAAaU,YAAA,SAA9Kb,KAAiMW,GAAA,4BAAAR,EAAA,KAA6CU,YAAA,2BAA9Ob,KAAmRW,GAAA,0BAAnRX,KAAmRW,GAAA,KAAAR,EAAA,OAAyDU,YAAA,uBAAAK,OAA0CY,cAAA,oBAAgC3B,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,QAAtZH,KAAsZW,GAAA,KAAAR,EAAA,aAA+D,WAAc,IAAaJ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBU,YAAA,eAAyBV,EAAA,OAAYU,YAAA,gBAA0BV,EAAA,OAAYU,YAAA,qBAA+BV,EAAA,KAAUU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,mCAAwClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,wBAA/Vb,KAA2XW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,uDAA4DlB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,0BAAtkBb,KAAomBW,GAAA,KAAAR,EAAA,KAA4BU,YAAA,YAAsBV,EAAA,KAAUU,YAAA,sBAAAK,OAAyCG,KAAA,yCAA8ClB,EAAA,QAAaU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,iCAA4C,WAAc,IAAad,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,WAAqBU,YAAA,2BAAqCV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,QAAaU,YAAA,gBAA0BV,EAAA,KAAUU,YAAA,mBAAlPb,KAA6QW,GAAA,KAAAR,EAAA,QAA2BU,YAAA,YAAxSb,KAA8TW,GAAA,QAAAR,EAAA,KAAyBU,YAAA,2BAAvVb,KAA4XW,GAAA,wBAAgC,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,UAAoBU,YAAA,WAAqBV,EAAA,OAAYU,YAAA,cAAwBV,EAAA,OAAYU,YAAA,8BAAwCV,EAAA,KAAAA,EAAA,UAAAO,EAAAC,GAAA,QAAAR,EAAA,KAA8CU,YAAA,2BAAqCH,EAAAC,GAAA,QAAAD,EAAAC,GAAA,QAAAR,EAAA,KAAwCe,OAAOG,KAAA,sCAAAU,OAAA,YAAgErB,EAAAC,GAAA,aAAAD,EAAAC,GAAA,oCAAAR,EAAA,KAAyEe,OAAOG,KAAA,oDAAyDX,EAAAC,GAAA,SAAAD,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAA,EAAA,KAAsEU,YAAA,OAAAK,OAA0BG,KAAA,mCAAwClB,EAAA,KAAUU,YAAA,+BCEz6E,IAcAR,EAdyBC,EAAQ,OAcjCC,CACEsE,EACAC,GATF,EAVA,SAAA9C,GACE1B,EAAQ,SAaV,kBAEA,MAUeE,EAAA,QAAAH,EAAiB,0GC1BhC,IAGe0E,GADEjF,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,SAAmBU,YAAA,eAAyBV,EAAA,MAAAA,EAAA,MAAAA,EAAA,eAAsCU,YAAA,kBAAAK,OAAqCW,GAAA,IAAAQ,MAAA,MAAqB3B,EAAAC,GAAA,wBAAAD,EAAAC,GAAA,KAAAR,EAAA,OAAuDU,YAAA,SAAmBV,EAAA,KAAUU,YAAA,eAAyBH,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAgDU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,kBAAAQ,MAAA,MAAmC3B,EAAAC,GAAA,cAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA8De,OAAOW,GAAA,wBAAAQ,MAAA,MAAyC3B,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAkEe,OAAOW,GAAA,wBAAAQ,MAAA,MAAyC3B,EAAAC,GAAA,aAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA6De,OAAOW,GAAA,sBAAAQ,MAAA,MAAuC3B,EAAAC,GAAA,qBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAkDU,YAAA,eAAyBH,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAgDU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAoEe,OAAOW,GAAA,0BAAAQ,MAAA,MAA2C3B,EAAAC,GAAA,oBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAoEe,OAAOW,GAAA,4BAAAQ,MAAA,MAA6C3B,EAAAC,GAAA,cAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA8De,OAAOW,GAAA,4BAAAQ,MAAA,MAA6C3B,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAkEe,OAAOW,GAAA,4BAAAQ,MAAA,MAA6C3B,EAAAC,GAAA,eAAAD,EAAAC,GAAA,KAAAR,EAAA,KAA4CU,YAAA,eAAyBH,EAAAC,GAAA,4BAAAD,EAAAC,GAAA,KAAAR,EAAA,MAA0DU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,0BAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA0Ee,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,0BAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAA0Ee,OAAOW,GAAA,0BAAAQ,MAAA,MAA2C3B,EAAAC,GAAA,mBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAmEe,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,2BAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAwDU,YAAA,eAAyBH,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAA+CU,YAAA,cAAwBV,EAAA,MAAAA,EAAA,eAA6Be,OAAOW,GAAA,sBAAAQ,MAAA,MAAuC3B,EAAAC,GAAA,QAAAR,EAAA,KAAyBU,YAAA,2BAAqCH,EAAAC,GAAA,gBAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,eAAgEe,OAAOW,GAAA,uBAAAQ,MAAA,MAAwC3B,EAAAC,GAAA,QAAAR,EAAA,KAAyBU,YAAA,2BAAqCH,EAAAC,GAAA,uBAEx+EP,oBCCjB,IAaAC,EAbyBC,EAAQ,OAajCC,CAXA,KAaEwE,GATF,EATA,SAAA/C,GACE1B,EAAQ,SAYV,kBAEA,MAUeE,EAAA,EAAAH,EAAiB,4FCzBhC,IAGe2E,GADElF,OAFjB,WAA0BE,KAAaC,eAAbD,KAAuCE,MAAAC,GAAwB,OAA/DH,KAA+DY,GAAA,IAExER,iBADjB,WAAoC,IAAAM,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,WAAAA,EAAA,MAAAO,EAAAC,GAAA,gBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mhBAAAR,EAAA,KAA2mBe,OAAOG,KAAA,iDAAsDX,EAAAC,GAAA,aAAAD,EAAAC,GAAA,cAAAR,EAAA,KAAmDe,OAAOG,KAAA,2DAAgEX,EAAAC,GAAA,aAAAD,EAAAC,GAAA,OAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,WAAAR,EAAA,KAA8LU,YAAA,2BAAqCH,EAAAC,GAAA,QAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,oWAAAR,EAAA,KAAwZU,YAAA,2BAAqCH,EAAAC,GAAA,0BAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,QAAAO,EAAAC,GAAA,KAAAR,EAAA,KAAiIW,aAAaE,YAAA,QAAmBE,OAAQE,MAAA,YAAkBV,EAAAC,GAAA,wCAAAR,EAAA,KAAyDU,YAAA,2BAAqCH,EAAAC,GAAA,cCY9zDN,EAbyBC,EAAQ,OAajCC,CAXA,KAaEyE,GATF,EAEA,KAEA,KAEA,MAUexE,EAAA,QAAAH,EAAiB,4FCtBhC,IAGe4E,GADEnF,OAFjB,WAA0B,IAAaC,EAAbC,KAAaC,eAAkD,OAA/DD,KAAuCE,MAAAC,IAAAJ,GAAwB,gBAExEK,oBCWjBC,EAbyBC,EAAQ,OAajCC,CAXA,KAaE0E,GATF,EAEA,KAEA,KAEA,MAUezE,EAAA,QAAAH,EAAiB,4FCtBhC,IAGe6E,GADEpF,OAFjB,WAA0B,IAAaC,EAAbC,KAAaC,eAAkD,OAA/DD,KAAuCE,MAAAC,IAAAJ,GAAwB,gBAExEK,oBCWjBC,EAbyBC,EAAQ,OAajCC,CAXA,KAaE2E,GATF,EAEA,KAEA,KAEA,MAUe1E,EAAA,QAAAH,EAAiB,4FCtBhC,IAGe8E,GADErF,OAFjB,WAA0B,IAAAY,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,WAAAA,EAAA,KAAAA,EAAA,mBAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,4FAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sEAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4MAAmiBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,uHAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,eAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,osBAA8zBR,EAAA,MAAAO,EAAAC,GAAA,yBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wGAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wHAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,oIAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sTAAgjCD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,iHAA0FD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,oOAAsUD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,GAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,mLAAoOD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,8KAAgOD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,iDAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,qVAAmdD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,6ZAA0VD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,kWAA2dD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gUAA2VD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,0KAAqMD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6BAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wEAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,2GAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,4CAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6BAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,iCAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gLAA+uBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4GAA2GD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,0OAAiSD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,uDAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,+JAAuQD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,soBAAsqBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,wwBAAmyBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4jBAAulBD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,qPAAgRD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iCAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,+lBAAmxBD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,gCAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,sIAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,mDAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,oIAAAR,EAAA,MAAAO,EAAAC,GAAA,mDAAAR,EAAA,MAAAO,EAAAC,GAAA,4DAAAR,EAAA,MAAAO,EAAAC,GAAA,0CAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,gGAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4EAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,yMAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,6fAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,iDAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,uDAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,2CAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kEAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,ucAAi3ED,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,kVAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,oaAA0oCD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,uIAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,8BAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAD,EAAAE,GAAA,IAAAF,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kBAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,4FAAAD,EAAAC,GAAA,KAAAR,EAAA,KAAAO,EAAAC,GAAA,cAAAD,EAAAC,GAAA,KAAAD,EAAAE,GAAA,OAEriaR,iBADjB,WAAoC,IAAAM,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,mGAAAR,EAAA,QAAoIU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,SAAAR,EAAA,QAA2CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,gCAAAR,EAAA,QAAkEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,QAAAR,EAAA,QAA0CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,yCAAAR,EAAA,QAA2EU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,eAAAR,EAAA,QAAiDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,yBAAAR,EAAA,QAA2DU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,UAAAR,EAAA,QAA4CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,+BAAAR,EAAA,QAAiEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,UAAAR,EAAA,QAA4CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,2LAAAR,EAAA,QAA6NU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,qCAAAR,EAAA,QAAuEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,8EAAAR,EAAA,QAAgHU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,mBAAAR,EAAA,QAAqDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,QAA8B,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,mTAAAR,EAAA,QAAoVU,YAAA,mBAAnZb,KAAgbW,GAAA,OAAhbX,KAAgbW,GAAA,MAAAR,EAAA,QAAwCU,YAAA,mBAAxdb,KAAqfW,GAAA,OAArfX,KAAqfW,GAAA,uDAA6E,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,KAAAR,EAAA,QAAiFU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,cAAAR,EAAA,QAAgDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,uCAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,WAAAD,EAAAC,GAAA,KAAAR,EAAA,QAAqIU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,OAAAR,EAAA,QAAyCU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,+DAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,KAAAR,EAAA,QAA8JU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,eAAAR,EAAA,QAAiDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,iEAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,YAAAD,EAAAC,GAAA,KAAAR,EAAA,QAAgKU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,eAAAR,EAAA,QAAiDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,yFAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,WAAAD,EAAAC,GAAA,KAAAR,EAAA,QAAuLU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,cAAAR,EAAA,QAAgDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,mDAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,aAAAD,EAAAC,GAAA,KAAAR,EAAA,QAAmJU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,OAAAR,EAAA,QAAyCU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,uGAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,yBAAAD,EAAAC,GAAA,KAAAR,EAAA,QAAmNU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,wBAAAR,EAAA,QAA0DU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,oEAA0F,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYe,OAAOC,IAAA,kCAAAC,MAAA,YAAlLpB,KAA4OW,GAAA,KAAAR,EAAA,OAA5OH,KAA4OW,GAAA,8DAA4F,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,0DAAAR,EAAA,KAAwFe,OAAOG,KAAA,iEAA9JrB,KAAoOW,GAAA,8BAApOX,KAAoOW,GAAA,QAAqD,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYW,aAAaQ,iBAAA,SAAyBJ,OAAQC,IAAA,kCAAAI,IAAA,8BAAzNvB,KAAmSW,GAAA,KAAAR,EAAA,OAAnSH,KAAmSW,GAAA,0DAAwF,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYe,OAAOC,IAAA,0DAAAC,MAAA,YAAlLpB,KAAoQW,GAAA,KAAAR,EAAA,OAApQH,KAAoQW,GAAA,qCAAmE,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,kHAAAR,EAAA,QAAmJU,YAAA,mBAAlNb,KAA+OW,GAAA,OAA/OX,KAA+OW,GAAA,oFAAAR,EAAA,QAAsHU,YAAA,mBAArWb,KAAkYW,GAAA,OAAlYX,KAAkYW,GAAA,qTAA2U,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAA,EAAA,UAA/DH,KAA+DW,GAAA,sEAAwG,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,8MAAAR,EAAA,MAA/DH,KAA+DW,GAAA,6HAAgX,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,yFAAAR,EAAA,MAA/DH,KAA+DW,GAAA,kHAAgP,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,ocAAidR,EAAA,UAAhhBH,KAAghBW,GAAA,WAAhhBX,KAAghBW,GAAA,oTAAkW,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,kEAA/DX,KAA6HW,GAAA,KAAAR,EAAA,MAA7HH,KAA6HW,GAAA,qNAA7HX,KAAmYW,GAAA,KAAAR,EAAA,MAAnYH,KAAmYW,GAAA,0EAAoH,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,0MAA4KR,EAAA,KAA4De,OAAOG,KAAA,oFAA9SrB,KAAuYW,GAAA,SAAvYX,KAAuYW,GAAA,4JAAoL,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,sFAAAR,EAAA,MAA/DH,KAA+DW,GAAA,mHAAAR,EAAA,MAA/DH,KAA+DW,GAAA,iMAA0UR,EAAA,MAAzYH,KAAyYW,GAAA,wKAA4RR,EAAA,MAArqBH,KAAqqBW,GAAA,oSAAqU,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAA/DH,KAA+DW,GAAA,kBAAAR,EAAA,QAAoDU,YAAA,mBAAnHb,KAAgJW,GAAA,OAAhJX,KAAgJW,GAAA,WAAAR,EAAA,QAA6CU,YAAA,mBAA7Lb,KAA0NW,GAAA,UAAkB,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,udAA+MR,EAAA,QAAySU,YAAA,mBAAvjBb,KAAolBW,GAAA,OAAplBX,KAAolBW,GAAA,gBAAAR,EAAA,QAAkDU,YAAA,mBAAtoBb,KAAmqBW,GAAA,OAAnqBX,KAAmqBW,GAAA,gJAAAR,EAAA,MAAnqBH,KAAmqBW,GAAA,gtBAAs4B,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,qJAAAR,EAAA,MAA/DH,KAA+DW,GAAA,8FAAwR,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,qBAAAR,EAAA,QAAsDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,oBAAAR,EAAA,QAAsDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,yJAAAR,EAAA,QAA2LU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,4BAAAR,EAAA,QAA8DU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,qPAA2Q,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,qLAAAR,EAAA,MAA/DH,KAA+DW,GAAA,mHAA6U,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,uBAAAR,EAAA,MAAAO,EAAAC,GAAA,8EAAAR,EAAA,MAAAO,EAAAC,GAAA,kDAAqMR,EAAA,MAAAO,EAAAC,GAAA,oFAAuGR,EAAA,MAAAO,EAAAC,GAAA,2GAAAR,EAAA,MAAAO,EAAAC,GAAA,mFAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,8JAAAR,EAAA,MAAAO,EAAAC,GAAA,0BAAAR,EAAA,MAAAO,EAAAC,GAAA,0GAAAR,EAAA,MAAAO,EAAAC,GAAA,gDAAAR,EAAA,MAAAO,EAAAC,GAAA,oFAA8vBR,EAAA,MAAAO,EAAAC,GAAA,sGAAAR,EAAA,MAAAO,EAAAC,GAAA,mFAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,uFAA8W,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,uwBAAoxBR,EAAA,MAAn1BH,KAAm1BW,GAAA,gXAAwY,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,OAAiBW,aAAaC,MAAA,iBAAAC,YAAA,MAAAC,aAAA,YAAkEd,EAAA,OAAYe,OAAOC,IAAA,kCAAAC,MAAA,YAAlLpB,KAA4OW,GAAA,KAAAR,EAAA,OAA5OH,KAA4OW,GAAA,sDAAoF,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,2OAAAR,EAAA,MAA/DH,KAA+DW,GAAA,uCAAuT,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,mGAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,iGAA+P,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,mGAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,oDAAkN,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,uFAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,iFAAmO,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,gFAA/DX,KAAwJW,GAAA,KAAAR,EAAA,MAAxJH,KAAwJW,GAAA,sFAAwI,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,gDAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,8EAA/DX,KAAkOW,GAAA,KAAAR,EAAA,MAAlOH,KAAkOW,GAAA,4GAA8J,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAAAO,EAAAC,GAAA,wKAAAR,EAAA,QAAyMU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,oCAAAR,EAAA,QAAsEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,0NAAAR,EAAA,MAAAO,EAAAC,GAAA,2LAAAR,EAAA,MAAAO,EAAAC,GAAA,0EAAAR,EAAA,QAAiiBU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,eAAAR,EAAA,QAAiDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,uIAAAR,EAAA,QAAyKU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,SAAAR,EAAA,QAA2CU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,8MAAoO,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,4DAA/DX,KAAoJW,GAAA,KAAAR,EAAA,MAApJH,KAAoJW,GAAA,2BAA6D,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,+EAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,0EAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,+EAAmTR,EAAA,QAAwBU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,6BAAAR,EAAA,QAA+DU,YAAA,mBAA6BH,EAAAC,GAAA,SAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iIAAgID,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6EAAAR,EAAA,QAAmKU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,oEAAAR,EAAA,QAAsGU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,6CAAAR,EAAA,QAAyHU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,OAAAR,EAAA,QAAyCU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,UAAgC,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,KAA/DH,KAA+DW,GAAA,uCAAAR,EAAA,QAAwEU,YAAA,mBAAvIb,KAAoKW,GAAA,OAApKX,KAAoKW,GAAA,QAAAR,EAAA,QAA0CU,YAAA,mBAA9Mb,KAA2OW,GAAA,OAA3OX,KAA2OW,GAAA,8KAAoM,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,+EAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,0EAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iGAAmUR,EAAA,QAA0BU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,4CAAAR,EAAA,QAA8EU,YAAA,mBAA6BH,EAAAC,GAAA,SAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,iIAAgID,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,kIAA+LD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,0IAAAR,EAAA,MAAAO,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,sCAA8P,WAAc,IAAAD,EAAAV,KAAaD,EAAAW,EAAAT,eAA0BE,EAAAO,EAAAR,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAAAO,EAAAC,GAAA,oFAAAR,EAAA,QAA+HU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,+IAAAR,EAAA,QAAiLU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,yFAAAR,EAAA,KAAwHe,OAAOG,KAAA,sCAA2CX,EAAAC,GAAA,iBAAAD,EAAAC,GAAA,iEAAAR,EAAA,QAA6GU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,cAAAR,EAAA,QAAgDU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,iMAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,2DAAAR,EAAA,KAAuTe,OAAOG,KAAA,0CAA+CX,EAAAC,GAAA,cAAAD,EAAAC,GAAA,2HAAAR,EAAA,QAAoKU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,gCAAAR,EAAA,QAAkEU,YAAA,mBAA6BH,EAAAC,GAAA,OAAAD,EAAAC,GAAA,mMAAAD,EAAAC,GAAA,KAAAR,EAAA,MAAAO,EAAAC,GAAA,+KAAAR,EAAA,KAA6ae,OAAOG,KAAA,sEAA2EX,EAAAC,GAAA,aAAAD,EAAAC,GAAA,kFAAAR,EAAA,KAAuHe,OAAOG,KAAA,qGAA0GX,EAAAC,GAAA,sBAAAD,EAAAC,GAAA,UAA+C,WAAc,IAAaZ,EAAbC,KAAaC,eAA0BE,EAAvCH,KAAuCE,MAAAC,IAAAJ,EAAwB,OAAAI,EAAA,MAAAA,EAAA,MAA/DH,KAA+DW,GAAA,8EAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,oFAA/DX,KAA+DW,GAAA,KAAAR,EAAA,MAA/DH,KAA+DW,GAAA,kFCYjnyBN,EAbyBC,EAAQ,OAajCC,CAXA,KAaE4E,GATF,EAEA,KAEA,KAEA,MAUe3E,EAAA,QAAAH,EAAiB","file":"static/js/app.006a6c3185467785515e.js","sourcesContent":["var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('router-view')}\nvar staticRenderFns = []\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-34eab6d5\",\"hasScoped\":false,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/vi/ViEntry.vue\n// module id = null\n// module chunks = ","var normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-34eab6d5\\\",\\\"hasScoped\\\":false,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./ViEntry.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = null\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/vi/ViEntry.vue\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',[_c('p',[_c('vue-mathjax')],1),_vm._v(\" \"),_c('h1',[_vm._v(\"I - Reinforcement Learning - from Policy Gradient to Deep Deterministic Policy Gradient\")]),_vm._v(\" \"),_vm._m(0),_vm._v(\" \"),_vm._m(1),_vm._v(\" \"),_c('p',[_vm._v(\"Here are the definitions of common terms in RL:\")]),_vm._v(\" \"),_vm._m(2),_vm._v(\" \"),_vm._m(3),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('p',[_vm._v(\"At a state $s$, agent interact with environment by action $a$,\\nleading to a new state $s_{t+1}$ and receive a reward $r_{t+1}$.\\nThe loop repeats like this until the final state reached $s_T$.\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"1 - Example\")]),_vm._v(\" \"),_vm._m(4),_vm._v(\" \"),_vm._m(5),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_vm._m(6),_vm._v(\" \"),_c('h1',[_vm._v(\"2 - Policy Gradient\")]),_vm._v(\" \"),_c('p',[_vm._v(\"For a lively example, we examine a simple game problem, Hare Egg game.\")]),_vm._v(\" \"),_vm._m(7),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('p',[_vm._v(\"Let $\\\\pi_\\\\theta(a|s) = f(s, \\\\theta)$ is the policy of agent, it is a probability distribution of action $a$ at state $s$.\")]),_vm._v(\" \"),_vm._m(8),_vm._v(\" \"),_c('p',[_vm._v(\"Let $\\\\tau = s_1, a_1, s_2, a_2,..., s_T, a_T$ is the sequence from state $s_1$ to state $s_T$. The probability of $\\\\tau$ is likely to happen:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"[\\n\\\\begin{eqnarray}\\np_\\\\theta(\\\\tau) &=& p_\\\\theta(s_1, a_1, s_2, a_2,...s_T, a_T) \\\\\\\\\\n&=& p(s_1)\\\\pi_\\\\theta(a_1|s_1)p(s_2|s_1, a_1)\\\\pi_\\\\theta(a_2|s_2)...p(s_{T}|s_{T-1},a_{T-1})\\\\pi_\\\\theta(a_T|s_T) \\\\\\\\\\n&=& p(s_1)\\\\Pi_{t=1}^{t=T}\\\\pi_\\\\theta(a_t|s_t)p(s_{t+1}|s_t, a_t) \\\\\\\\\\n\\\\end{eqnarray}\\n]\")]),_vm._v(\" \"),_c('p',[_vm._v(\"We will see that the probability distribution of state $p(s_{t+1}|a_t, s_t)$ will be eliminated later.\")]),_vm._v(\" \"),_vm._m(9),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\theta^* &=& \\\\arg\\\\max_\\\\theta E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\big[r(\\\\tau)\\\\big] \\\\\\\\\\n&=& \\\\arg\\\\max_\\\\theta E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(10),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nJ(\\\\theta) &=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg] \\\\\\\\\\n&=& \\\\frac{1}{N} \\\\sum_i\\\\sum_t r(a_t, s_t)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(11),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nJ(\\\\theta) &=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg] \\\\\\\\\\n&=& \\\\int p_\\\\theta(\\\\tau) r(\\\\tau) dr\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Continuing to examine gradient of the objective function:\")]),_vm._v(\" \"),_vm._m(12),_vm._v(\" \"),_c('p',[_vm._v(\"Take a closer look at $\\\\log p_\\\\theta(\\\\tau)$, as we have seen above $p_\\\\theta(\\\\tau) = p(s_1)\\\\Pi_{t=1}^{t=T}\\\\pi_\\\\theta(a_t|s_t)p(s_{t+1}|s_t, a_t)$, we have:\\n$$\\n\\\\begin{eqnarray}\\n\\\\log p_\\\\theta(\\\\tau) = \\\\log p(s_1) + \\\\sum_{t=1}^{t=T}\\\\log \\\\pi_\\\\theta(a_t|s_t) + \\\\sum_{t=1}^{t=T}\\\\log p(s_{t+1}|s_t, a_t)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(13),_vm._v(\" \"),_c('p',[_vm._v(\"Gradient of the objective function now becomes:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=&  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) r(\\\\tau)\\\\bigg] \\\\\\\\\\n&=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a_t|s_t)\\\\sum_{t=1}^{t=T} r(a_t, s_t)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Similarly, after experiencing $N$ episodes, the expectation of this gradient is:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=& \\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\bigg(\\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_{i,t}|s_{i,t})\\\\bigg)\\\\bigg(\\\\sum_{t=1}^{t=T} r(a_{i,t}, s_{i,t})\\\\bigg)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Finally, we update $\\\\theta$ using gradient ascent:\\n$$\\n\\\\begin{eqnarray}\\n\\\\theta \\\\leftarrow \\\\theta + \\\\nabla_\\\\theta J(\\\\theta)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"3 - REINFORCE algorithm\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Sum up all the result above, we have the REINFORCE algorithm as below:\")]),_vm._v(\" \"),_vm._m(14),_vm._v(\" \"),_c('p',[_vm._v(\"Now, let's stop to look closer on the gradient of the objective function. Write in a simple form, we have:\")]),_vm._v(\" \"),_vm._m(15),_vm._v(\" \"),_c('h1',[_vm._v(\"4 - Some new definitions\")]),_vm._v(\" \"),_vm._m(16),_vm._v(\" \"),_c('h2',[_vm._v(\"4.1 - Bellman Equations\")]),_vm._v(\" \"),_c('p',[_vm._v(\"From the formula above, we have:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) &=& E_\\\\pi\\\\bigg[G_t|S=s_t\\\\bigg] \\\\\\\\\\n&=& E_\\\\pi\\\\bigg[\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+1}|S=s_t\\\\bigg] \\\\\\\\\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Take the reward $R_{t+1}$ received when going from state $s_t$ to $s_{t+1}$ to outside the $\\\\sum$, we get:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nE_\\\\pi\\\\bigg[R_{t+1} + \\\\gamma\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+2}|S=s_t\\\\bigg] &=& E_\\\\pi[R_{t+1}|S=s_t] + \\\\gamma E_\\\\pi\\\\bigg[\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+2}|S=s_t\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Expand 2 expected values of the equation above, we have:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nE_\\\\pi\\\\bigg[R_{t+1}|S=s_t\\\\bigg]=\\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)R(s_{t+1}|s_t, a)\\n\\\\end{eqnarray}\\n$$\\nBut:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\gamma E_\\\\pi\\\\bigg[\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+2}|S=s_t\\\\bigg] = \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\gamma E_\\\\pi\\\\bigg[\\\\sum^\\\\infty_{k=0} \\\\gamma^k R_{t+k+2} | S = s_{t+1}\\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nWe have:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) = \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\Bigg[R(s_{t+1}|s_t, a) + \\\\gamma E_\\\\pi\\\\bigg[\\\\sum^\\\\infty_{k=0} \\\\gamma^k R_{t+k+2} | S = s_{t+1} \\\\bigg]\\\\Bigg]\\n\\\\end{eqnarray}\\n$$\\nNotice that:\\n$$\\n\\\\begin{eqnarray}\\nE_\\\\pi\\\\bigg[\\\\sum^\\\\infty_{k=0} \\\\gamma^k R_{t+k+2} | S = s_{t+1}\\\\bigg] = V^\\\\pi(s_{t+1})\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Finally we have:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) = \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\bigg[R(s_{t+1}|s_t, a) + \\\\gamma  V^\\\\pi(s_{t+1})\\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nDoing similar thing with $Q^\\\\pi(s_t, a_t)$:\\n$$\\n\\\\begin{eqnarray}\\nQ^\\\\pi(s_t, a_t) = \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\bigg[R(s_{t+1}|s_t, a) + \\\\gamma \\\\sum_{a_{t+1}} \\\\pi(s_{t+1}, a_{t+1}) Q^\\\\pi (s_{t+1}, a_{t+1}) \\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nCombine with the relation between $V^\\\\pi$ and $Q^\\\\pi$ above, we have:\\n$$\\n\\\\begin{eqnarray}\\n\\\\sum_{a_{t+1}} \\\\pi(s_{t+1}, a_{t+1}) Q^\\\\pi (s_{t+1}, a_{t+1}) = V^\\\\pi(s_{t+1})\\n\\\\end{eqnarray}\\n$$\\nThus:\\n$$\\n\\\\begin{eqnarray}\\nQ^\\\\pi(s_t, a_t) = \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a_t)\\\\bigg[R(s_{t+1}|s_t, a_t) + \\\\gamma  V^\\\\pi(s_{t+1}) \\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"All of the above show that we can represent the value of $Q^\\\\pi$ and $V^\\\\pi$ at state $s_t$ with state $s_{t+1}$. Therefore, if we know the value at state $s_{t+1}$, we can easily calculate the value at state $s_t$. To sum up, we have 2 formulas below:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) &=& \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\bigg[R(s_{t+1}|s_t, a) + \\\\gamma  V^\\\\pi(s_{t+1})\\\\bigg] \\\\\\\\\\nQ^\\\\pi(s_t, a_t) &=& \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a_t)\\\\bigg[R(s_{t+1}|s_t, a_t) + \\\\gamma  V^\\\\pi(s_{t+1}) \\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Going back with the gradient of the objective function, now we have:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)Q^\\\\pi(s,a)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"5 - Advantage\")]),_vm._v(\" \"),_vm._m(17),_vm._v(\" \"),_vm._m(18),_vm._v(\" \"),_c('h1',[_vm._v(\"6 - Stochastic Actor-Critic\")]),_vm._v(\" \"),_vm._m(19),_vm._v(\" \"),_c('p',[_vm._v(\"Examine the gradient of the objective function that we have above:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)\\\\Big(Q^\\\\pi(s,a)-V^\\\\pi(s)\\\\Big)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nFrom the Bellman Equation we have the relationship between $Q^\\\\pi$ and $V^\\\\pi$, now the objective function becomes:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim \\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)\\\\Big(R + \\\\gamma V^\\\\pi(s_{t+1})- V^\\\\pi(s)\\\\Big)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(20),_vm._v(\" \"),_c('h1',[_vm._v(\"7 - Actor-Critic Algorithm\")]),_vm._v(\" \"),_c('p',[_vm._v(\"From REINFORCE algorithm, now we use an additional approximation function for value function $V_\\\\phi$, changing a bit and we have:\")]),_vm._v(\" \"),_vm._m(21),_vm._v(\" \"),_c('h1',[_vm._v(\"8 - From Stochastic Actor-Critic to Q-Learning\")]),_vm._v(\" \"),_vm._m(22),_vm._v(\" \"),_vm._m(23),_vm._v(\" \"),_c('br'),_vm._v(\"\\nTherefore, with a policy $\\\\pi$, we always can apply policy $\\\\pi'$ over it to have a new policy equal or better.\"),_c('br'),_vm._v(\"\\nWe now have the algorithm as follow:\"),_c('br'),_vm._v(\"\\n1. Evaluate $A^\\\\pi(s,a)$ with different actions $a$ \"),_c('br'),_vm._v(\"\\n2. Optimize $\\\\pi \\\\leftarrow \\\\pi'$\\n\"),_vm._m(24),_vm._v(\" \"),_vm._m(25),_vm._v(\" \"),_c('p',[_vm._v(\"Now we actually do not need to care about policy anymore, and the second step can be written as:\")]),_vm._v(\" \"),_vm._m(26),_vm._v(\" \"),_c('p',[_vm._v(\"If we use an approximation function for $V_\\\\phi(s)$, we have the following algorithm:\")]),_vm._v(\" \"),_vm._m(27),_vm._v(\" \"),_c('p',[_vm._v(\"This algorithm is not good, in the first step we need to have reward $r(s, a)$ corresponding to different actions $a$, thus we need different simulations at a state $s$. To solve this, we could do the same analysis above with $Q(s,a)$ instead of $V(s)$.\")]),_vm._v(\" \"),_vm._m(28),_vm._v(\" \"),_vm._m(29),_vm._v(\" \"),_vm._m(30),_vm._v(\" \"),_vm._m(31),_vm._v(\" \"),_c('p',[_vm._v(\"To sum up, for the algorithm to be stable, and possibly converge, we need:\")]),_vm._v(\" \"),_vm._m(32),_vm._v(\" \"),_c('p',[_vm._v(\"The algorithm now:\")]),_vm._v(\" \"),_vm._m(33),_vm._v(\" \"),_c('h1',[_vm._v(\"9 - From Deep Q-Network to Deep Deterministic Policy Gradient\")]),_vm._v(\" \"),_c('p',[_vm._v(\"DQN algorithm is succeeded to approximate Q-value, but there is a limitation in step 3: we need to evaluate $Q_{\\\\phi'}$ with all different actions to choose the highest $Q$. With discrete action space such as games, when the set of actions is just up down left right buttons, the number of actions is finite and small, this is possible. However, in continuous action space, for example with action in a range from 0 to 1 we need a different approach.\\nThe first thing we could think of is to discretize the action space into bins, for example from 0 to 1, we could divide it by 5 or 10 bins. Another way is that we sample actions with uniform distribution on the action space and choose the highest $Q(s,a)$ at state $s$.\")]),_vm._v(\" \"),_vm._m(34),_vm._v(\" \"),_c('p',[_vm._v(\"Now, if we add an approximation function $\\\\mu_\\\\theta(s) = \\\\arg max_a Q_\\\\phi(s,a)$, we will have to find $\\\\theta$ in which: $\\\\theta \\\\leftarrow  \\\\arg max_\\\\theta Q_\\\\phi(s,\\\\mu_\\\\theta(s))$. This optimization evaluates the change of $Q_\\\\phi$ w.r.t parameters $\\\\theta$. We could evaluate this change by the chain rule as follow:\\n$\\\\frac{dQ_\\\\phi}{d\\\\theta} = \\\\frac{dQ_\\\\phi}{d\\\\mu} \\\\frac{d\\\\mu}{d\\\\theta}$.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Notice that, $\\\\mu_\\\\theta(s)$ is a Deterministic Policy, therefore this method is called Deep Deterministic Policy Gradient.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"The DDPG algorithm is as follow:\")]),_vm._v(\" \"),_vm._m(35),_vm._v(\" \"),_vm._m(36),_vm._v(\" \"),_c('h1',[_vm._v(\"10 - Conclusion\")]),_vm._v(\" \"),_c('p',[_vm._v(\"To sum up, we went throught the Policy Gradient algorithm to DQN and DDPG.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Take away:\")]),_vm._v(\" \"),_vm._m(37)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Reinforcement Learning is the field related to teaching machine \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"agent\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" to perform well a task by interacting with the environment and receive rewards.\\nThis way of learning is very similar to the way human learns from the environment by the wrong test method. Taking an example of a child in the winter, the child will tend to get closer to the fire \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"because the reward is warm\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\", but touching the fire is hot, the child will tend to avoid touching the fire \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"it will burn him\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\".\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"In the above example, the reward appears immediately, the action adjustment is\\nrelatively easy. However, in more complex situations where rewards are far in the future, this becomes more complicated. How to achieve highest accumulative reward throughout the process? Reinforcement Learning algorithms\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\" RL\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" is to solve this optimization problem.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_c('em',[_vm._v(\"Environment\")]),_vm._v(\" : is the space, the game, the environment that the machine interacts with.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Agent\")]),_vm._v(\" : the machine observes the environment and generates action accordingly.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Policy\")]),_vm._v(\": the rule which the agent follows to get the goal.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Reward\")]),_vm._v(\": a reward that the agent received from the environment for taking an action.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"State\")]),_vm._v(\" : the state of the environment that the agent observes.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Episode\")]),_vm._v(\" : the sequence of state and action until it finishes $s_1,a_1,s_2,a_2,...s_T, a_T$\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Accumulative Reward\")]),_vm._v(\" : the sum of all rewards received from an episode.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{attrs:{\"src\":\"https://i.imgur.com/nIUdsIm.jpg\",\"align\":\"center\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Image 1: The interaction loop between agent and environment.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"This example below is from openAI Gym, environment named\\n\"),_c('a',{attrs:{\"href\":\"https://github.com/openai/gym/wiki/MountainCarContinuous-v0\"}},[_vm._v(\"MountaincontinuousCar-v0\")]),_vm._v(\".\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{staticStyle:{\"padding-bottom\":\"0.5em\"},attrs:{\"src\":\"https://i.imgur.com/yGWmDei.jpg\",\"alt\":\"MountaincontinuousCar-v0\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Image 2: A render from MountaincontinuousCar-v0.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_c('em',[_vm._v(\"Goal\")]),_vm._v(\" : the goal of this game is to find a policy to control the car reaching the flag.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Environment\")]),_vm._v(\" : ramps and cars running in it.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"State\")]),_vm._v(\" : the state of the vehicle has 2 dimensions, the coordinates of the vehicle in the $x$ axis and the speed of the vehicle at the time of measurement.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Action\")]),_vm._v(\" : Force applied to control the vehicle, however the force is not strong enough in order to push the car at once to the flag. The car will need to go back and forth on the sides of gain enough acceleration and reach the flag.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Reward\")]),_vm._v(\" : With every step that the car cannot reach the flag, the agent gets a reward $r=\\\\frac{-a^2}{10}$,\\nand a reward 100 if it reach the target. Thus, if the agent controls the car but it cannot reach the flag, the agent will be punished.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Terminal state\")]),_vm._v(\" : ff the agent reaches the flag or the step number exceeds 998 steps.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{attrs:{\"src\":\"https://laptrinhcuocsong.com/images/game-hung-trung.png\",\"align\":\"center\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Image 3: Hare Egg game.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"In Hare Egg game, assume that we have 3 actions: go left, go right or stand still.\\nCorresponding to the current state $s$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"the position of the basket, the position of the egg falling against the basket,\\nspeed of eggs falling...\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" we will have a probability distribution of action,\\nfor example $[0.1, 0.3, 0.5]$. The sum of all action probability at state $s$ is $1$, we have: $\\\\sum_{a}\\\\pi_\\\\theta(a|s) = 1$.\\nLet $p(s_{t+1}|a_t, s_t)$ is the probability distrubution of the next state when the agent is at state $s$ and executes an action $a$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_c('strong',[_vm._v(\"The goal of reinforcement learning is to find $\\\\theta$ such that:\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"From the formula we can see $\\\\theta^*$ is a set of parameters such that the expectation of accumulative reward from many different samples $\\\\tau$, which we collect by the current policy $\\\\pi_\\\\theta$ is biggest.\"),_c('br'),_vm._v(\"\\nAfter $N$ different episodes, the agent collects $N$ different samples $\\\\tau$. The objective function now becomes:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$J(\\\\theta)$ is the average of accumulative reward from $N$ episodes.\"),_c('br'),_vm._v(\"\\nWe can also see $J(\\\\theta)$ under the probability distribution $p_\\\\theta(\\\\tau)$ as below:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg] \\\\\\\\\\n&=& \\\\int \\\\nabla_\\\\theta p_\\\\theta(\\\\tau) r(\\\\tau) dr\\n\\\\end{eqnarray}\\n$$\\nBut we also have:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta p_\\\\theta(\\\\tau) &=&  p_\\\\theta(\\\\tau) \\\\frac{\\\\nabla_\\\\theta p_\\\\theta(\\\\tau)} {p_\\\\theta(\\\\tau)} \\\\\\\\\\n&=& p_\\\\theta(\\\\tau)\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau)\\n\\\\end{eqnarray}\\n$$\\n\"),_c('strong',[_vm._v(\"Note\")]),_vm._v(\" that this trick is usually used, thus:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=& \\\\int p_\\\\theta(\\\\tau) \\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) r(\\\\tau) dr \\\\\\\\\\n&=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) r(\\\\tau)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Finally:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) = \\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_t|s_t)\\n\\\\end{eqnarray}\\n$$\\nThis result is beautiful because the derivative with respect to \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"w.r.t\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" $\\\\theta$ of the function $\\\\log p_\\\\theta(\\\\tau)$ is no longer dependent on the transition probability of state $p(s_{t+1}|a_t, s_t)$, it is only dependent on the probability distribution of action $a_i$ which the agent execute on $s_i$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Collect $N$ samples {$\\\\tau^i$} with the policy $\\\\pi_\\\\theta$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Calculate gradient: $\\\\nabla_\\\\theta J(\\\\theta) = \\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\bigg(\\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_{i,t}|s_{i,t})\\\\bigg)\\\\bigg(\\\\sum_{t=1}^{t=T} r(a_{i,t}, s_{i,t})\\\\bigg) $\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Update $\\\\theta \\\\leftarrow \\\\theta + \\\\nabla_\\\\theta J(\\\\theta)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) = \\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(\\\\tau_i)r(\\\\tau_i)\\n\\\\end{eqnarray}\\n$$\\nThis is exactly the maximum likelihood estimation \"),_c('a',{attrs:{\"href\":\"https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\"}},[_vm._v(\"MLE\")]),_vm._v(\" multiply with the accumulative reward.\\nOptimizing the objective function also means increasing the probability to follow sequences $\\\\tau$ which give high accumulative rewards.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$V^\\\\pi(s)$: expected accumulative reward at state $s$ by policy $\\\\pi$.\"),_c('br'),_vm._v(\"\\n$Q^\\\\pi(s,a)$: expected accumulative reward if execute action $a$ at state $s$ by policy $\\\\pi$.\"),_c('br'),_vm._v(\"\\nThe relationship between $V^\\\\pi(s)$ and $Q^\\\\pi(s,a)$: $V^\\\\pi(s) = \\\\sum_{a \\\\in A}\\\\pi_\\\\theta(s,a)Q^\\\\pi(s,a)$ - this makes sense because $\\\\pi_\\\\theta(s,a)$ is the probability of doing action $a$ at state $s$.\"),_c('br'),_vm._v(\"\\nTWe also have:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) &=& E_\\\\pi[G_t | S=s_t] \\\\\\\\\\nQ^\\\\pi(s_t,a_t) &=& E_\\\\pi[G_t|S=s_t, A=a_t]\\n\\\\end{eqnarray}\\n$$\\nIn which:\"),_c('br'),_vm._v(\"\\n$G_t=\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+1}$: sum of all reward will be received from state $s_t$ to the future, with $\\\\gamma$ called discount factor: $0 < \\\\gamma < 1$. The farther into the future, the reward will be discounted more, agent cares more about incoming rewards than far future rewards.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)Q^\\\\pi(s,a)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nGradient of the objective function shows that the agent will do more action $a$ if it receives a high $Q^\\\\pi(s,a)$. Assuming that the agent is at state $s$, the fact that it is at state $s$ is already good for the agent, executing any action $a$ will give back a high $Q^\\\\pi(s,a)$ so it cannot discriminate its actions $a$ and from there, it does not know which action  $a$ is optimal. Therefore, we need a baseline to compare the value of $Q^\\\\pi(s,a)$.\"),_c('br'),_vm._v(\"\\nAs in the part 4, we have $V^\\\\pi(s)$ is the expectation of accumulative reward at state $s$, no matter what action the agent will take at state $s$, we expect an accumulative reward $V^\\\\pi(s)$ from there to the end.\\nTherefore, an action $a_m$ is bad if $Q^\\\\pi(s,a_m)$ < $V^\\\\pi(s)$ and an action $a_n$ is good if $Q^\\\\pi(s,a_n)$ > $V^\\\\pi(s)$. From here we have 1 baseline to compare $Q^\\\\pi(s,a)$ which is $V^\\\\pi(s)$. The gradient of objective function now can be written:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)\\\\Big(Q^\\\\pi(s,a)-V^\\\\pi(s)\\\\Big)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"If $Q^\\\\pi(s,a)-V^\\\\pi(s) < 0$, 2 gradients have opposite signs, optimizing the objective function will decrease the probability of executing action $a$ at $s$.\"),_c('br'),_vm._v(\"\\nWe call $A^\\\\pi(s,a)=Q^\\\\pi(s,a)-V^\\\\pi(s)$ is the Advantage of action $a$ at state $s$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Stochastic Actor means the policy $\\\\pi_\\\\theta(a|s)$ is a probability distribution of actions at $s$. We call Stochastic Actor to distinguish it from Deterministic Actor \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"or Deterministic Policy\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" which means the policy is not a probability distribution of actions at $s$, but under $s$ we only execute a deterministic action, in another word, the probability execution of a chosen action $a=\\\\mu_\\\\theta(s)$ under $s$ is 1 and all other actions is 0.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"The objective function depends on 2 things: policy $\\\\pi_\\\\theta$ and value function $V^\\\\pi$. Assuming that we have an approximation function for $V^\\\\pi(s)$ is $V_\\\\phi(s)$ depending on parameters $\\\\phi$.\"),_c('br'),_vm._v(\"\\nWe call the appromixation function for policy $\\\\pi_\\\\theta$ is Actor and the appromixation function for $V_\\\\phi$ is Critic.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Batch Actor-Critic:\"),_c('br'),_vm._v(\"\\n1. Sample a rollout $\\\\tau$ to terminal state by the policy $\\\\pi_\\\\theta$\"),_c('br'),_vm._v(\"\\n2. Fit $V_\\\\phi$ avec $y = \\\\sum_{i}^{T} r_i$\"),_c('br'),_vm._v(\"\\n3. Find $A(s_t,a_t) = r(s_t, a_t) + \\\\gamma V_\\\\phi(s_{t+1}) - V_\\\\phi(s_{t})$\"),_c('br'),_vm._v(\"\\n4. Find $\\\\nabla_\\\\theta J(\\\\theta) = \\\\sum_i \\\\nabla \\\\log \\\\pi_\\\\theta (a_i|s_i) A^\\\\pi (s_i, a_i)$\"),_c('br'),_vm._v(\"\\n5. Update $\\\\theta \\\\leftarrow \\\\theta  + \\\\alpha \\\\nabla_\\\\theta J(\\\\theta)$\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nAbove, we can represent $V_\\\\phi(s) = r + V_\\\\phi(s')$ according to Bellman Equation, therfore we could update the model knowing only 1 step ahead.\"),_c('br'),_vm._v(\"\\nOnline Actor-Critic:\"),_c('br'),_vm._v(\"\\n1. With policy $\\\\pi_\\\\theta$, execute 1 action $a \\\\sim \\\\pi_\\\\theta(a|s)$ to have $(s,a,s',r)$\"),_c('br'),_vm._v(\"\\n2. Fit $V_\\\\phi (s)$ avec $r + V_\\\\phi(s')$\"),_c('br'),_vm._v(\"\\n3. Find $A(s_t,a_t) = r(s_t, a_t) + \\\\gamma V_\\\\phi(s_{t+1}) - V_\\\\phi(s_{t})$\"),_c('br'),_vm._v(\"\\n4. Find $\\\\nabla_\\\\theta J(\\\\theta) = \\\\sum_i \\\\nabla \\\\log \\\\pi_\\\\theta (a_i|s_i) A (s_i, a_i)$\"),_c('br'),_vm._v(\"\\n5. Update $\\\\theta \\\\leftarrow \\\\theta  + \\\\alpha \\\\nabla_\\\\theta J(\\\\theta)$\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nThus, we update interatively both approximation functions $V_\\\\phi$ and $\\\\pi_\\\\theta$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Examine a policy as follow:\\n$$\\n\\\\begin{eqnarray}\\n\\\\pi'(a_t|s_t) = 1 \\\\ \\\\text{if}\\\\  a_t = \\\\arg \\\\max_{a_t} A^\\\\pi(s_t, a_t)\\n\\\\end{eqnarray}\\n$$\\nPolicy $\\\\pi'$ is a Deterministic Policy: given a policy $\\\\pi$ and assuming we know the Advantage of actions at state $s_t$ under policy $\\\\pi$, we always choose the action with the highest Advantage at state $s$, probability of that action is 1, all other actions at $s_t$ is 0.\\nPolicy $\\\\pi'$ will be always better or at least equal to policy $\\\\pi$. A policy is evaluated as equal or better than other if:\\n$V^\\\\pi(s) \\\\leq V^{\\\\pi'} (s) \\\\forall s \\\\in S$ : with all state $s$ in the state space $S$, the return value $V^\\\\pi(s)$ always less than or equal to the return value $V^{\\\\pi'} (s)$.\"),_c('br'),_vm._v(\"\\nFor example, we have: at state $s$, we have 4 ways to go from state $s'$ corresponding to 4 actions and Advantages $A^\\\\pi_1$, $A^\\\\pi_2$, $A^\\\\pi_3$, $A^\\\\pi_4$. From state $s'$, we continue to follow policy $\\\\pi$. From $s$ to $s'$, if we choose to follow stochastic policy $\\\\pi$, expected Advantage is $\\\\sum_{a \\\\in A} p(a)A^\\\\pi_a$, this quantity must be less than or equal to $\\\\max_a A^\\\\pi_a$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{attrs:{\"src\":\"https://i.imgur.com/yMtTahR.jpg\",\"align\":\"center\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Image 4: Transition from state $s$ to $s'$.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"But evaluating $A^\\\\pi(s,a)$ is also equivalent to evaluate $Q^\\\\pi(s,a)$ because $A^\\\\pi(s,a) =  Q^\\\\pi(s,a) - V^\\\\pi(s) = r(s,a)  + \\\\gamma V^\\\\pi(s') - V^\\\\pi(s)$, and the quantity $V^\\\\pi(s)$ is the same for different actions $a$ at state $s$.\"),_c('br'),_vm._v(\"\\nThe algorithm now becomes:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate $Q^\\\\pi(s,a) \\\\leftarrow r(s,a)  + \\\\gamma V^\\\\pi(s') $ with different actions $a$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Optimize $\\\\pi \\\\leftarrow \\\\pi'$ : choose the action with highest $A$, it is also highest $Q$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate $Q^\\\\pi(s,a) \\\\leftarrow r(s,a)  + \\\\gamma V^\\\\pi(s') $ for different actions $a$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$V^\\\\pi(s) \\\\leftarrow \\\\max_a Q^\\\\pi(s,a)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate $V^\\\\pi(s) \\\\leftarrow \\\\max_a \\\\big(r(s,a)  + \\\\gamma V^\\\\pi(s')\\\\big)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\arg min_\\\\phi \\\\big(V^\\\\pi(s) - V_\\\\phi(s)\\\\big)^2$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma \\\\max_{a'} Q_\\\\phi(s', a') $\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\arg min_\\\\phi \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)^2$ $(*)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"This is the Q-Learning algorithm. Notice that, reward $r$ above is not dependent on the state transition and on the policy $\\\\pi$ used to generate the sample, therefore we only need the sample $(s, a, r, s')$ to improve the policy without knowing that sample is generated from which policy. Because of this reason, we call it off-policy. Later, we will have on-policy algorithms and they need the new samples generated by the current policy to improve itself \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"cannot use experience from history\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\".\\nWe have the Online Q-Learning as follow:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate action $a$ to have $(s, a, s', r)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Evaluate $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma max_{a'} Q_\\\\phi(s', a') $\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\phi - \\\\alpha \\\\frac{dQ_\\\\phi}{d\\\\phi}(s,a) \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Notice in the step 3, is it the gradient descent as same as where I marked $(*)$ above? The answer is no, in fact, we ignore the derivative of $y_i$ by $\\\\phi$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"$y_i$ also depends on $\\\\phi$\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\". As a consequence, everytime we update $\\\\phi$ with this algorithm, the value of the target $y_i$ is also changed! The target changes when we try to get closer, this makes the algorithm becomes unstable.\"),_c('br'),_vm._v(\"\\nTo solve this, we need another approximation function called target network, different from the train network we use to run. Target network will be update slowly and is used to evaluate $y$.\"),_c('br'),_vm._v(\"\\nAnother problem is that samples are generated continuously so they are correlated. The algorithm above is similar as Supervised Learning - we map a Q-value with a target, we want the samples are independent and identically distributed \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"i.i.d\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\". To break the correlation between samples, we could use an experience buffer: a list containing many samples from different episodes and we choose randomly a batch from the buffer and train our agent on that batch.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_vm._v(\"A separated target network called $Q_{\\\\phi'}$.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Experience buffer.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Execute action $a_i$ to have $(s_i, a_i, s_i', r_i)$ and put it into the buffer.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Sample randomly a batch $N$ samples from the buffer $(s_i, a_i, s_i', r_i)$.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Evaluate $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma max_{a'} Q_{\\\\phi'}(s', a')$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"using target network here\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")])]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\phi - \\\\alpha \\\\frac{1}{N}\\\\sum_i^N \\\\frac{dQ_\\\\phi}{d\\\\phi}(s,a_i) \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Update target network $\\\\phi' \\\\leftarrow (1-\\\\tau)\\\\phi' + \\\\tau \\\\phi$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"using $\\\\tau %$ of new train network to update target network\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nThis algorithm is Deep Q-Network \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"DQN\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\".\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Deep Deterministic Policy Gradient \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"DDPG\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" has a nice approach, notice that:\\n$$\\n\\\\begin{eqnarray}\\nmax_{a} Q_{\\\\phi}(s, a) = Q_\\\\phi\\\\big(s, \\\\arg max_a Q_\\\\phi(s,a)\\\\big)\\n\\\\end{eqnarray}\\n$$\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Execute action $a_i$ to have $(s_i, a_i, s_i', r_i)$ and put it into the buffer.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Sample a batch of $N$ samples from the buffer $(s_i, a_i, s_i', r_i)$.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Evaluate $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma Q_{\\\\phi'}\\\\big(s', \\\\mu_{\\\\theta'}(s')\\\\big)$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"use both policy and Q target network here\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")])]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\phi - \\\\alpha \\\\frac{1}{N}\\\\sum_i^N \\\\frac{dQ_\\\\phi}{d\\\\phi}(s,a_i) \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\theta \\\\leftarrow \\\\theta - \\\\beta \\\\frac{1}{N}\\\\sum_i^N \\\\frac{d\\\\mu_\\\\theta}{d\\\\theta}(s) \\\\frac{dQ_\\\\phi}{da}(s, a_i)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Update target network $\\\\phi' \\\\leftarrow (1-\\\\tau)\\\\phi' + \\\\tau \\\\phi$ and $\\\\theta' \\\\leftarrow (1-\\\\tau)\\\\theta' + \\\\tau \\\\theta$\\n\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nNotice in the  DDPG implementation:\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_vm._v(\"Because actions in DDPG are always deterministic, thus to explore the environment \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"we do not want the agent always exploit the best trajectory in its knowledge, there may be a better path out there\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\", a small action noise will be added into the action from the agent.\\nThe noise in the \"),_c('a',{attrs:{\"href\":\"https://arxiv.org/abs/1509.02971\"}},[_vm._v(\"original paper\")]),_vm._v(\" is a stochastic process named OrnsteinUhlenbeck process \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"OU process\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\". The authors choosed this process because the experiments gave good result, however other experiments conducted by different groups showing that other noise such as Gaussian Noise give the same performance.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Implementation of action noise in the library \"),_c('a',{attrs:{\"href\":\"https://github.com/keras-rl/keras-rl\"}},[_vm._v(\"keras-rl\")]),_vm._v(\" is OU process, however when I run, this noise is not decayed w.r.t time. Hoever, we need a big noise at the beginning \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"to explore the environment\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" and decrease after many episodes. This can be done if before we add the noise to the action, we multiply it with a quantity epsilon and the epsilon decays to 0 w.r.t time.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Besides adding noise into the action before executing it on the environment, they also add Gaussian Noise on the node of Neural Network. Reference paper \"),_c('a',{attrs:{\"href\":\"https://openai.com/blog/better-exploration-with-parameter-noise/\"}},[_vm._v(\"here\")]),_vm._v(\". You could find the implementation o actor network noise in this library \"),_c('a',{attrs:{\"href\":\"https://stable-baselines.readthedocs.io/en/master/modules/ddpg.html#action-and-parameters-noise\"}},[_vm._v(\"stable baselines\")]),_vm._v(\".\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_vm._v(\"Policy Gradient is an on-policy and a stochastic policy.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Q-learning, DQN, DDPG are off-policy and deterministic policies.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Always have a deterministic policy better than a stochastic policy.\")])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-aa19fafe\",\"hasScoped\":false,\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/en/theoricalRL/En1DDPG.md\n// module id = null\n// module chunks = ","var normalizeComponent = require(\"!../../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-aa19fafe\\\",\\\"hasScoped\\\":false,\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../../node_modules/vue-loader/lib/selector?type=template&index=0!../../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./En1DDPG.md\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = null\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/en/theoricalRL/En1DDPG.md\n// module id = null\n// module chunks = ","<template>\n  <div>\n    <nav class=\"navbar is-fixed-top is-light is-bold\">\n        <div class=\"navbar-brand\">\n            <a class=\"navbar-item\" href=\"\">\n                <span class=\"logo\">\n                    Frew<i class=\"fas fa-angle-double-up\" ></i>rd\n                </span>\n            </a>\n            <div class=\"navbar-burger burger\" data-target=\"navbarLanguage\">\n                <span></span>\n                <span></span>\n                <span></span>\n            </div>\n        </div>\n        <div id=\"navbarLanguage\" class=\"navbar-menu\">\n            <div class=\"navbar-start\">\n                <div class=\"navbar-item has-dropdown is-hoverable\">\n                    <a class=\"navbar-link\">\n                        Ngn Ng\n                    </a>\n                    <div class=\"navbar-dropdown is-boxed\">\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/\"><span>Ting Anh</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/vi\"><span>Ting Vit</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/fr\"><span>Ting Php</span></router-link>\n                        </a>\n                    </div>\n                </div>\n            </div>\n            <div class=\"navbar-end\">\n                <div class=\"navbar-item\">\n                    <div class=\"field is-grouped\">\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://github.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-github\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\">\n                                <span class=\"icon\"><i class=\"fab fa-linkedin\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.facebook.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-facebook\"></i></span>\n                            </a>\n                        </p>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </nav>\n    <section class=\"section\">\n      <div class=\"container\">\n        <div class=\"columns\">\n          <div class=\"column is-2 side-nav\">\n            <side-menu></side-menu>\n          </div>\n          <div class=\"column is-10 markdown\">\n            <router-view></router-view>\n          </div>\n        </div>\n      </div>\n    </section>\n\n    <footer class=\"footer\">\n      <div class=\"container\">\n        <div class=\"content has-text-centered\">\n          <p>\n            <strong>Frew<i class=\"fas fa-angle-double-up\" ></i>rd</strong> by <a href=\"https://www.facebook.com/toanngosy/\" target=\"_blank\">Gonaton</a>. M ngun bn quyn\n            <a href=\"http://opensource.org/licenses/mit-license.php\">MIT</a>.\n          </p>\n          <p>\n            <a class=\"icon\" href=\"https://github.com/toanngosy/\">\n              <i class=\"fab fa-github\"></i>\n            </a>\n          </p>\n        </div>\n      </div>\n    </footer>\n  </div>\n</template>\n\n<script>\nimport SideMenu from './ViSideMenu';\nexport default {\n  components: { SideMenu }\n};\n</script>\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n  .logo\n  {\n  font-size: 30px;\n  color: black;\n  }\n  .randomimage\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 200px;\n  color: #D3D3D3;\n  }\n\n  .welcome\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 62.5px;\n  font-weight: bold;\n  color: #D3D3D3;\n  }\n</style>\n\n\n\n// WEBPACK FOOTER //\n// src/components/vi/ViComponents.vue","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',[_c('nav',{staticClass:\"navbar is-fixed-top is-light is-bold\"},[_vm._m(0),_vm._v(\" \"),_c('div',{staticClass:\"navbar-menu\",attrs:{\"id\":\"navbarLanguage\"}},[_c('div',{staticClass:\"navbar-start\"},[_c('div',{staticClass:\"navbar-item has-dropdown is-hoverable\"},[_c('a',{staticClass:\"navbar-link\"},[_vm._v(\"\\n                      Ngn Ng\\n                  \")]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-dropdown is-boxed\"},[_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/\"}},[_c('span',[_vm._v(\"Ting Anh\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/vi\"}},[_c('span',[_vm._v(\"Ting Vit\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/fr\"}},[_c('span',[_vm._v(\"Ting Php\")])])],1)])])]),_vm._v(\" \"),_vm._m(1)])]),_vm._v(\" \"),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-2 side-nav\"},[_c('side-menu')],1),_vm._v(\" \"),_c('div',{staticClass:\"column is-10 markdown\"},[_c('router-view')],1)])])]),_vm._v(\" \"),_vm._m(2)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-brand\"},[_c('a',{staticClass:\"navbar-item\",attrs:{\"href\":\"\"}},[_c('span',{staticClass:\"logo\"},[_vm._v(\"\\n                  Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\\n              \")])]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-burger burger\",attrs:{\"data-target\":\"navbarLanguage\"}},[_c('span'),_vm._v(\" \"),_c('span'),_vm._v(\" \"),_c('span')])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-end\"},[_c('div',{staticClass:\"navbar-item\"},[_c('div',{staticClass:\"field is-grouped\"},[_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-github\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-linkedin\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.facebook.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-facebook\"})])])])])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('footer',{staticClass:\"footer\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"content has-text-centered\"},[_c('p',[_c('strong',[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")]),_vm._v(\" by \"),_c('a',{attrs:{\"href\":\"https://www.facebook.com/toanngosy/\",\"target\":\"_blank\"}},[_vm._v(\"Gonaton\")]),_vm._v(\". M ngun bn quyn\\n          \"),_c('a',{attrs:{\"href\":\"http://opensource.org/licenses/mit-license.php\"}},[_vm._v(\"MIT\")]),_vm._v(\".\\n        \")]),_vm._v(\" \"),_c('p',[_c('a',{staticClass:\"icon\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('i',{staticClass:\"fab fa-github\"})])])])])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-f0800906\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/vi/ViComponents.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-f0800906\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../../node_modules/vue-loader/lib/selector?type=styles&index=0!./ViComponents.vue\")\n}\nvar normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nexport * from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./ViComponents.vue\"\nimport __vue_script__ from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./ViComponents.vue\"\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-f0800906\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./ViComponents.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-f0800906\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/vi/ViComponents.vue\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',[_c('h1',[_vm._v(\"Introduction\")]),_vm._v(\" \"),_c('p',[_vm._v(\" ct des dveloppements de Computer Vision, Natural Language Processing,\\nReinforcement Learning a galement obtenu des rsultats surprenants\\nces dernires annes et reu beaucoup d'attention.\\nCependant, les tutoriels trouvs en ligne sacclrent\\nsouvent jusqu la section de codage sans entrer profondment dans les mathmatiques.\\nCe blog est bas sur la lecture du professeur Sergey Levine de lUC Berkeley\\net le livre Introduction to Reinforcement Learning du Professeur Sutton et Barto,\\nVous pouvez trouver le lien pour la lecture\\n\"),_c('a',{attrs:{\"href\":\"http://rail.eecs.berkeley.edu/deeprlcourse/\"}},[_vm._v(\"ici\")]),_vm._v(\"\\net le livre \"),_c('a',{attrs:{\"href\":\"http://incompleteideas.net/book/bookdraft2017nov5.pdf\"}},[_vm._v(\"ici\")]),_vm._v(\".\")]),_vm._v(\" \"),_c('p',[_vm._v(\"This blog will also introduce RL libraries and how to use them.\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"About Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")]),_vm._v(\" \"),_c('p',[_vm._v(\"In RL, reward is important, actions taken by the AI are to\\noptimize the total reward in long-term and constructing a reward function so that it's reasonable\\nis one of the essential conditions for RL algorithms to work. In reality,\\nreward are also important, which is the goal we aim for in life.\\nReward function - \\\\(f(reward)\\\\) - Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd is from here.\\n\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br')]),_vm._v(\" \"),_c('p',{staticStyle:{\"font-size\":\"200%\"},attrs:{\"align\":\"center\"}},[_vm._v(\"In this Freeworld, what is your Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd?\")])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-514578a2\",\"hasScoped\":false,\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/fr/FrIntroduction.md\n// module id = null\n// module chunks = ","var normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-514578a2\\\",\\\"hasScoped\\\":false,\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./FrIntroduction.md\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = null\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/fr/FrIntroduction.md\n// module id = null\n// module chunks = ","module.exports = require(\"!!vue-loader!../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./EnIntroduction.md\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/pages/en/EnIntroduction.md\n// module id = 7ZQQ\n// module chunks = 0","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('aside',{staticClass:\"list-group\"},[_c('ul',[_c('li',[_c('router-link',{staticClass:\"list-group-item\",attrs:{\"to\":\"/\",\"exact\":\"\"}},[_vm._v(\"Li m u\")])],1)]),_vm._v(\" \"),_c('div',{staticClass:\"menu\"},[_c('p',{staticClass:\"menu-label\"},[_vm._v(\"RL c bn\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/vi/theorical/1\",\"exact\":\"\"}},[_vm._v(\"DDPG\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/layout\",\"exact\":\"\"}},[_vm._v(\"TRPO/PPO\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/button\",\"exact\":\"\"}},[_vm._v(\"SAC\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/icon\",\"exact\":\"\"}},[_vm._v(\"Inference\")])],1)]),_vm._v(\" \"),_c('p',{staticClass:\"menu-label\"},[_vm._v(\"RL luyn tp\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/affix\",\"exact\":\"\"}},[_vm._v(\"OpenAI Gym\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/scrollto\",\"exact\":\"\"}},[_vm._v(\"Q-learning\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/breadcrumb\",\"exact\":\"\"}},[_vm._v(\"DDPG\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/breadcrumb\",\"exact\":\"\"}},[_vm._v(\"TRPO/PPO\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/breadcrumb\",\"exact\":\"\"}},[_vm._v(\"SAC\")])],1)]),_vm._v(\" \"),_c('p',{staticClass:\"menu-label\"},[_vm._v(\"Th vin RL\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/alert\",\"exact\":\"\"}},[_vm._v(\"OpenAI baselines\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/aside\",\"exact\":\"\"}},[_vm._v(\"Stable baselines\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/collapse\",\"exact\":\"\"}},[_vm._v(\"Ray/RLLib\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/modal\",\"exact\":\"\"}},[_vm._v(\"Unity ML-Agents\")])],1)]),_vm._v(\" \"),_c('p',{staticClass:\"menu-label\"},[_vm._v(\"ng dng\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/form\",\"exact\":\"\"}},[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd Env\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/form2\",\"exact\":\"\"}},[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd Exp\")])],1)])])])}\nvar staticRenderFns = []\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-2fee8012\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/vi/ViSideMenu.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-2fee8012\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../../node_modules/vue-loader/lib/selector?type=styles&index=0!./ViSideMenu.vue\")\n}\nvar normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-2fee8012\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./ViSideMenu.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-2fee8012\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/vi/ViSideMenu.vue\n// module id = null\n// module chunks = ","module.exports = require(\"!!vue-loader!../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./ViIntroduction.md\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/pages/vi/ViIntroduction.md\n// module id = BVxU\n// module chunks = 0","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('aside',{staticClass:\"list-group\"},[_c('ul',[_c('li',[_c('router-link',{staticClass:\"list-group-item\",attrs:{\"to\":\"/\",\"exact\":\"\"}},[_vm._v(\"Introduction\")])],1)]),_vm._v(\" \"),_c('div',{staticClass:\"menu\"},[_c('p',{staticClass:\"menu-label\"},[_vm._v(\"Theorical RL\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/theorical/1\",\"exact\":\"\"}},[_vm._v(\"DDPG\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/components/layout\",\"exact\":\"\"}},[_vm._v(\"TRPO/PPO\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/components/button\",\"exact\":\"\"}},[_vm._v(\"SAC\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/components/icon\",\"exact\":\"\"}},[_vm._v(\"Inference\")])],1)]),_vm._v(\" \"),_c('p',{staticClass:\"menu-label\"},[_vm._v(\"Practical RL\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/affix\",\"exact\":\"\"}},[_vm._v(\"OpenAI Gym\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/scrollto\",\"exact\":\"\"}},[_vm._v(\"Q-learning\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/breadcrumb\",\"exact\":\"\"}},[_vm._v(\"DDPG\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/breadcrumb\",\"exact\":\"\"}},[_vm._v(\"TRPO/PPO\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/breadcrumb\",\"exact\":\"\"}},[_vm._v(\"SAC\")])],1)]),_vm._v(\" \"),_c('p',{staticClass:\"menu-label\"},[_vm._v(\"Library Review\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/alert\",\"exact\":\"\"}},[_vm._v(\"OpenAI baselines\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/aside\",\"exact\":\"\"}},[_vm._v(\"Stable baselines\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/collapse\",\"exact\":\"\"}},[_vm._v(\"Ray/RLLib\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/modal\",\"exact\":\"\"}},[_vm._v(\"Unity ML-Agents\")])],1)]),_vm._v(\" \"),_c('p',{staticClass:\"menu-label\"},[_vm._v(\"Application\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/form\",\"exact\":\"\"}},[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd Env\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/form2\",\"exact\":\"\"}},[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd Exp\")])],1)])])])}\nvar staticRenderFns = []\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-7817a196\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/en/EnSideMenu.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-7817a196\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../../node_modules/vue-loader/lib/selector?type=styles&index=0!./EnSideMenu.vue\")\n}\nvar normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-7817a196\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./EnSideMenu.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-7817a196\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/en/EnSideMenu.vue\n// module id = null\n// module chunks = ","<template>\n  <div>\n    <nav class=\"navbar is-fixed-top is-light is-bold\">\n        <div class=\"navbar-brand\">\n            <a class=\"navbar-item\" href=\"\">\n                <span class=\"logo\">\n                    Frew<i class=\"fas fa-angle-double-up\" ></i>rd\n                </span>\n            </a>\n            <div class=\"navbar-burger burger\" data-target=\"navbarLanguage\">\n                <span></span>\n                <span></span>\n                <span></span>\n            </div>\n        </div>\n        <div id=\"navbarLanguage\" class=\"navbar-menu\">\n            <div class=\"navbar-start\">\n                <div class=\"navbar-item has-dropdown is-hoverable\">\n                    <a class=\"navbar-link\">\n                        Langue\n                    </a>\n                    <div class=\"navbar-dropdown is-boxed\">\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/\"><span>Anglais</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/vi\"><span>Vietnamien</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/fr\"><span>Franais</span></router-link>\n                        </a>\n                    </div>\n                </div>\n            </div>\n            <div class=\"navbar-end\">\n                <div class=\"navbar-item\">\n                    <div class=\"field is-grouped\">\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://github.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-github\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\">\n                                <span class=\"icon\"><i class=\"fab fa-linkedin\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.facebook.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-facebook\"></i></span>\n                            </a>\n                        </p>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </nav>\n    <section class=\"hero is-dark is-medium\">\n        <div class=\"hero-body\">\n            <div class=\"container\">\n                <span class=\"randomimage\"><i class=\"fas fa-brain\" ></i></span>\n                <span class=\"welcome\">Bienvenue  Frew<i class=\"fas fa-angle-double-up\" ></i>rd</span>\n            </div>\n        </div>\n    </section>\n    <section class=\"section\">\n      <div class=\"container\">\n        <div class=\"columns\">\n          <div class=\"column is-2 side-nav\">\n            <side-menu></side-menu>\n          </div>\n          <div class=\"column is-10 markdown\">\n            <router-view></router-view>\n          </div>\n        </div>\n      </div>\n    </section>\n\n    <footer class=\"footer\">\n      <div class=\"container\">\n        <div class=\"content has-text-centered\">\n          <p>\n            <strong>Frew<i class=\"fas fa-angle-double-up\" ></i>rd</strong> par <a href=\"https://www.facebook.com/toanngosy/\" target=\"_blank\">Gonaton</a>. Le code source est sous licence\n            <a href=\"http://opensource.org/licenses/mit-license.php\">MIT</a>.\n          </p>\n          <p>\n            <a class=\"icon\" href=\"https://github.com/toanngosy/\">\n              <i class=\"fab fa-github\"></i>\n            </a>\n          </p>\n        </div>\n      </div>\n    </footer>\n  </div>\n</template>\n\n<script>\nimport SideMenu from './FrSideMenu';\nexport default {\n  components: { SideMenu },\n};\n</script>\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n  .logo\n  {\n  font-size: 30px;\n  color: black;\n  }\n  .randomimage\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 200px;\n  color: #D3D3D3;\n  }\n\n  .welcome\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 62.5px;\n  font-weight: bold;\n  color: #D3D3D3;\n  }\n</style>\n\n\n\n// WEBPACK FOOTER //\n// src/components/fr/FrIndex.vue","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',[_c('nav',{staticClass:\"navbar is-fixed-top is-light is-bold\"},[_vm._m(0),_vm._v(\" \"),_c('div',{staticClass:\"navbar-menu\",attrs:{\"id\":\"navbarLanguage\"}},[_c('div',{staticClass:\"navbar-start\"},[_c('div',{staticClass:\"navbar-item has-dropdown is-hoverable\"},[_c('a',{staticClass:\"navbar-link\"},[_vm._v(\"\\n                      Langue\\n                  \")]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-dropdown is-boxed\"},[_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/\"}},[_c('span',[_vm._v(\"Anglais\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/vi\"}},[_c('span',[_vm._v(\"Vietnamien\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/fr\"}},[_c('span',[_vm._v(\"Franais\")])])],1)])])]),_vm._v(\" \"),_vm._m(1)])]),_vm._v(\" \"),_vm._m(2),_vm._v(\" \"),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-2 side-nav\"},[_c('side-menu')],1),_vm._v(\" \"),_c('div',{staticClass:\"column is-10 markdown\"},[_c('router-view')],1)])])]),_vm._v(\" \"),_vm._m(3)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-brand\"},[_c('a',{staticClass:\"navbar-item\",attrs:{\"href\":\"\"}},[_c('span',{staticClass:\"logo\"},[_vm._v(\"\\n                  Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\\n              \")])]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-burger burger\",attrs:{\"data-target\":\"navbarLanguage\"}},[_c('span'),_vm._v(\" \"),_c('span'),_vm._v(\" \"),_c('span')])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-end\"},[_c('div',{staticClass:\"navbar-item\"},[_c('div',{staticClass:\"field is-grouped\"},[_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-github\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-linkedin\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.facebook.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-facebook\"})])])])])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',{staticClass:\"hero is-dark is-medium\"},[_c('div',{staticClass:\"hero-body\"},[_c('div',{staticClass:\"container\"},[_c('span',{staticClass:\"randomimage\"},[_c('i',{staticClass:\"fas fa-brain\"})]),_vm._v(\" \"),_c('span',{staticClass:\"welcome\"},[_vm._v(\"Bienvenue  Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")])])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('footer',{staticClass:\"footer\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"content has-text-centered\"},[_c('p',[_c('strong',[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")]),_vm._v(\" par \"),_c('a',{attrs:{\"href\":\"https://www.facebook.com/toanngosy/\",\"target\":\"_blank\"}},[_vm._v(\"Gonaton\")]),_vm._v(\". Le code source est sous licence\\n          \"),_c('a',{attrs:{\"href\":\"http://opensource.org/licenses/mit-license.php\"}},[_vm._v(\"MIT\")]),_vm._v(\".\\n        \")]),_vm._v(\" \"),_c('p',[_c('a',{staticClass:\"icon\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('i',{staticClass:\"fab fa-github\"})])])])])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-6798b13e\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/fr/FrIndex.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-6798b13e\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../../node_modules/vue-loader/lib/selector?type=styles&index=0!./FrIndex.vue\")\n}\nvar normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nexport * from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./FrIndex.vue\"\nimport __vue_script__ from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./FrIndex.vue\"\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-6798b13e\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./FrIndex.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-6798b13e\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/fr/FrIndex.vue\n// module id = null\n// module chunks = ","module.exports = require(\"!!vue-loader!../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./FrIntroduction.md\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/pages/fr/FrIntroduction.md\n// module id = DPxC\n// module chunks = 0","<template>\n  <div>\n    <nav class=\"navbar is-fixed-top is-light is-bold\">\n        <div class=\"navbar-brand\">\n            <a class=\"navbar-item\" href=\"\">\n                <span class=\"logo\">\n                    Frew<i class=\"fas fa-angle-double-up\" ></i>rd\n                </span>\n            </a>\n            <div class=\"navbar-burger burger\" data-target=\"navbarLanguage\">\n                <span></span>\n                <span></span>\n                <span></span>\n            </div>\n        </div>\n        <div id=\"navbarLanguage\" class=\"navbar-menu\">\n            <div class=\"navbar-start\">\n                <div class=\"navbar-item has-dropdown is-hoverable\">\n                    <a class=\"navbar-link\">\n                        Language\n                    </a>\n                    <div class=\"navbar-dropdown is-boxed\">\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/\"><span>English</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/vi\"><span>Vietnamese</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/fr\"><span>French</span></router-link>\n                        </a>\n                    </div>\n                </div>\n            </div>\n            <div class=\"navbar-end\">\n                <div class=\"navbar-item\">\n                    <div class=\"field is-grouped\">\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://github.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-github\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\">\n                                <span class=\"icon\"><i class=\"fab fa-linkedin\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.facebook.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-facebook\"></i></span>\n                            </a>\n                        </p>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </nav>\n\n    <section class=\"hero is-dark is-medium\">\n        <div class=\"hero-body\">\n            <div class=\"container\">\n                <span class=\"randomimage\"><i class=\"fas fa-brain\" ></i></span>\n                <span class=\"welcome\">Welcome to Frew<i class=\"fas fa-angle-double-up\" ></i>rd</span>\n            </div>\n        </div>\n    </section>\n\n    <section class=\"section\">\n      <div class=\"container\">\n        <div class=\"columns\">\n          <div class=\"column is-2 side-nav\">\n            <side-menu></side-menu>\n          </div>\n          <div class=\"column is-10 markdown\">\n            <router-view></router-view>\n          </div>\n        </div>\n      </div>\n    </section>\n\n    <footer class=\"footer\">\n      <div class=\"container\">\n        <div class=\"content has-text-centered\">\n          <p>\n            <strong>Frew<i class=\"fas fa-angle-double-up\" ></i>rd</strong> by <a href=\"https://www.facebook.com/toanngosy/\" target=\"_blank\">Gonaton</a>. The source code is licensed\n            <a href=\"http://opensource.org/licenses/mit-license.php\">MIT</a>.\n          </p>\n          <p>\n            <a class=\"icon\" href=\"https://github.com/toanngosy/\">\n              <i class=\"fab fa-github\"></i>\n            </a>\n          </p>\n        </div>\n      </div>\n    </footer>\n  </div>\n</template>\n\n<!---------------------------------------------------------------->\n<script>\nimport SideMenu from './EnSideMenu';\nexport default {\n  components: { SideMenu },\n};\n</script>\n\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n  .logo\n  {\n  font-size: 30px;\n  color: black;\n  }\n  .randomimage\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 200px;\n  color: #D3D3D3;\n  }\n\n  .welcome\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 62.5px;\n  font-weight: bold;\n  color: #D3D3D3;\n  }\n</style>\n\n\n\n\n// WEBPACK FOOTER //\n// src/components/en/EnIndex.vue","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',[_c('nav',{staticClass:\"navbar is-fixed-top is-light is-bold\"},[_vm._m(0),_vm._v(\" \"),_c('div',{staticClass:\"navbar-menu\",attrs:{\"id\":\"navbarLanguage\"}},[_c('div',{staticClass:\"navbar-start\"},[_c('div',{staticClass:\"navbar-item has-dropdown is-hoverable\"},[_c('a',{staticClass:\"navbar-link\"},[_vm._v(\"\\n                      Language\\n                  \")]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-dropdown is-boxed\"},[_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/\"}},[_c('span',[_vm._v(\"English\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/vi\"}},[_c('span',[_vm._v(\"Vietnamese\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/fr\"}},[_c('span',[_vm._v(\"French\")])])],1)])])]),_vm._v(\" \"),_vm._m(1)])]),_vm._v(\" \"),_vm._m(2),_vm._v(\" \"),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-2 side-nav\"},[_c('side-menu')],1),_vm._v(\" \"),_c('div',{staticClass:\"column is-10 markdown\"},[_c('router-view')],1)])])]),_vm._v(\" \"),_vm._m(3)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-brand\"},[_c('a',{staticClass:\"navbar-item\",attrs:{\"href\":\"\"}},[_c('span',{staticClass:\"logo\"},[_vm._v(\"\\n                  Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\\n              \")])]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-burger burger\",attrs:{\"data-target\":\"navbarLanguage\"}},[_c('span'),_vm._v(\" \"),_c('span'),_vm._v(\" \"),_c('span')])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-end\"},[_c('div',{staticClass:\"navbar-item\"},[_c('div',{staticClass:\"field is-grouped\"},[_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-github\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-linkedin\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.facebook.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-facebook\"})])])])])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',{staticClass:\"hero is-dark is-medium\"},[_c('div',{staticClass:\"hero-body\"},[_c('div',{staticClass:\"container\"},[_c('span',{staticClass:\"randomimage\"},[_c('i',{staticClass:\"fas fa-brain\"})]),_vm._v(\" \"),_c('span',{staticClass:\"welcome\"},[_vm._v(\"Welcome to Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")])])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('footer',{staticClass:\"footer\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"content has-text-centered\"},[_c('p',[_c('strong',[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")]),_vm._v(\" by \"),_c('a',{attrs:{\"href\":\"https://www.facebook.com/toanngosy/\",\"target\":\"_blank\"}},[_vm._v(\"Gonaton\")]),_vm._v(\". The source code is licensed\\n          \"),_c('a',{attrs:{\"href\":\"http://opensource.org/licenses/mit-license.php\"}},[_vm._v(\"MIT\")]),_vm._v(\".\\n        \")]),_vm._v(\" \"),_c('p',[_c('a',{staticClass:\"icon\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('i',{staticClass:\"fab fa-github\"})])])])])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-4bcf43b8\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/en/EnIndex.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-4bcf43b8\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../../node_modules/vue-loader/lib/selector?type=styles&index=0!./EnIndex.vue\")\n}\nvar normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nexport * from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./EnIndex.vue\"\nimport __vue_script__ from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./EnIndex.vue\"\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-4bcf43b8\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./EnIndex.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-4bcf43b8\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/en/EnIndex.vue\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',[_c('h1',[_vm._v(\"Introduction\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Besides the development of Computer Vision, Natural Language Processing,\\nReinforcement Learning also achieved suprising results in recent years\\nand received much attention.\\nHowever, tutorials found online often speed up to coding section without\\ngoing deeply into math.\\nThis blog is based on a lecture given by Professor Sergey Levine of UC Berkeley\\nand the Introduction to Reinforcement Learning book by Professor Sutton and Barto,\\nYou can find the link for the lecture\\n\"),_c('a',{attrs:{\"href\":\"http://rail.eecs.berkeley.edu/deeprlcourse/\"}},[_vm._v(\"here\")]),_vm._v(\"\\nand the book \"),_c('a',{attrs:{\"href\":\"http://incompleteideas.net/book/bookdraft2017nov5.pdf\"}},[_vm._v(\"here\")]),_vm._v(\".\")]),_vm._v(\" \"),_c('p',[_vm._v(\"This blog will also introduce RL libraries and how to use them.\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"About Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")]),_vm._v(\" \"),_c('p',[_vm._v(\"In RL, reward is important, actions taken by the AI are to\\noptimize the total reward in long-term and constructing a reward function so that it's reasonable\\nis one of the essential conditions for RL algorithms to work. In reality,\\nreward are also important, which is the goal we aim for in life.\\nReward function - \\\\(f(reward)\\\\) - Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd is from here.\\n\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br')]),_vm._v(\" \"),_c('p',{staticStyle:{\"font-size\":\"200%\"},attrs:{\"align\":\"center\"}},[_vm._v(\"In this Freeworld, what is your Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd?\")])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-7b59d2b0\",\"hasScoped\":false,\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/en/EnIntroduction.md\n// module id = null\n// module chunks = ","var normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-7b59d2b0\\\",\\\"hasScoped\\\":false,\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./EnIntroduction.md\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = null\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/en/EnIntroduction.md\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',[_c('p',[_c('vue-mathjax')],1),_vm._v(\" \"),_c('h1',[_vm._v(\"I - Reinforcement Learning - from Policy Gradient to Deep Deterministic Policy Gradient\")]),_vm._v(\" \"),_vm._m(0),_vm._v(\" \"),_vm._m(1),_vm._v(\" \"),_c('p',[_vm._v(\"Voici les dfinitions des termes communs en RL:\")]),_vm._v(\" \"),_vm._m(2),_vm._v(\" \"),_vm._m(3),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('p',[_vm._v(\"Dans un tat $s$, l'agent interagit avec l'environnement par l'action $a$,\\nconduisant  un nouvel tat $ s_{t+1}$ et recevez une rcompense $r_{t+1}$.\\nLa boucle se rpte ainsi jusqu' ce que l'tat final atteigne $s_T$.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Dans la section ci-dessous, je vais utiliser les termes Anglais  suivre au lieu de traduire en Franais.\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"1 - Example\")]),_vm._v(\" \"),_vm._m(4),_vm._v(\" \"),_vm._m(5),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_vm._m(6),_vm._v(\" \"),_c('h1',[_vm._v(\"2 - Policy Gradient\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Pour un exemple vivant, nous examinons un problme de jeu simple, le jeu Hare Egg.\")]),_vm._v(\" \"),_vm._m(7),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('p',[_vm._v(\"Soit $\\\\pi_\\\\theta(a|s) = f(s, \\\\theta)$ est le policy de l'agent, c'est une distribution de probabilit d'action $a$  l'tat $s$.\")]),_vm._v(\" \"),_vm._m(8),_vm._v(\" \"),_c('p',[_vm._v(\"Soit $\\\\tau = s_1, a_1, s_2, a_2,..., s_T, a_T$ est la squence de l'tat $s_1$   l'tat $s_T$. La probabilit de $\\\\tau$ est susceptible de se produire:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"[\\n\\\\begin{eqnarray}\\np_\\\\theta(\\\\tau) &=& p_\\\\theta(s_1, a_1, s_2, a_2,...s_T, a_T) \\\\\\\\\\n&=& p(s_1)\\\\pi_\\\\theta(a_1|s_1)p(s_2|s_1, a_1)\\\\pi_\\\\theta(a_2|s_2)...p(s_{T}|s_{T-1},a_{T-1})\\\\pi_\\\\theta(a_T|s_T) \\\\\\\\\\n&=& p(s_1)\\\\Pi_{t=1}^{t=T}\\\\pi_\\\\theta(a_t|s_t)p(s_{t+1}|s_t, a_t) \\\\\\\\\\n\\\\end{eqnarray}\\n]\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Nous verrons que la distribution de probabilit de l'tat $p(s_{t+1}|a_t, s_t)$ sera limine plus tard.\")]),_vm._v(\" \"),_vm._m(9),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\theta^* &=& \\\\arg\\\\max_\\\\theta E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\big[r(\\\\tau)\\\\big] \\\\\\\\\\n&=& \\\\arg\\\\max_\\\\theta E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(10),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nJ(\\\\theta) &=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg] \\\\\\\\\\n&=& \\\\frac{1}{N} \\\\sum_i\\\\sum_t r(a_t, s_t)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(11),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nJ(\\\\theta) &=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg] \\\\\\\\\\n&=& \\\\int p_\\\\theta(\\\\tau) r(\\\\tau) dr\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Continuant  examiner le gradient de la fonction objectif:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg] \\\\\\\\\\n&=& \\\\int \\\\nabla_\\\\theta p_\\\\theta(\\\\tau) r(\\\\tau) dr\\n\\\\end{eqnarray}\\n$$\\nMais nous avons aussi:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta p_\\\\theta(\\\\tau) &=&  p_\\\\theta(\\\\tau) \\\\frac{\\\\nabla_\\\\theta p_\\\\theta(\\\\tau)} {p_\\\\theta(\\\\tau)} \\\\\\\\\\n&=& p_\\\\theta(\\\\tau)\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau)\\n\\\\end{eqnarray}\\n$$\\n** Notez ** que cette trick est utilise souvant, donc:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=& \\\\int p_\\\\theta(\\\\tau) \\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) r(\\\\tau) dr \\\\\\\\\\n&=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) r(\\\\tau)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Examinons de plus sur $\\\\log p_\\\\theta(\\\\tau)$, comme nous l'avons vu plus haut  $p_\\\\theta(\\\\tau) = p(s_1)\\\\Pi_{t=1}^{t=T}\\\\pi_\\\\theta(a_t|s_t)p(s_{t+1}|s_t, a_t)$, nous avons:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\log p_\\\\theta(\\\\tau) = \\\\log p(s_1) + \\\\sum_{t=1}^{t=T}\\\\log \\\\pi_\\\\theta(a_t|s_t) + \\\\sum_{t=1}^{t=T}\\\\log p(s_{t+1}|s_t, a_t)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Finalement:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) = \\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_t|s_t)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(12),_vm._v(\" \"),_c('p',[_vm._v(\"Le gradient de la fonction objectif devient maintenant:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=&  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) r(\\\\tau)\\\\bigg] \\\\\\\\\\n&=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a_t|s_t)\\\\sum_{t=1}^{t=T} r(a_t, s_t)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"De mme, aprs avoir pass $N$ pisodes , l'expectation de ce gradient est la suivante:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=& \\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\bigg(\\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_{i,t}|s_{i,t})\\\\bigg)\\\\bigg(\\\\sum_{t=1}^{t=T} r(a_{i,t}, s_{i,t})\\\\bigg)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Enfin, mettre  jour $\\\\theta$ en utilisant un gradient ascendant:\\n$$\\n\\\\begin{eqnarray}\\n\\\\theta \\\\leftarrow \\\\theta + \\\\nabla_\\\\theta J(\\\\theta)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"3 - L'algorithme REINFORCE\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Rsumez tous les rsultats ci-dessus, nous avons l'algorithme REINFORCE comme ci-dessous:\")]),_vm._v(\" \"),_vm._m(13),_vm._v(\" \"),_c('p',[_vm._v(\"Maintenant, on se pauser pour regarder de plus sur le gradient de la fonction objectif. crivez sous une forme simple, nous avons:\")]),_vm._v(\" \"),_vm._m(14),_vm._v(\" \"),_c('h1',[_vm._v(\"4 - Quelques nouvelles dfinitions\")]),_vm._v(\" \"),_vm._m(15),_vm._v(\" \"),_c('p',[_vm._v(\"$G_t=\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+1}$: la somme de toutes les rcompenses sera reue de l'tat $s_t$  l'avenir, avec le facteur de remise $\\\\gamma$: $0 < \\\\gamma < 1$. Plus loin dans le futur, la reward sera moins prise en compte, l'agent concerne les rewards plus approches que des rewards lointaines.\")]),_vm._v(\" \"),_c('h2',[_vm._v(\"4.1 - Les quations de Bellman\")]),_vm._v(\" \"),_c('p',[_vm._v(\"De la formule ci-dessus, nous avons:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) &=& E_\\\\pi\\\\bigg[G_t|S=s_t\\\\bigg] \\\\\\\\\\n&=& E_\\\\pi\\\\bigg[\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+1}|S=s_t\\\\bigg] \\\\\\\\\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Prenez la rcompense $R_{t+1}$ reue lorsque il passe de l'tat $s_t$  $s_{t+1}$ en dehors de $\\\\sum$, nous obtenons:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nE_\\\\pi\\\\bigg[R_{t+1} + \\\\gamma\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+2}|S=s_t\\\\bigg] &=& E_\\\\pi[R_{t+1}|S=s_t] + \\\\gamma E_\\\\pi\\\\bigg[\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+2}|S=s_t\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Dveloppez les 2 xpectations de l'quation ci-dessus, nous avons:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nE_\\\\pi\\\\bigg[R_{t+1}|S=s_t\\\\bigg]=\\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)R(s_{t+1}|s_t, a)\\n\\\\end{eqnarray}\\n$$\\nMais:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\gamma E_\\\\pi\\\\bigg[\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+2}|S=s_t\\\\bigg] = \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\gamma E_\\\\pi\\\\bigg[\\\\sum^\\\\infty_{k=0} \\\\gamma^k R_{t+k+2} | S = s_{t+1}\\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nNous avons:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) = \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\Bigg[R(s_{t+1}|s_t, a) + \\\\gamma E_\\\\pi\\\\bigg[\\\\sum^\\\\infty_{k=0} \\\\gamma^k R_{t+k+2} | S = s_{t+1} \\\\bigg]\\\\Bigg]\\n\\\\end{eqnarray}\\n$$\\nRemarquerez que:\\n$$\\n\\\\begin{eqnarray}\\nE_\\\\pi\\\\bigg[\\\\sum^\\\\infty_{k=0} \\\\gamma^k R_{t+k+2} | S = s_{t+1}\\\\bigg] = V^\\\\pi(s_{t+1})\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Enfin nous avons:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) = \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\bigg[R(s_{t+1}|s_t, a) + \\\\gamma  V^\\\\pi(s_{t+1})\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Faire la mme chose avec $Q^\\\\pi(s_t, a_t)$:\\n$$\\n\\\\begin{eqnarray}\\nQ^\\\\pi(s_t, a_t) = \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\bigg[R(s_{t+1}|s_t, a) + \\\\gamma \\\\sum_{a_{t+1}} \\\\pi(s_{t+1}, a_{t+1}) Q^\\\\pi (s_{t+1}, a_{t+1}) \\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nCombinez avec la relation entre $V^\\\\pi$ and $Q^\\\\pi$ ci-dessus, nous avons:\\n$$\\n\\\\begin{eqnarray}\\n\\\\sum_{a_{t+1}} \\\\pi(s_{t+1}, a_{t+1}) Q^\\\\pi (s_{t+1}, a_{t+1}) = V^\\\\pi(s_{t+1})\\n\\\\end{eqnarray}\\n$$\\nDonc:\\n$$\\n\\\\begin{eqnarray}\\nQ^\\\\pi(s_t, a_t) = \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a_t)\\\\bigg[R(s_{t+1}|s_t, a_t) + \\\\gamma  V^\\\\pi(s_{t+1}) \\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Par consquent, si nous connaissons la valeur  l'tat $ s_ {t + 1} $, nous pouvons facilement calculer la valeur  l'tat $ s_t $. En rsum, nous avons 2 formules ci-dessous:\\nTout ce qui prcde montre que nous pouvons reprsenter la valeur de $Q^\\\\pi$ et $V^\\\\pi$  l'tat $s_t$ avec l'tat $s_{t+1}$. Par consquent, si nous connaissons la valeur  l'tat $s_{t+1}$, nous pouvons facilement calculer la valeur  l'tat $s_t$. En rsum, nous avons 2 formules ci-dessous:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) &=& \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\bigg[R(s_{t+1}|s_t, a) + \\\\gamma  V^\\\\pi(s_{t+1})\\\\bigg] \\\\\\\\\\nQ^\\\\pi(s_t, a_t) &=& \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a_t)\\\\bigg[R(s_{t+1}|s_t, a_t) + \\\\gamma  V^\\\\pi(s_{t+1}) \\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Revenir au gradient de la fonction objectif, nous avons maintenant:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)Q^\\\\pi(s,a)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"5 - Advantage\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)Q^\\\\pi(s,a)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(16),_vm._v(\" \"),_c('p',[_vm._v(\"Comme dans la partie 4, nous avons $V^\\\\pi(s)$ est lattente dune reward accumule  ltat $s$, quelle que soit la dcision prise par lagent  ltat $s$, nous nous attendons  une reward accumule $V^\\\\pi(s)$ de l  la fin.\\nPar consquent, une action $a_m$ est mauvaise si $Q^\\\\pi(s,a_m)$ < $V^\\\\pi(s)$ et une action $a_n$ est bonne si $Q^\\\\pi(s,a_n)$ > $V^\\\\pi(s)$.  partir de\\nl, nous avons un ligne de base pour comparer $Q^\\\\pi(s,a)$ qui est $V^\\\\pi(s)$. Le gradient de la fonction objectif peut maintenant tre crit:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)\\\\Big(Q^\\\\pi(s,a)-V^\\\\pi(s)\\\\Big)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(17),_vm._v(\" \"),_c('h1',[_vm._v(\"6 - Stochastic Actor-Critic\")]),_vm._v(\" \"),_vm._m(18),_vm._v(\" \"),_c('p',[_vm._v(\"Examinez le gradient de la fonction objectif que nous avons ci-dessus:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)\\\\Big(Q^\\\\pi(s,a)-V^\\\\pi(s)\\\\Big)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\" partir de l'quation de Bellman, nous avons la relation entre $Q^\\\\pi$ et $V^\\\\pi$, maintenant la fonction objectif devient:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim \\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)\\\\Big(R + \\\\gamma V^\\\\pi(s_{t+1})- V^\\\\pi(s)\\\\Big)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(19),_vm._v(\" \"),_vm._m(20),_vm._v(\" \"),_c('h1',[_vm._v(\"7 - L'algorithm Actor-Critic\")]),_vm._v(\" \"),_c('p',[_vm._v(\" partir de l'algorithme REINFORCE, nous utilisons maintenant une fonction d'approximation supplmentaire pour la fonction de valeur $V_\\\\phi$, qui change un peu et nous avons:\")]),_vm._v(\" \"),_vm._m(21),_vm._v(\" \"),_c('h1',[_vm._v(\"8 - De Stochastic Actor-Critic  Q-Learning\")]),_vm._v(\" \"),_vm._m(22),_vm._v(\" \"),_vm._m(23),_vm._v(\" \"),_c('br'),_vm._v(\"\\nTherefore, with a policy $\\\\pi$, we always can apply policy $\\\\pi'$ over it to have a new policy equal or better.\"),_c('br'),_vm._v(\"\\nWe now have the algorithm as follow:\"),_c('br'),_vm._v(\"\\n1. Evaluate $A^\\\\pi(s,a)$ with different actions $a$ \"),_c('br'),_vm._v(\"\\n2. Optimize $\\\\pi \\\\leftarrow \\\\pi'$\\n\"),_vm._m(24),_vm._v(\" \"),_vm._m(25),_vm._v(\" \"),_c('p',[_vm._v(\"Now we actually do not need to care about policy anymore, and the second step can be written as:\")]),_vm._v(\" \"),_vm._m(26),_vm._v(\" \"),_c('p',[_vm._v(\"If we use an approximation function for $V_\\\\phi(s)$, we have the following algorithm:\")]),_vm._v(\" \"),_vm._m(27),_vm._v(\" \"),_c('p',[_vm._v(\"This algorithm is not good, in the first step we need to have reward $r(s, a)$ corresponding to different actions $a$, thus we need different simulations at a state $s$. To solve this, we could do the same analysis above with $Q(s,a)$ instead of $V(s)$.\")]),_vm._v(\" \"),_vm._m(28),_vm._v(\" \"),_vm._m(29),_vm._v(\" \"),_vm._m(30),_vm._v(\" \"),_vm._m(31),_vm._v(\" \"),_c('p',[_vm._v(\"To sum up, for the algorithm to be stable, and possibly converge, we need:\")]),_vm._v(\" \"),_vm._m(32),_vm._v(\" \"),_c('p',[_vm._v(\"The algorithm now:\")]),_vm._v(\" \"),_vm._m(33),_vm._v(\" \"),_c('h1',[_vm._v(\"9 - De Deep Q-Network  Deep Deterministic Policy Gradient\")]),_vm._v(\" \"),_c('p',[_vm._v(\"DQN algorithm is succeeded to approximate Q-value, but there is a limitation in step 3: we need to evaluate $Q_{\\\\phi'}$ with all different actions to choose the highest $Q$. With discrete action space such as games, when the set of actions is just up down left right buttons, the number of actions is finite and small, this is possible. However, in continuous action space, for example with action in a range from 0 to 1 we need a different approach.\\nThe first thing we could think of is to discretize the action space into bins, for example from 0 to 1, we could divide it by 5 or 10 bins. Another way is that we sample actions with uniform distribution on the action space and choose the highest $Q(s,a)$ at state $s$.\")]),_vm._v(\" \"),_vm._m(34),_vm._v(\" \"),_c('p',[_vm._v(\"Now, if we add an approximation function $\\\\mu_\\\\theta(s) = \\\\arg max_a Q_\\\\phi(s,a)$, we will have to find $\\\\theta$ in which: $\\\\theta \\\\leftarrow  \\\\arg max_\\\\theta Q_\\\\phi(s,\\\\mu_\\\\theta(s))$. This optimization evaluates the change of $Q_\\\\phi$ w.r.t parameters $\\\\theta$. We could evaluate this change by the chain rule as follow:\\n$\\\\frac{dQ_\\\\phi}{d\\\\theta} = \\\\frac{dQ_\\\\phi}{d\\\\mu} \\\\frac{d\\\\mu}{d\\\\theta}$.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Notice that, $\\\\mu_\\\\theta(s)$ is a Deterministic Policy, therefore this method is called Deep Deterministic Policy Gradient.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"The DDPG algorithm is as follow:\")]),_vm._v(\" \"),_vm._m(35),_vm._v(\" \"),_vm._m(36),_vm._v(\" \"),_c('h1',[_vm._v(\"10 - Conclusion\")]),_vm._v(\" \"),_c('p',[_vm._v(\"To sum up, we went throught the Policy Gradient algorithm to DQN and DDPG.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Take away:\")]),_vm._v(\" \"),_vm._m(37)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Lapprentissage par renforcement est le domaine associ  l'enseignement de machine \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"agent\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" pour bien excuter une tche \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"task\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" en interagissant avec l'environnement \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"environment\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" et recevoir des rcompenses \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"reward\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\".\\nCette faon dapprentissage est trs similaire  la faon dont lhomme apprend en utilisant la mauvaise mthode de test. En prenant l'exemple d'un enfant en hiver, l'enfant aura tendance  se rapprocher du feu \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"car la rcompense est chaleureuse\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\", mais galement le feu est chaud, l'enfant aura tendance  viter de toucher le feu \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"il le brlera\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\".\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Dans l'exemple ci-dessus, la rcompense apparat immdiatement, l'ajustement de l'action est\\nrelativement facile. Cependant, dans des situations plus complexes o les rcompenses sont lointains,\\nla situation devient plus complique. Comment obtenir la plus grande rcompense accumule tout au\\nlong du processus? Les algorithmes d'apprentissage par renforcement \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"RL\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" visent  rsoudre ce problme d'optimisation.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_c('em',[_vm._v(\"Environment\")]),_vm._v(\" : est lespace, le jeu, lenvironnement avec lequel la machine interagit.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Agent\")]),_vm._v(\" : la machine observe l'environnement et gnre une action en consquence.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Policy\")]),_vm._v(\": la rgle que l'agent suit pour obtenir le but.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Reward\")]),_vm._v(\": une rcompense que l'agent a reue de l'environnement pour avoir pris une action.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"State\")]),_vm._v(\" : l'tat de l'environnement observ par l'agent.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Episode\")]),_vm._v(\" : la squence d'tat et d'action jusqu' la fin $s_1,a_1,s_2,a_2,...s_T, a_T$.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Accumulative Reward\")]),_vm._v(\" : la somme de toutes les rcompenses reues d'un pisode.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{attrs:{\"src\":\"https://i.imgur.com/nIUdsIm.jpg\",\"align\":\"center\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Image 1: The interaction loop between agent and environment.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Cet exemple ci-dessous est  partir de openAI Gym, l'environnement nomm\\n\"),_c('a',{attrs:{\"href\":\"https://github.com/openai/gym/wiki/MountainCarContinuous-v0\"}},[_vm._v(\"MountaincontinuousCar-v0\")]),_vm._v(\".\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{staticStyle:{\"padding-bottom\":\"0.5em\"},attrs:{\"src\":\"https://i.imgur.com/yGWmDei.jpg\",\"alt\":\"MountaincontinuousCar-v0\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Image 2: Un rendu de MountaincontinuousCar-v0.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_c('em',[_vm._v(\"Goal\")]),_vm._v(\" : le but de ce jeu est de trouver une policy permettant de contrler la voiture atteignant le drapeau.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Environment\")]),_vm._v(\" : des rampes et des voitures y circulent.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"State\")]),_vm._v(\" : l'tat du vhicule a 2 dimensions, les coordonnes du vhicule sur l'axe $x$ et la vitesse du vhicule au moment de la mesure.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Action\")]),_vm._v(\" : Force applique pour contrler le vhicule, cependant, la force n'est pas assez forte pour pousser immdiatement la voiture au drapeau. La voiture devra faire des va-et-vient pour gagner suffisamment dacclration et obtenir le drapeau.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Reward\")]),_vm._v(\" :  chaque pas que la voiture ne peut obtenir le drapeau, l'agent reoit une reward $r=\\\\frac{-a^2}{10}$,\\net la reward 100 si elle atteint le cible. Alors si l'agent contrle la voiture mais qu'il ne peut pas obtenir le drapeau, l'agent sera puni.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Terminal state\")]),_vm._v(\" : si l'agent obtenir le drapeau ou si le nombre d'tapes dpasse 998 tapes.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{attrs:{\"src\":\"https://laptrinhcuocsong.com/images/game-hung-trung.png\",\"align\":\"center\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Image 3: le jeu Hare Egg.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Dans le jeu Hare Egg, supposons que nous ayons 3 actions: aller  gauche, aller  droite ou rester immobile.\\nCorrespondant  l'tat  ce moment $s$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\" (\")]),_vm._v(\")la position du panier, la position de l'uf tombant contre le panier,\\nla vitesse de chute des ufs...\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\") \")]),_vm._v(\" nous aurons une distribution de probabilit d'action,\\npar exemple $ [0.1, 0.3, 0.5] $. La somme de toutes les probabilits d'action dans l'tat $s$ est $1$, nous avons: $\\\\sum_{a}\\\\pi_\\\\theta(a|s) = 1 $.\\nSoit $p(s_{t + 1} | a_t, s_t)$ la probabilit de distribution du prochain tat lorsque l'agent est  l'tat $s$ et excute une action $a$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_c('strong',[_vm._v(\"Lapprentissage par renforcement vise  trouver des $\\\\theta$ tels que:\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"La formule montre que $\\\\theta^*$ est un ensemble de paramtres tels que l'attente de la reward accumule de nombreux chantillons diffrents $\\\\tau$, que nous collectons par la policy actuelle $\\\\pi_\\\\theta$ est la plus grande. \"),_c('br'),_vm._v(\"\\nAprs $N$ pisodes diffrents, l'agent collecte $N$ chantillons diffrents $\\\\tau$. La fonction objectif devient maintenant:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$J(\\\\theta)$ est la moyenne des rewards accumules des pisodes de $N$.\"),_c('br'),_vm._v(\"\\nNous pouvons galement voir $J(\\\\theta)$ sous la distribution de probabilit $p_\\\\theta(\\\\tau)$ comme ci-dessous:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Ce rsultat est intressant parce que la drive par rapport  \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"w.r.t\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" $\\\\theta$ de la fonction $\\\\log p_\\\\theta(\\\\tau)$ ne dpend plus de la probabilit de transition de ltat $p(s_{t+1}|a_t, s_t)$, il ne dpend que de la distribution de probabilit de laction $a_i$ excute par lagent $s_i$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Collecte $N$ samples {$\\\\tau^i$} with the policy $\\\\pi_\\\\theta$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Calculate gradient: $\\\\nabla_\\\\theta J(\\\\theta) = \\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\bigg(\\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_{i,t}|s_{i,t})\\\\bigg)\\\\bigg(\\\\sum_{t=1}^{t=T} r(a_{i,t}, s_{i,t})\\\\bigg) $\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Update $\\\\theta \\\\leftarrow \\\\theta + \\\\nabla_\\\\theta J(\\\\theta)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) = \\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(\\\\tau_i)r(\\\\tau_i)\\n\\\\end{eqnarray}\\n$$\\nC'est exactement l'estimation du maximum de vraisemblance \"),_c('a',{attrs:{\"href\":\"https://fr.wikipedia.org/wiki/Maximum_de_vraisemblance\"}},[_vm._v(\"EMV\")]),_vm._v(\" multiplie par la reward accumule.\\nOptimiser la fonction objectif signifie galement augmenter la probabilit de suivre les trajectoires $\\\\tau$ qui donnent des reward cumulatives leves.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$V^\\\\pi(s)$: reward cumulative attendue  l'tat $s$ par la policy $\\\\pi$.\"),_c('br'),_vm._v(\"\\n$Q^\\\\pi(s,a)$: rcompense cumulative attendue si excuter l'action $a$  l'tat $s$ par la policy $\\\\pi$.\"),_c('br'),_vm._v(\"\\nLa relation entre $V^\\\\pi(s)$ et $Q^\\\\pi(s,a)$: $V^\\\\pi(s) = \\\\sum_{a \\\\in A}\\\\pi_\\\\theta(s,a)Q^\\\\pi(s,a)$ - cela a du sens parce que $\\\\pi_\\\\theta(s,a)$ est la probabilit de faire une action $a$  ltat $s$.\"),_c('br'),_vm._v(\"\\nNous avons galement:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) &=& E_\\\\pi[G_t | S=s_t] \\\\\\\\\\nQ^\\\\pi(s_t,a_t) &=& E_\\\\pi[G_t|S=s_t, A=a_t]\\n\\\\end{eqnarray}\\n$$\\nDans lequel:\"),_c('br'),_vm._v(\"\\nla somme de toutes les rcompenses sera reue de l'tat $ s_t $  l'avenir, avec le facteur de remise $ \\\\ gamma $ appel: 0 $ <\\\\ gamma <1 $. Plus loin dans le futur, la rcompense sera moins prise en compte, l'agent se soucie davantage des rcompenses entrantes que des rcompenses lointaines.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Le gradient de la fonction objectif indique que l'agent fera plus d'action $a$ s'il reoit un $Q^\\\\pi(s,a)$ lev. En supposant que l'agent est  l'tat $s$, le fait qu'il soit  l'tat $s$ est dj bon pour l'agent, l'excution de toute action $a$ onnera un haut $Q^\\\\pi(s,a)$ il ne peut donc pas discriminer ses actions $a$ et  partir de l, il ne sait pas quelle action $a$ est optimale. Par consquent, nous avons besoin dune base de rfrence pour comparer la valeur de $Q^\\\\pi(s,a)$.\"),_c('br')])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Si $Q^\\\\pi(s,a)-V^\\\\pi(s) < 0$,2 gradients ont des signes opposs, l'optimisation de la fonction objectif rduira la probabilit d'excution de l'action  $a$ et $s$.\"),_c('br'),_vm._v(\"\\nNous appelons $A^\\\\pi(s,a)=Q^\\\\pi(s,a)-V^\\\\pi(s)$ est l'avantage de l'action $a$  l'tat $s$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Stochastic Actor signifie que la policy $\\\\pi_\\\\theta(a|s)$ est une distribution de probabilit d'actions  $s$. Nous appelons Stochastic Actor pour le distinguer de Deterministic Actor \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"ou Deterministic Policy\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" ce qui signifie que la politique n'est pas une distribution de probabilit d'actions  $s$, mais sous $s$ nous n'excutons qu'une action dterministe. En d'autres termes, la probabilit d'excution d'une action choisie $a=\\\\mu_\\\\theta(s)$ sur $s$ vaut 1 et toutes les autres actions valent 0.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"La fonction objectif dpend de 2 choses: la fonction policy et value $ V ^ \\\\ pi $. En supposant que nous ayons une fonction dapproximation pour $ V ^ \\\\ pi (s) $ est $ V_ \\\\ phi (s) $ en fonction des paramtres $ \\\\ phi $. \"),_c('br'),_vm._v(\"\\nNous appelons la fonction d'approbation de la politique $ \\\\ pi_ \\\\ theta $ Actor et la fonction d'appromixation de $ V_ \\\\ phi $ est Critique.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"La fonction objectif dpend de 2 choses: policy $\\\\pi_\\\\theta$ et la function value $V^\\\\pi$. En supposant que nous ayons une fonction dapproximation pour $V^\\\\pi(s)$ is $V_\\\\phi(s)$ en fonction des paramtres $\\\\phi$.\"),_c('br'),_vm._v(\"\\nNous appelons la fonction d'dapproximation de la policy $\\\\pi_\\\\theta$ est Actor  et la fonction d'appromixation de $V_\\\\phi$ est Critic.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Batch Actor-Critic:\"),_c('br'),_vm._v(\"\\n1. Collecte une trajectoire $\\\\tau$  l'tat terminal par la policy $\\\\pi_\\\\theta$\"),_c('br'),_vm._v(\"\\n2. Fit $V_\\\\phi$ avec $y = \\\\sum_{i}^{T} r_i$\"),_c('br'),_vm._v(\"\\n3. Calcul $A(s_t,a_t) = r(s_t, a_t) + \\\\gamma V_\\\\phi(s_{t+1}) - V_\\\\phi(s_{t})$\"),_c('br'),_vm._v(\"\\n4. Calcul $\\\\nabla_\\\\theta J(\\\\theta) = \\\\sum_i \\\\nabla \\\\log \\\\pi_\\\\theta (a_i|s_i) A^\\\\pi (s_i, a_i)$\"),_c('br'),_vm._v(\"\\n5. Update $\\\\theta \\\\leftarrow \\\\theta  + \\\\alpha \\\\nabla_\\\\theta J(\\\\theta)$\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nCi-dessus, nous pouvons reprsenter $V_\\\\phi(s) = r + V_\\\\phi(s')$ selon l'quation de Bellman, Nous pouvons donc mettre  jour le modle en ne sachant qu'une seule tape.\"),_c('br'),_vm._v(\"\\nOnline Actor-Critic:\"),_c('br'),_vm._v(\"\\n1. Avec policy $\\\\pi_\\\\theta$, excutez 1 action $a \\\\sim \\\\pi_\\\\theta(a|s)$ pour avoir $(s,a,s',r)$\"),_c('br'),_vm._v(\"\\n2. Fit $V_\\\\phi (s)$ avec $r + V_\\\\phi(s')$\"),_c('br'),_vm._v(\"\\n3. Trouvez $A(s_t,a_t) = r(s_t, a_t) + \\\\gamma V_\\\\phi(s_{t+1}) - V_\\\\phi(s_{t})$\"),_c('br'),_vm._v(\"\\n4. Trouvez $\\\\nabla_\\\\theta J(\\\\theta) = \\\\sum_i \\\\nabla \\\\log \\\\pi_\\\\theta (a_i|s_i) A (s_i, a_i)$\"),_c('br'),_vm._v(\"\\n5. Mettre  jour $\\\\theta \\\\leftarrow \\\\theta  + \\\\alpha \\\\nabla_\\\\theta J(\\\\theta)$\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nAlors, nous mettons  jour de manire itrative les deux fonctions dapproximation $V_\\\\phi$ et $\\\\pi_\\\\theta$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Examiner une policy comme suit:\\n$$\\n\\\\begin{eqnarray}\\n\\\\pi'(a_t|s_t) = 1 \\\\ \\\\text{if}\\\\  a_t = \\\\arg \\\\max_{a_t} A^\\\\pi(s_t, a_t)\\n\\\\end{eqnarray}\\n$$\\nPolicy $\\\\pi'$ est une Deterministic Policy: tant donn une policy $\\\\pi$ et en supposant que nous connaissons l'avantage des actions  l'tat $s_t$ sous la policy $\\\\pi$, nous choisissons toujours l'action avec le plus grand avantage  l'tat $s$, la probabilit de cette action est 1, toutes les autres actions  $s_t$ sont 0.\\nLa policy $\\\\pi'$ sera toujours meilleure ou au moins gale  la policy $\\\\pi$. Une policy est value gale ou meilleure que les autres si:\\n$V^\\\\pi(s) \\\\leq V^{\\\\pi'} (s) \\\\forall s \\\\in S$ : avec tout l'tat $s$ dans l'espace d'tat $S$, la valeur de retour $V^\\\\pi(s)$ toujours infrieur ou gal  la valeur de retour $V^{\\\\pi'} (s)$.\"),_c('br'),_vm._v(\"\\nPar exemple, nous avons:  l'tat $s$, nous avons 4 faons de passer  l'tat $s'$ correspondant  4 actions et avantages $A^\\\\pi_1$, $A^\\\\pi_2$, $A^\\\\pi_3$, $A^\\\\pi_4$.De l'tat $s'$, nous continuons  suivre la policy $\\\\pi$. De $s$  $s'$, si nous choisissons de suivre la stochastic policy $\\\\pi$,  lavantage expect est de $\\\\sum_{a \\\\in A} p(a)A^\\\\pi_a$, cette quantit doit tre infrieure  ou gal  $\\\\max_a A^\\\\pi_a$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{attrs:{\"src\":\"https://i.imgur.com/yMtTahR.jpg\",\"align\":\"center\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Image 4: Passage de l'tat $s$  $s'$.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"But evaluating $A^\\\\pi(s,a)$ is also equivalent to evaluate $Q^\\\\pi(s,a)$ because $A^\\\\pi(s,a) =  Q^\\\\pi(s,a) - V^\\\\pi(s) = r(s,a)  + \\\\gamma V^\\\\pi(s') - V^\\\\pi(s)$, and the quantity $V^\\\\pi(s)$ is the same for different actions $a$ at state $s$.\"),_c('br'),_vm._v(\"\\nThe algorithm now becomes:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate $Q^\\\\pi(s,a) \\\\leftarrow r(s,a)  + \\\\gamma V^\\\\pi(s') $ vi cc action $a$ khc nhau\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Optimize $\\\\pi \\\\leftarrow \\\\pi'$ : choose the action with highest $A$, it is also highest $Q$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate $Q^\\\\pi(s,a) \\\\leftarrow r(s,a)  + \\\\gamma V^\\\\pi(s') $ for different actions $a$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$V^\\\\pi(s) \\\\leftarrow \\\\max_a Q^\\\\pi(s,a)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate $V^\\\\pi(s) \\\\leftarrow \\\\max_a \\\\big(r(s,a)  + \\\\gamma V^\\\\pi(s')\\\\big)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\arg min_\\\\phi \\\\big(V^\\\\pi(s) - V_\\\\phi(s)\\\\big)^2$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma \\\\max_{a'} Q_\\\\phi(s', a') $\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\arg min_\\\\phi \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)^2$ $(*)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"This is the Q-Learning algorithm. Notice that, reward $r$ above is not dependent on the state transition and on the policy $\\\\pi$ used to generate the sample, therefore we only need the sample $(s, a, r, s')$ to improve the policy without knowing that sample is generated from which policy. Because of this reason, we call it off-policy. Later, we will have on-policy algorithms and they need the new samples generated by the current policy to improve itself \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"cannot use experience from history\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\".\\nWe have the Online Q-Learning as follow:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Evaluate action $a$ to have $(s, a, s', r)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Evaluate $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma max_{a'} Q_\\\\phi(s', a') $\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\phi - \\\\alpha \\\\frac{dQ_\\\\phi}{d\\\\phi}(s,a) \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Notice in the step 3, is it the gradient descent as same as where I marked $(*)$ above? The answer is no, in fact, we ignore the derivative of $y_i$ by $\\\\phi$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"$y_i$ also depends on $\\\\phi$\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\". As a consequence, everytime we update $\\\\phi$ with this algorithm, the value of the target $y_i$ is also changed! The target changes when we try to get closer, this makes the algorithm becomes unstable.\"),_c('br'),_vm._v(\"\\nTo solve this, we need another approximation function called target network, different from the train network we use to run. Target network will be update slowly and is used to evaluate $y$.\"),_c('br'),_vm._v(\"\\nAnother problem is that samples are generated continuously so they are correlated. The algorithm above is similar as Supervised Learning - we map a Q-value with a target, we want the samples are independent and identically distributed \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"i.i.d\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\". To break the correlation between samples, we could use an experience buffer: a list containing many samples from different episodes and we choose randomly a batch from the buffer and train our agent on that batch.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_vm._v(\"A separated target network called $Q_{\\\\phi'}$.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Experience buffer.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Execute action $a_i$ to have $(s_i, a_i, s_i', r_i)$ and put it into the buffer.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Sample randomly a batch $N$ samples from the buffer $(s_i, a_i, s_i', r_i)$.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Evaluate $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma max_{a'} Q_{\\\\phi'}(s', a')$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"using target network here\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")])]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\phi - \\\\alpha \\\\frac{1}{N}\\\\sum_i^N \\\\frac{dQ_\\\\phi}{d\\\\phi}(s,a_i) \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Update target network $\\\\phi' \\\\leftarrow (1-\\\\tau)\\\\phi' + \\\\tau \\\\phi$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"using $\\\\tau %$ of new train network to update target network\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nThis algorithm is Deep Q-Network \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"DQN\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\".\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Deep Deterministic Policy Gradient \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"DDPG\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" has a nice approach, notice that:\\n$$\\n\\\\begin{eqnarray}\\nmax_{a} Q_{\\\\phi}(s, a) = Q_\\\\phi\\\\big(s, \\\\arg max_a Q_\\\\phi(s,a)\\\\big)\\n\\\\end{eqnarray}\\n$$\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Execute action $a_i$ to have $(s_i, a_i, s_i', r_i)$ and put it into the buffer.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Sample a batch of $N$ samples from the buffer $(s_i, a_i, s_i', r_i)$.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Evaluate $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma Q_{\\\\phi'}\\\\big(s', \\\\mu_{\\\\theta'}(s')\\\\big)$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"use both policy v Q target network here\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")])]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\phi - \\\\alpha \\\\frac{1}{N}\\\\sum_i^N \\\\frac{dQ_\\\\phi}{d\\\\phi}(s,a_i) \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\theta \\\\leftarrow \\\\theta - \\\\beta \\\\frac{1}{N}\\\\sum_i^N \\\\frac{d\\\\mu_\\\\theta}{d\\\\theta}(s) \\\\frac{dQ_\\\\phi}{da}(s, a_i)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Update target network $\\\\phi' \\\\leftarrow (1-\\\\tau)\\\\phi' + \\\\tau \\\\phi$ v $\\\\theta' \\\\leftarrow (1-\\\\tau)\\\\theta' + \\\\tau \\\\theta$\\n\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nNotice in the  DDPG implementation:\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_vm._v(\"Because actions in DDPG are always deterministic, thus to explore the environment \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"we do not want the agent always exploit the best trajectory in its knowledge, there may be a better path out there\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\", a small action noise will be added into the action from the agent.\\nThe noise in the \"),_c('a',{attrs:{\"href\":\"https://arxiv.org/abs/1509.02971\"}},[_vm._v(\"original paper\")]),_vm._v(\" is a stochastic process named OrnsteinUhlenbeck process \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"OU process\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\". The authors choosed this process because the experiments gave good result, however other experiments conducted by different groups showing that other noise such as Gaussian Noise give the same performance.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Implementation of action noise in the library \"),_c('a',{attrs:{\"href\":\"https://github.com/keras-rl/keras-rl\"}},[_vm._v(\"keras-rl\")]),_vm._v(\" is OU process, however when I run, this noise is not decayed w.r.t time. Hoever, we need a big noise at the beginning \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"to explore the environment\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" and decrease after many episodes. This can be done if before we add the noise to the action, we multiply it with a quantity epsilon and the epsilon decays to 0 w.r.t time.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Besides adding noise into the action before executing it on the environment, they also add Gaussian Noise on the node of Neural Network. Reference paper \"),_c('a',{attrs:{\"href\":\"https://openai.com/blog/better-exploration-with-parameter-noise/\"}},[_vm._v(\"here\")]),_vm._v(\". You could find the implementation o actor network noise in this library \"),_c('a',{attrs:{\"href\":\"https://stable-baselines.readthedocs.io/en/master/modules/ddpg.html#action-and-parameters-noise\"}},[_vm._v(\"stable baselines\")]),_vm._v(\".\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_vm._v(\"Policy Gradient is an on-policy and a stochastic policy.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Q-learning, DQN, DDPG are off-policy and deterministic policies.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Always have a deterministic policy better than a stochastic policy.\")])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-402fb2c6\",\"hasScoped\":false,\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/fr/theoricalRL/Fr1DDPG.md\n// module id = null\n// module chunks = ","var normalizeComponent = require(\"!../../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-402fb2c6\\\",\\\"hasScoped\\\":false,\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../../node_modules/vue-loader/lib/selector?type=template&index=0!../../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./Fr1DDPG.md\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = null\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/fr/theoricalRL/Fr1DDPG.md\n// module id = null\n// module chunks = ","<template>\n  <div>\n    <nav class=\"navbar is-fixed-top is-light is-bold\">\n        <div class=\"navbar-brand\">\n            <a class=\"navbar-item\" href=\"\">\n                <span class=\"logo\">\n                    Frew<i class=\"fas fa-angle-double-up\" ></i>rd\n                </span>\n            </a>\n            <div class=\"navbar-burger burger\" data-target=\"navbarLanguage\">\n                <span></span>\n                <span></span>\n                <span></span>\n            </div>\n        </div>\n        <div id=\"navbarLanguage\" class=\"navbar-menu\">\n            <div class=\"navbar-start\">\n                <div class=\"navbar-item has-dropdown is-hoverable\">\n                    <a class=\"navbar-link\">\n                        Langue\n                    </a>\n                    <div class=\"navbar-dropdown is-boxed\">\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/\"><span>Anglais</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/vi\"><span>Vietnamien</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/fr\"><span>Franais</span></router-link>\n                        </a>\n                    </div>\n                </div>\n            </div>\n            <div class=\"navbar-end\">\n                <div class=\"navbar-item\">\n                    <div class=\"field is-grouped\">\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://github.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-github\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\">\n                                <span class=\"icon\"><i class=\"fab fa-linkedin\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.facebook.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-facebook\"></i></span>\n                            </a>\n                        </p>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </nav>\n    <section class=\"section\">\n      <div class=\"container\">\n        <div class=\"columns\">\n          <div class=\"column is-2 side-nav\">\n            <side-menu></side-menu>\n          </div>\n          <div class=\"column is-10 markdown\">\n            <router-view></router-view>\n          </div>\n        </div>\n      </div>\n    </section>\n\n    <footer class=\"footer\">\n      <div class=\"container\">\n        <div class=\"content has-text-centered\">\n          <p>\n            <strong>Frew<i class=\"fas fa-angle-double-up\" ></i>rd</strong> par <a href=\"https://www.facebook.com/toanngosy/\" target=\"_blank\">Gonaton</a>. Le code source est sous licence\n            <a href=\"http://opensource.org/licenses/mit-license.php\">MIT</a>.\n          </p>\n          <p>\n            <a class=\"icon\" href=\"https://github.com/toanngosy/\">\n              <i class=\"fab fa-github\"></i>\n            </a>\n          </p>\n        </div>\n      </div>\n    </footer>\n  </div>\n</template>\n\n<script>\nimport SideMenu from './FrSideMenu';\nexport default {\n  components: { SideMenu },\n};\n</script>\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n  .logo\n  {\n  font-size: 30px;\n  color: black;\n  }\n  .randomimage\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 200px;\n  color: #D3D3D3;\n  }\n\n  .welcome\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 62.5px;\n  font-weight: bold;\n  color: #D3D3D3;\n  }\n</style>\n\n\n\n// WEBPACK FOOTER //\n// src/components/fr/FrComponents.vue","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',[_c('nav',{staticClass:\"navbar is-fixed-top is-light is-bold\"},[_vm._m(0),_vm._v(\" \"),_c('div',{staticClass:\"navbar-menu\",attrs:{\"id\":\"navbarLanguage\"}},[_c('div',{staticClass:\"navbar-start\"},[_c('div',{staticClass:\"navbar-item has-dropdown is-hoverable\"},[_c('a',{staticClass:\"navbar-link\"},[_vm._v(\"\\n                      Langue\\n                  \")]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-dropdown is-boxed\"},[_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/\"}},[_c('span',[_vm._v(\"Anglais\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/vi\"}},[_c('span',[_vm._v(\"Vietnamien\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/fr\"}},[_c('span',[_vm._v(\"Franais\")])])],1)])])]),_vm._v(\" \"),_vm._m(1)])]),_vm._v(\" \"),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-2 side-nav\"},[_c('side-menu')],1),_vm._v(\" \"),_c('div',{staticClass:\"column is-10 markdown\"},[_c('router-view')],1)])])]),_vm._v(\" \"),_vm._m(2)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-brand\"},[_c('a',{staticClass:\"navbar-item\",attrs:{\"href\":\"\"}},[_c('span',{staticClass:\"logo\"},[_vm._v(\"\\n                  Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\\n              \")])]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-burger burger\",attrs:{\"data-target\":\"navbarLanguage\"}},[_c('span'),_vm._v(\" \"),_c('span'),_vm._v(\" \"),_c('span')])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-end\"},[_c('div',{staticClass:\"navbar-item\"},[_c('div',{staticClass:\"field is-grouped\"},[_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-github\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-linkedin\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.facebook.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-facebook\"})])])])])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('footer',{staticClass:\"footer\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"content has-text-centered\"},[_c('p',[_c('strong',[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")]),_vm._v(\" par \"),_c('a',{attrs:{\"href\":\"https://www.facebook.com/toanngosy/\",\"target\":\"_blank\"}},[_vm._v(\"Gonaton\")]),_vm._v(\". Le code source est sous licence\\n          \"),_c('a',{attrs:{\"href\":\"http://opensource.org/licenses/mit-license.php\"}},[_vm._v(\"MIT\")]),_vm._v(\".\\n        \")]),_vm._v(\" \"),_c('p',[_c('a',{staticClass:\"icon\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('i',{staticClass:\"fab fa-github\"})])])])])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-3d0ea01e\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/fr/FrComponents.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-3d0ea01e\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../../node_modules/vue-loader/lib/selector?type=styles&index=0!./FrComponents.vue\")\n}\nvar normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nexport * from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./FrComponents.vue\"\nimport __vue_script__ from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./FrComponents.vue\"\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-3d0ea01e\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./FrComponents.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-3d0ea01e\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/fr/FrComponents.vue\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{attrs:{\"id\":\"app\"}},[_c('router-view')],1)}\nvar staticRenderFns = []\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-07bc1184\",\"hasScoped\":false,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/App.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-07bc1184\\\",\\\"scoped\\\":false,\\\"hasInlineConfig\\\":false}!sass-loader?{\\\"sourceMap\\\":true}!../node_modules/vue-loader/lib/selector?type=styles&index=0!./App.vue\")\n}\nvar normalizeComponent = require(\"!../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nexport * from \"!!babel-loader!../node_modules/vue-loader/lib/selector?type=script&index=0!./App.vue\"\nimport __vue_script__ from \"!!babel-loader!../node_modules/vue-loader/lib/selector?type=script&index=0!./App.vue\"\n/* template */\nimport __vue_template__ from \"!!../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-07bc1184\\\",\\\"hasScoped\\\":false,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../node_modules/vue-loader/lib/selector?type=template&index=0!./App.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/App.vue\n// module id = null\n// module chunks = ","<template>\n  <div id=\"app\">\n    <router-view/>\n  </div>\n</template>\n\n<script>\nexport default {\n  name: 'App'\n}\n</script>\n\n<style lang=\"scss\">\n#app {\n  @import \"css/docs.scss\";\n  font-family: 'Avenir', Helvetica, Arial, sans-serif;\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n  text-align: justify;\n  color: #2c3e50;\n  margin-top: 60px;\n}\n</style>\n\n\n\n// WEBPACK FOOTER //\n// src/App.vue","/*eslint-disable */\nexport default [\n  {\n    path: '/',\n    component: require('../components/en/EnEntry.vue').default,\n    children: [{\n      path: '',\n      component: require('../components/en/EnIndex.vue').default,\n      children: [{\n        path: '',\n        component: require('../pages/en/EnIntroduction.md').default,\n        }\n      ],\n    },\n    {\n      path:'theorical',\n      component: require('../components/en/EnComponents.vue').default,\n      children: [{\n        path: '1',\n        component: require('../pages/en/theoricalRL/En1DDPG.md').default,\n      }],\n    }\n    ],\n  },\n];\n/*eslint-disable */\n\n\n\n// WEBPACK FOOTER //\n// ./src/router/router.en.js","/*eslint-disable */\nexport default [\n  {\n    path: '/vi',\n    component: require('../components/vi/ViEntry.vue').default,\n    children: [{\n      path: '',\n      component: require('../components/vi/ViIndex.vue').default,\n      children: [{\n        path: '',\n        component: require('../pages/vi/ViIntroduction.md').default,\n        }\n      ],\n    },\n    {\n      path:'theorical',\n      component: require('../components/vi/ViComponents.vue').default,\n      children: [{\n        path: '1',\n        component: require('../pages/vi/theoricalRL/Vi1DDPG.md').default,\n      }],\n    }\n    ],\n  },\n];\n/*eslint-disable */\n\n\n\n// WEBPACK FOOTER //\n// ./src/router/router.vi.js","/*eslint-disable */\nexport default [\n  {\n    path: '/fr',\n    component: require('../components/fr/FrEntry.vue').default,\n    children: [{\n      path: '',\n      component: require('../components/fr/FrIndex.vue').default,\n      children: [{\n        path: '',\n        component: require('../pages/fr/FrIntroduction.md').default,\n        }\n      ],\n    },\n    {\n      path:'theorical',\n      component: require('../components/fr/FrComponents.vue').default,\n      children: [{\n        path: '1',\n        component: require('../pages/fr/theoricalRL/Fr1DDPG.md').default,\n      }],\n    }\n    ],\n  },\n];\n/*eslint-disable */\n\n\n\n// WEBPACK FOOTER //\n// ./src/router/router.fr.js","import Vue from 'vue'\nimport Router from 'vue-router'\nimport EnRouter from './router.en'\nimport ViRouter from './router.vi'\nimport FrRouter from './router.fr'\nVue.use(Router)\n\nlet router = []\nrouter = router.concat(EnRouter)\nrouter = router.concat(ViRouter)\nrouter = router.concat(FrRouter)\n\nexport default new Router({\n  routes: router\n})\n\n\n\n// WEBPACK FOOTER //\n// ./src/router/index.js","// The Vue build version to load with the `import` command\n// (runtime-only or standalone) has been set in webpack.base.conf with an alias.\nimport Vue from 'vue'\nimport App from './App'\nimport router from './router'\nimport VueMathjax from 'vue-mathjax'\n\nVue.use(VueMathjax)\nVue.config.productionTip = false\n\n/* eslint-disable no-new */\nnew Vue({\n  mode: 'history',\n  el: '#app',\n  router,\n  components: { App },\n  template: '<App/>'\n})\n\n\n\n// WEBPACK FOOTER //\n// ./src/main.js","module.exports = require(\"!!vue-loader!../../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./En1DDPG.md\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/pages/en/theoricalRL/En1DDPG.md\n// module id = PPBh\n// module chunks = 0","<template>\n  <div>\n    <nav class=\"navbar is-fixed-top is-light is-bold\">\n        <div class=\"navbar-brand\">\n            <a class=\"navbar-item\" href=\"\">\n                <span class=\"logo\">\n                    Frew<i class=\"fas fa-angle-double-up\" ></i>rd\n                </span>\n            </a>\n            <div class=\"navbar-burger burger\" data-target=\"navbarLanguage\">\n                <span></span>\n                <span></span>\n                <span></span>\n            </div>\n        </div>\n        <div id=\"navbarLanguage\" class=\"navbar-menu\">\n            <div class=\"navbar-start\">\n                <div class=\"navbar-item has-dropdown is-hoverable\">\n                    <a class=\"navbar-link\">\n                        Language\n                    </a>\n                    <div class=\"navbar-dropdown is-boxed\">\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/\"><span>English</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/vi\"><span>Vietnamese</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/fr\"><span>French</span></router-link>\n                        </a>\n                    </div>\n                </div>\n            </div>\n            <div class=\"navbar-end\">\n                <div class=\"navbar-item\">\n                    <div class=\"field is-grouped\">\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://github.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-github\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\">\n                                <span class=\"icon\"><i class=\"fab fa-linkedin\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.facebook.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-facebook\"></i></span>\n                            </a>\n                        </p>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </nav>\n\n    <section class=\"section\">\n      <div class=\"container\">\n        <div class=\"columns\">\n          <div class=\"column is-2 side-nav\">\n            <side-menu></side-menu>\n          </div>\n          <div class=\"column is-10 markdown\">\n            <router-view></router-view>\n          </div>\n        </div>\n      </div>\n    </section>\n\n    <footer class=\"footer\">\n      <div class=\"container\">\n        <div class=\"content has-text-centered\">\n          <p>\n            <strong>Frew<i class=\"fas fa-angle-double-up\" ></i>rd</strong> by <a href=\"https://www.facebook.com/toanngosy/\" target=\"_blank\">Gonaton</a>. The source code is licensed\n            <a href=\"http://opensource.org/licenses/mit-license.php\">MIT</a>.\n          </p>\n          <p>\n            <a class=\"icon\" href=\"https://github.com/toanngosy/\">\n              <i class=\"fab fa-github\"></i>\n            </a>\n          </p>\n        </div>\n      </div>\n    </footer>\n  </div>\n</template>\n\n<!---------------------------------------------------------------->\n<script>\nimport SideMenu from './EnSideMenu';\nexport default {\n  components: { SideMenu },\n};\n</script>\n\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n  .logo\n  {\n  font-size: 30px;\n  color: black;\n  }\n  .randomimage\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 200px;\n  color: #D3D3D3;\n  }\n\n  .welcome\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 62.5px;\n  font-weight: bold;\n  color: #D3D3D3;\n  }\n</style>\n\n\n\n\n// WEBPACK FOOTER //\n// src/components/en/EnComponents.vue","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',[_c('nav',{staticClass:\"navbar is-fixed-top is-light is-bold\"},[_vm._m(0),_vm._v(\" \"),_c('div',{staticClass:\"navbar-menu\",attrs:{\"id\":\"navbarLanguage\"}},[_c('div',{staticClass:\"navbar-start\"},[_c('div',{staticClass:\"navbar-item has-dropdown is-hoverable\"},[_c('a',{staticClass:\"navbar-link\"},[_vm._v(\"\\n                      Language\\n                  \")]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-dropdown is-boxed\"},[_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/\"}},[_c('span',[_vm._v(\"English\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/vi\"}},[_c('span',[_vm._v(\"Vietnamese\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/fr\"}},[_c('span',[_vm._v(\"French\")])])],1)])])]),_vm._v(\" \"),_vm._m(1)])]),_vm._v(\" \"),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-2 side-nav\"},[_c('side-menu')],1),_vm._v(\" \"),_c('div',{staticClass:\"column is-10 markdown\"},[_c('router-view')],1)])])]),_vm._v(\" \"),_vm._m(2)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-brand\"},[_c('a',{staticClass:\"navbar-item\",attrs:{\"href\":\"\"}},[_c('span',{staticClass:\"logo\"},[_vm._v(\"\\n                  Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\\n              \")])]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-burger burger\",attrs:{\"data-target\":\"navbarLanguage\"}},[_c('span'),_vm._v(\" \"),_c('span'),_vm._v(\" \"),_c('span')])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-end\"},[_c('div',{staticClass:\"navbar-item\"},[_c('div',{staticClass:\"field is-grouped\"},[_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-github\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-linkedin\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.facebook.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-facebook\"})])])])])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('footer',{staticClass:\"footer\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"content has-text-centered\"},[_c('p',[_c('strong',[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")]),_vm._v(\" by \"),_c('a',{attrs:{\"href\":\"https://www.facebook.com/toanngosy/\",\"target\":\"_blank\"}},[_vm._v(\"Gonaton\")]),_vm._v(\". The source code is licensed\\n          \"),_c('a',{attrs:{\"href\":\"http://opensource.org/licenses/mit-license.php\"}},[_vm._v(\"MIT\")]),_vm._v(\".\\n        \")]),_vm._v(\" \"),_c('p',[_c('a',{staticClass:\"icon\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('i',{staticClass:\"fab fa-github\"})])])])])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-f1e1833e\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/en/EnComponents.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-f1e1833e\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../../node_modules/vue-loader/lib/selector?type=styles&index=0!./EnComponents.vue\")\n}\nvar normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nexport * from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./EnComponents.vue\"\nimport __vue_script__ from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./EnComponents.vue\"\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-f1e1833e\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./EnComponents.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-f1e1833e\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/en/EnComponents.vue\n// module id = null\n// module chunks = ","module.exports = require(\"!!vue-loader!../../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./Vi1DDPG.md\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/pages/vi/theoricalRL/Vi1DDPG.md\n// module id = SZf6\n// module chunks = 0","module.exports = require(\"!!vue-loader!../../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./Fr1DDPG.md\");\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/pages/fr/theoricalRL/Fr1DDPG.md\n// module id = WXZB\n// module chunks = 0","<template>\n  <div>\n    <nav class=\"navbar is-fixed-top is-light is-bold\">\n        <div class=\"navbar-brand\">\n            <a class=\"navbar-item\" href=\"\">\n                <span class=\"logo\">\n                    Frew<i class=\"fas fa-angle-double-up\" ></i>rd\n                </span>\n            </a>\n            <div class=\"navbar-burger burger\" data-target=\"navbarLanguage\">\n                <span></span>\n                <span></span>\n                <span></span>\n            </div>\n        </div>\n        <div id=\"navbarLanguage\" class=\"navbar-menu\">\n            <div class=\"navbar-start\">\n                <div class=\"navbar-item has-dropdown is-hoverable\">\n                    <a class=\"navbar-link\">\n                        Ngn Ng\n                    </a>\n                    <div class=\"navbar-dropdown is-boxed\">\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/\"><span>Ting Anh</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/vi\"><span>Ting Vit</span></router-link>\n                        </a>\n                        <a class=\"navbar-item\">\n                            <router-link to=\"/fr\"><span>Ting Php</span></router-link>\n                        </a>\n                    </div>\n                </div>\n            </div>\n            <div class=\"navbar-end\">\n                <div class=\"navbar-item\">\n                    <div class=\"field is-grouped\">\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://github.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-github\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\">\n                                <span class=\"icon\"><i class=\"fab fa-linkedin\"></i></span>\n                            </a>\n                        </p>\n                        <p class=\"control\">\n                            <a class=\"bd-tw-button button\" href=\"https://www.facebook.com/toanngosy/\">\n                                <span class=\"icon\"><i class=\"fab fa-facebook\"></i></span>\n                            </a>\n                        </p>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </nav>\n    <section class=\"hero is-dark is-medium\">\n        <div class=\"hero-body\">\n            <div class=\"container\">\n                <span class=\"randomimage\"><i class=\"fas fa-brain\" ></i></span>\n                <span class=\"welcome\">Frew<i class=\"fas fa-angle-double-up\" ></i>rd cho bn</span>\n            </div>\n        </div>\n    </section>\n    <section class=\"section\">\n      <div class=\"container\">\n        <div class=\"columns\">\n          <div class=\"column is-2 side-nav\">\n            <side-menu></side-menu>\n          </div>\n          <div class=\"column is-10 markdown\">\n            <router-view></router-view>\n          </div>\n        </div>\n      </div>\n    </section>\n\n    <footer class=\"footer\">\n      <div class=\"container\">\n        <div class=\"content has-text-centered\">\n          <p>\n            <strong>Frew<i class=\"fas fa-angle-double-up\" ></i>rd</strong> by <a href=\"https://www.facebook.com/toanngosy/\" target=\"_blank\">Gonaton</a>. M ngun bn quyn\n            <a href=\"http://opensource.org/licenses/mit-license.php\">MIT</a>.\n          </p>\n          <p>\n            <a class=\"icon\" href=\"https://github.com/toanngosy/\">\n              <i class=\"fab fa-github\"></i>\n            </a>\n          </p>\n        </div>\n      </div>\n    </footer>\n  </div>\n</template>\n\n<script>\nimport SideMenu from './ViSideMenu';\nexport default {\n  components: { SideMenu },\n};\n</script>\n<!-- Add \"scoped\" attribute to limit CSS to this component only -->\n<style scoped>\n  .logo\n  {\n  font-size: 30px;\n  color: black;\n  }\n  .randomimage\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 200px;\n  color: #D3D3D3;\n  }\n\n  .welcome\n  {\n  display:table;\n  margin:0 auto;\n  font-size: 62.5px;\n  font-weight: bold;\n  color: #D3D3D3;\n  }\n</style>\n\n\n\n// WEBPACK FOOTER //\n// src/components/vi/ViIndex.vue","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',[_c('nav',{staticClass:\"navbar is-fixed-top is-light is-bold\"},[_vm._m(0),_vm._v(\" \"),_c('div',{staticClass:\"navbar-menu\",attrs:{\"id\":\"navbarLanguage\"}},[_c('div',{staticClass:\"navbar-start\"},[_c('div',{staticClass:\"navbar-item has-dropdown is-hoverable\"},[_c('a',{staticClass:\"navbar-link\"},[_vm._v(\"\\n                      Ngn Ng\\n                  \")]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-dropdown is-boxed\"},[_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/\"}},[_c('span',[_vm._v(\"Ting Anh\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/vi\"}},[_c('span',[_vm._v(\"Ting Vit\")])])],1),_vm._v(\" \"),_c('a',{staticClass:\"navbar-item\"},[_c('router-link',{attrs:{\"to\":\"/fr\"}},[_c('span',[_vm._v(\"Ting Php\")])])],1)])])]),_vm._v(\" \"),_vm._m(1)])]),_vm._v(\" \"),_vm._m(2),_vm._v(\" \"),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-2 side-nav\"},[_c('side-menu')],1),_vm._v(\" \"),_c('div',{staticClass:\"column is-10 markdown\"},[_c('router-view')],1)])])]),_vm._v(\" \"),_vm._m(3)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-brand\"},[_c('a',{staticClass:\"navbar-item\",attrs:{\"href\":\"\"}},[_c('span',{staticClass:\"logo\"},[_vm._v(\"\\n                  Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\\n              \")])]),_vm._v(\" \"),_c('div',{staticClass:\"navbar-burger burger\",attrs:{\"data-target\":\"navbarLanguage\"}},[_c('span'),_vm._v(\" \"),_c('span'),_vm._v(\" \"),_c('span')])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"navbar-end\"},[_c('div',{staticClass:\"navbar-item\"},[_c('div',{staticClass:\"field is-grouped\"},[_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-github\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.linkedin.com/in/sy-toan-ngo-491109bb/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-linkedin\"})])])]),_vm._v(\" \"),_c('p',{staticClass:\"control\"},[_c('a',{staticClass:\"bd-tw-button button\",attrs:{\"href\":\"https://www.facebook.com/toanngosy/\"}},[_c('span',{staticClass:\"icon\"},[_c('i',{staticClass:\"fab fa-facebook\"})])])])])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',{staticClass:\"hero is-dark is-medium\"},[_c('div',{staticClass:\"hero-body\"},[_c('div',{staticClass:\"container\"},[_c('span',{staticClass:\"randomimage\"},[_c('i',{staticClass:\"fas fa-brain\"})]),_vm._v(\" \"),_c('span',{staticClass:\"welcome\"},[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd cho bn\")])])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('footer',{staticClass:\"footer\"},[_c('div',{staticClass:\"container\"},[_c('div',{staticClass:\"content has-text-centered\"},[_c('p',[_c('strong',[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")]),_vm._v(\" by \"),_c('a',{attrs:{\"href\":\"https://www.facebook.com/toanngosy/\",\"target\":\"_blank\"}},[_vm._v(\"Gonaton\")]),_vm._v(\". M ngun bn quyn\\n          \"),_c('a',{attrs:{\"href\":\"http://opensource.org/licenses/mit-license.php\"}},[_vm._v(\"MIT\")]),_vm._v(\".\\n        \")]),_vm._v(\" \"),_c('p',[_c('a',{staticClass:\"icon\",attrs:{\"href\":\"https://github.com/toanngosy/\"}},[_c('i',{staticClass:\"fab fa-github\"})])])])])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-b20430e4\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/vi/ViIndex.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-b20430e4\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../../node_modules/vue-loader/lib/selector?type=styles&index=0!./ViIndex.vue\")\n}\nvar normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nexport * from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./ViIndex.vue\"\nimport __vue_script__ from \"!!babel-loader!../../../node_modules/vue-loader/lib/selector?type=script&index=0!./ViIndex.vue\"\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-b20430e4\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./ViIndex.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-b20430e4\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/vi/ViIndex.vue\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('aside',{staticClass:\"list-group\"},[_c('ul',[_c('li',[_c('router-link',{staticClass:\"list-group-item\",attrs:{\"to\":\"/\",\"exact\":\"\"}},[_vm._v(\"Introduction\")])],1)]),_vm._v(\" \"),_c('div',{staticClass:\"menu\"},[_c('p',{staticClass:\"menu-label\"},[_vm._v(\"RL Thorique\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/fr/theorical/1\",\"exact\":\"\"}},[_vm._v(\"DDPG\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/layout\",\"exact\":\"\"}},[_vm._v(\"TRPO/PPO\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/button\",\"exact\":\"\"}},[_vm._v(\"SAC\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/icon\",\"exact\":\"\"}},[_vm._v(\"Inference\")])],1)]),_vm._v(\" \"),_c('p',{staticClass:\"menu-label\"},[_vm._v(\"RL Practique\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/affix\",\"exact\":\"\"}},[_vm._v(\"OpenAI Gym\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/scrollto\",\"exact\":\"\"}},[_vm._v(\"Q-learning\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/breadcrumb\",\"exact\":\"\"}},[_vm._v(\"DDPG\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/breadcrumb\",\"exact\":\"\"}},[_vm._v(\"TRPO/PPO\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/breadcrumb\",\"exact\":\"\"}},[_vm._v(\"SAC\")])],1)]),_vm._v(\" \"),_c('p',{staticClass:\"menu-label\"},[_vm._v(\"Rvision bibliothque \")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/alert\",\"exact\":\"\"}},[_vm._v(\"OpenAI baselines\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/aside\",\"exact\":\"\"}},[_vm._v(\"Stable baselines\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/collapse\",\"exact\":\"\"}},[_vm._v(\"Ray/RLLib\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/modal\",\"exact\":\"\"}},[_vm._v(\"Unity ML-Agents\")])],1)]),_vm._v(\" \"),_c('p',{staticClass:\"menu-label\"},[_vm._v(\"Application\")]),_vm._v(\" \"),_c('ul',{staticClass:\"menu-list\"},[_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/form\",\"exact\":\"\"}},[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd Env\")])],1),_vm._v(\" \"),_c('li',[_c('router-link',{attrs:{\"to\":\"/en/components/form2\",\"exact\":\"\"}},[_vm._v(\"Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd Exp\")])],1)])])])}\nvar staticRenderFns = []\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-7d7cdfd8\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/fr/FrSideMenu.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-7d7cdfd8\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../../node_modules/vue-loader/lib/selector?type=styles&index=0!./FrSideMenu.vue\")\n}\nvar normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-7d7cdfd8\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./FrSideMenu.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-7d7cdfd8\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/fr/FrSideMenu.vue\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',[_c('h1',[_vm._v(\"Li m u\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Bn cnh s pht trin ca Computer Vision, Natural Language Processing,\\ncc thut ton Reinforcement Learning cng t c nhng thnh tu ng\\nngc nhin trong nhng nm gn y v nhn c nhiu s ch .\\nTuy nhin, cc bi hng dn c tm thy trn mng thng y nhanh n\\nphn code m khng i su vo ton.\\nBlog ny da trn bi ging ca gio s Sergey Levine thuc i hc UC Berkeley\\nv sch Introduction to Reinforcement Learning ca gio s Sutton v Barto,\\ncc bn c th tm thy link cho bi ging\\n\"),_c('a',{attrs:{\"href\":\"http://rail.eecs.berkeley.edu/deeprlcourse/\"}},[_vm._v(\"ti y\")]),_vm._v(\"\\nv sch \"),_c('a',{attrs:{\"href\":\"http://incompleteideas.net/book/bookdraft2017nov5.pdf\"}},[_vm._v(\"ti y\")]),_vm._v(\".\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Blog cng s gii thiu cc th vin RL v cch dng chng trong\\nthc t.\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"V Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Trong RL, reward rt quan trng, cc hnh ng m my hc c l \\nti u tng lng reward v lu di v xy dng hm reward sao cho hp l\\nl mt trong cc iu kin cn  thut ton RL c th chy c. Trong thc t,\\nreward cng rt quan trng,  chnh l mc tiu m chng ta hng n\\ntrong cuc sng.\\nHm reward - \\\\(f(reward)\\\\) - Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd\\nxut pht t .\\n\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br')]),_vm._v(\" \"),_c('p',{staticStyle:{\"font-size\":\"200%\"},attrs:{\"align\":\"center\"}},[_vm._v(\"In this Freeworld, what is your Frew\"),_c('i',{staticClass:\"fas fa-angle-double-up\"}),_vm._v(\"rd?\")])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-b55718cc\",\"hasScoped\":false,\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/vi/ViIntroduction.md\n// module id = null\n// module chunks = ","var normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-b55718cc\\\",\\\"hasScoped\\\":false,\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./ViIntroduction.md\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = null\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/vi/ViIntroduction.md\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('router-view')}\nvar staticRenderFns = []\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-6a927a95\",\"hasScoped\":false,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/en/EnEntry.vue\n// module id = null\n// module chunks = ","var normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-6a927a95\\\",\\\"hasScoped\\\":false,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./EnEntry.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = null\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/en/EnEntry.vue\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('router-view')}\nvar staticRenderFns = []\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-856c2516\",\"hasScoped\":false,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/fr/FrEntry.vue\n// module id = null\n// module chunks = ","var normalizeComponent = require(\"!../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-856c2516\\\",\\\"hasScoped\\\":false,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../node_modules/vue-loader/lib/selector?type=template&index=0!./FrEntry.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = null\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/fr/FrEntry.vue\n// module id = null\n// module chunks = ","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('section',[_c('p',[_c('vue-mathjax')],1),_vm._v(\" \"),_c('h1',[_vm._v(\"I - Reinforcement Learning - t Policy Gradient n Deep Deterministic Policy Gradient\")]),_vm._v(\" \"),_vm._m(0),_vm._v(\" \"),_vm._m(1),_vm._v(\" \"),_c('p',[_vm._v(\"Di y l nh ngha ca cc thut ng hay xut hin trong RL:\")]),_vm._v(\" \"),_vm._m(2),_vm._v(\" \"),_vm._m(3),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('p',[_vm._v(\"Nh vy, ti state $s$, agent tng tc vi environment vi hnh ng $a$,\\ndn n state mi $s_{t+1}$ v nhn c reward tng ng $r_{t+1}$.\\nVng lp nh th cho n trng thi cui cng $s_T$.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Trong phn di y, mnh s dng cc thut ng ting Anh  cc bn tin\\ntheo di thay v dch sang ting Vit.\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"1 - V d\")]),_vm._v(\" \"),_vm._m(4),_vm._v(\" \"),_vm._m(5),_vm._v(\" \"),_c('br'),_vm._v(\"\\n* _Goal_: mc ch ca bi ton l xy dng policy  iu khin xe ln n c ch cm c.\\n* _Environment_: dc v xe chy trong \\n* _State_: trng thi ca xe c 2 dimension, ta  ca xe theo trc $x$ v vn tc ca xe ti thi im o.\\n* _Action_: Lc c truyn cho xe  iu khin, lc ny khng  mnh\\n y xe 1 lc ln n c, xe s cn i qua i li 2 bn mt nghin \\ntng tc n ch cm c.\\n* _Reward_: vi mi step m xe khng n c c, agent nhn reward $r=\\\\frac{-a^2}{10}$,\\nxe n c c th nhn reward l 100. Nh th, nu agent iu khin xe m xe khng ln c th s b pht.\\n* _Terminal state_: nu agent ln n c c hoc l s step vt qu 998 steps.\\n\"),_c('h1',[_vm._v(\"2 - Policy Gradient\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Trong phn di y  v d sinh ng, mnh gii quyt 1 bi ton game n gin, game Hng Trng.\")]),_vm._v(\" \"),_vm._m(6),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('p',[_vm._v(\"Gi $\\\\pi_\\\\theta(a|s) = f(s, \\\\theta)$ l policy ca agent,  hm phn b xc sut ca action $a$ ti state $s$.\")]),_vm._v(\" \"),_vm._m(7),_vm._v(\" \"),_c('p',[_vm._v(\"Gi $\\\\tau = s_1, a_1, s_2, a_2,..., s_T, a_T$ l chui s kin t state $s_1$ n state $s_T$. Xc sut xy ra chui $\\\\tau$:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"[\\n\\\\begin{eqnarray}\\np_\\\\theta(\\\\tau) &=& p_\\\\theta(s_1, a_1, s_2, a_2,...s_T, a_T) \\\\\\\\\\n&=& p(s_1)\\\\pi_\\\\theta(a_1|s_1)p(s_2|s_1, a_1)\\\\pi_\\\\theta(a_2|s_2)...p(s_{T}|s_{T-1},a_{T-1})\\\\pi_\\\\theta(a_T|s_T) \\\\\\\\\\n&=& p(s_1)\\\\Pi_{t=1}^{t=T}\\\\pi_\\\\theta(a_t|s_t)p(s_{t+1}|s_t, a_t) \\\\\\\\\\n\\\\end{eqnarray}\\n]\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Chng ta s thy phn b xc sut ca state $p(s_{t+1}|a_t, s_t)$ b loi b trong cc phng trnh v sau.\")]),_vm._v(\" \"),_vm._m(8),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\theta^* &=& \\\\arg\\\\max_\\\\theta E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\big[r(\\\\tau)\\\\big] \\\\\\\\\\n&=& \\\\arg\\\\max_\\\\theta E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(9),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nJ(\\\\theta) &=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg] \\\\\\\\\\n&=& \\\\frac{1}{N} \\\\sum_i\\\\sum_t r(a_t, s_t)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(10),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nJ(\\\\theta) &=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg] \\\\\\\\\\n&=& \\\\int p_\\\\theta(\\\\tau) r(\\\\tau) dr\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Tip tc xem xt gradient ca hm mc tiu:\")]),_vm._v(\" \"),_vm._m(11),_vm._v(\" \"),_c('p',[_vm._v(\"Tip tc phn tch hm $\\\\log p_\\\\theta(\\\\tau)$, nh ta  c  trn $p_\\\\theta(\\\\tau) = p(s_1)\\\\Pi_{t=1}^{t=T}\\\\pi_\\\\theta(a_t|s_t)p(s_{t+1}|s_t, a_t)$, ta c:\\n$$\\n\\\\begin{eqnarray}\\n\\\\log p_\\\\theta(\\\\tau) = \\\\log p(s_1) + \\\\sum_{t=1}^{t=T}\\\\log \\\\pi_\\\\theta(a_t|s_t) + \\\\sum_{t=1}^{t=T}\\\\log p(s_{t+1}|s_t, a_t)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Cui cng:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) = \\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_t|s_t)\\n\\\\end{eqnarray}\\n$$\\nKt qu ny rt hay v o hm theo $\\\\theta$ ca hm $\\\\log p_\\\\theta(\\\\tau)$  khng cn ph thuc vo phn b xc sut chuyn ca state $p(s_{t+1}|a_t, s_t)$, n ch ph thuc vo phn b xc sut ca action $a_i$ chng ta thc hin trn $s_i$.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Gradient ca hm mc tiu lc ny:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=&  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) r(\\\\tau)\\\\bigg] \\\\\\\\\\n&=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a_t|s_t)\\\\sum_{t=1}^{t=T} r(a_t, s_t)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Tng t, sau khi tri qua $N$ episodes, expectation ca hm gradient ny l:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=& \\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\bigg(\\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_{i,t}|s_{i,t})\\\\bigg)\\\\bigg(\\\\sum_{t=1}^{t=T} r(a_{i,t}, s_{i,t})\\\\bigg)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Cui cng, chng ta update $\\\\theta$ nh dng gradient ascent:\\n$$\\n\\\\begin{eqnarray}\\n\\\\theta \\\\leftarrow \\\\theta + \\\\nabla_\\\\theta J(\\\\theta)\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('h1',[_vm._v(\"3 - REINFORCE algorithm\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Tng hp cc kt qu trn ta c thut ton REINFORCE nh di y:\")]),_vm._v(\" \"),_vm._m(12),_vm._v(\" \"),_c('p',[_vm._v(\"By gi hy dng li  xem xt gradient ca phng trnh mc tiu. Vit  dng  ri mt hn ta c:\")]),_vm._v(\" \"),_vm._m(13),_vm._v(\" \"),_c('h1',[_vm._v(\"4 - nh ngha thm 1 s khi nim mi\")]),_vm._v(\" \"),_vm._m(14),_vm._v(\" \"),_c('h2',[_vm._v(\"4.1 - Bellman Equations\")]),_vm._v(\" \"),_c('p',[_vm._v(\"T cng thc  trn, ta c:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) &=& E_\\\\pi\\\\bigg[G_t|S=s_t\\\\bigg] \\\\\\\\\\n&=& E_\\\\pi\\\\bigg[\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+1}|S=s_t\\\\bigg] \\\\\\\\\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Ly reward $R_{t+1}$ nhn c khi chuyn t state $s_t$ sang $s_{t+1}$ ra ngoi du $\\\\sum$, ta c:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nE_\\\\pi\\\\bigg[R_{t+1} + \\\\gamma\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+2}|S=s_t\\\\bigg] &=& E_\\\\pi[R_{t+1}|S=s_t] + \\\\gamma E_\\\\pi\\\\bigg[\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+2}|S=s_t\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Khai trin expected value ca 2 cm  trn ta c:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\nE_\\\\pi\\\\bigg[R_{t+1}|S=s_t\\\\bigg]=\\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)R(s_{t+1}|s_t, a)\\n\\\\end{eqnarray}\\n$$\\nM:\")]),_vm._v(\" \"),_c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\gamma E_\\\\pi\\\\bigg[\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+2}|S=s_t\\\\bigg] = \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\gamma E_\\\\pi\\\\bigg[\\\\sum^\\\\infty_{k=0} \\\\gamma^k R_{t+k+2} | S = s_{t+1}\\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nTa c:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) = \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\Bigg[R(s_{t+1}|s_t, a) + \\\\gamma E_\\\\pi\\\\bigg[\\\\sum^\\\\infty_{k=0} \\\\gamma^k R_{t+k+2} | S = s_{t+1} \\\\bigg]\\\\Bigg]\\n\\\\end{eqnarray}\\n$$\\n  rng:\\n$$\\n\\\\begin{eqnarray}\\nE_\\\\pi\\\\bigg[\\\\sum^\\\\infty_{k=0} \\\\gamma^k R_{t+k+2} | S = s_{t+1}\\\\bigg] = V^\\\\pi(s_{t+1})\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Cui cng ta c:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) = \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\bigg[R(s_{t+1}|s_t, a) + \\\\gamma  V^\\\\pi(s_{t+1})\\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nTng t vi:\\n$$\\n\\\\begin{eqnarray}\\nQ^\\\\pi(s_t, a_t) = \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\bigg[R(s_{t+1}|s_t, a) + \\\\gamma \\\\sum_{a_{t+1}} \\\\pi(s_{t+1}, a_{t+1}) Q^\\\\pi (s_{t+1}, a_{t+1}) \\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nM theo quan h gia $V^\\\\pi$ v $Q^\\\\pi$  trn, th ta li c:\\n$$\\n\\\\begin{eqnarray}\\n\\\\sum_{a_{t+1}} \\\\pi(s_{t+1}, a_{t+1}) Q^\\\\pi (s_{t+1}, a_{t+1}) = V^\\\\pi(s_{t+1})\\n\\\\end{eqnarray}\\n$$\\nDo :\\n$$\\n\\\\begin{eqnarray}\\nQ^\\\\pi(s_t, a_t) = \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a_t)\\\\bigg[R(s_{t+1}|s_t, a_t) + \\\\gamma  V^\\\\pi(s_{t+1}) \\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Tt c nhng bin i  trn cho thy ta c th biu din gi tr ca $Q^\\\\pi$ v $V^\\\\pi$ ti state $s_t$ vi state $s_{t+1}$. Nh vy, nu bit c gi tr ti state $s_{t+1}$, ta c th d dng tnh ton c gi tr ti $s_t$. Tm gn th ta c 2 phng trnh sau:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) &=& \\\\sum_a \\\\pi(s_t,a) \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a)\\\\bigg[R(s_{t+1}|s_t, a) + \\\\gamma  V^\\\\pi(s_{t+1})\\\\bigg] \\\\\\\\\\nQ^\\\\pi(s_t, a_t) &=& \\\\sum_{s_{t+1}} p(s_{t+1}|s_t, a_t)\\\\bigg[R(s_{t+1}|s_t, a_t) + \\\\gamma  V^\\\\pi(s_{t+1}) \\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Tr li vi gradient hm mc tiu, by gi ta c:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)Q^\\\\pi(s,a)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(15),_vm._v(\" \"),_vm._m(16),_vm._v(\" \"),_vm._m(17),_vm._v(\" \"),_c('h1',[_vm._v(\"6 - Stochastic Actor-Critic\")]),_vm._v(\" \"),_vm._m(18),_vm._v(\" \"),_c('p',[_vm._v(\"Xem xt gradient ca hm mc tiu m ta  c  phn trn:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)\\\\Big(Q^\\\\pi(s,a)-V^\\\\pi(s)\\\\Big)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nT Bellman Equation  trn ta c quan h gia $Q^\\\\pi$ v $V^\\\\pi$, lc ny hm mc tiu tr thnh:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim \\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)\\\\Big(R + \\\\gamma V^\\\\pi(s_{t+1})- V^\\\\pi(s)\\\\Big)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")]),_vm._v(\" \"),_vm._m(19),_vm._v(\" \"),_c('h1',[_vm._v(\"7 - Actor-Critic Algorithm\")]),_vm._v(\" \"),_c('p',[_vm._v(\"T thut ton REINFORCE, by gi chng ta s dng thm hm xp x cho value function $V_\\\\phi$, thay i mt cht ta c nh sau:\")]),_vm._v(\" \"),_vm._m(20),_vm._v(\" \"),_c('h1',[_vm._v(\"8 - T Stochastic Actor-Critic ti Q-Learning\")]),_vm._v(\" \"),_vm._m(21),_vm._v(\" \"),_vm._m(22),_vm._v(\" \"),_c('br'),_vm._v(\"\\nNh vy, vi mt policy $\\\\pi$, ta lun c th p dng policy $\\\\pi'$ trn   c mt policy t nht l bng hoc tt hn.\"),_c('br'),_vm._v(\"\\nTa c thut ton by gi c th vit nh sau:\"),_c('br'),_vm._v(\"\\n1. nh gi $A^\\\\pi(s,a)$ vi cc action $a$ khc nhau\"),_c('br'),_vm._v(\"\\n2. Ti u $\\\\pi \\\\leftarrow \\\\pi'$\\n\"),_vm._m(23),_vm._v(\" \"),_vm._m(24),_vm._v(\" \"),_c('p',[_vm._v(\"n y th thc s ta khng cn quan tm n policy na, m bc 2 c th vit li thnh:\")]),_vm._v(\" \"),_vm._m(25),_vm._v(\" \"),_c('p',[_vm._v(\"Nu x dng mt hm xp x cho $V_\\\\phi(s)$, ta c thut ton nh sau:\")]),_vm._v(\" \"),_vm._m(26),_vm._v(\" \"),_c('p',[_vm._v(\"Thut ton ny khng n,  bc 1 ta cn c reward $r(s, a)$ ng vi mi action $a$ khc nhau, nh vy ta cn nhiu simulation ti 1 state $s$. Ta c th lm tng t vi $Q(s,a)$ thay v $V(s)$.\")]),_vm._v(\" \"),_vm._m(27),_vm._v(\" \"),_c('p',[_vm._v(\"y chnh l thut ton Q-Learning.   rng, reward $r$  trn khng ph thuc vo state transition v cng khng\\nph thuc vo policy $\\\\pi$ dng  sinh ra sample, nn ta ch cn c sample $(s, a, r, s')$ l c th ci thin c\\npolicy m khng cn bit n c sinh ra t policy no. Do , thut ton ny c gi l off-policy. Sau ny, chng\\nta s c cc thut ton on-policy, cc thut ton on-policy th phi da vo sample c sinh ra ti policy hin ti\\n c th ci thin policy mi.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Ta c thut ton Online Q-Learning nh sau:\")]),_vm._v(\" \"),_vm._m(28),_vm._v(\" \"),_vm._m(29),_vm._v(\" \"),_c('p',[_vm._v(\"Tm li,  thut ton n nh v hi t, ta cn:\")]),_vm._v(\" \"),_vm._m(30),_vm._v(\" \"),_c('p',[_vm._v(\"Thut ton by gi c vit nh sau:\")]),_vm._v(\" \"),_vm._m(31),_vm._v(\" \"),_c('h1',[_vm._v(\"9 - T Deep Q-Network n Deep Deterministic Policy Gradient\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Thut ton DQN  thnh cng trong vic sp x Q-value, nhng c mt hn ch  bc 3: chng ta cn nh gi $Q_{\\\\phi'}$ vi tt c cc action khc nhau  chn ra $Q$ ln nht. Vi discrete action space nh cc game, khi m action ch l cc nt bm ln xung qua li, s lng action l hu hn, iu ny c th thc hin c. Tuy nhin, vi continuous action space, v d action c th trong khong t 0 n 1, ta cn c mt cch tip cn khc.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Cch ta c th ngh n  l tm cch phn nh action space, phn nh continuous space thnh cc khong nh, v d nh t 0 n 1,  ta c th phn ra lm 5 n 10 khong gi tr c th ri vo. Mt cch khc  l sample ngu nhin cc action khc nhau trong khong cho php vi cng state $s$ v chn ra gi tr $Q(s,a)$ ln nht.\")]),_vm._v(\" \"),_vm._m(32),_vm._v(\" \"),_c('p',[_vm._v(\"By gi, nu nh ta c thm mt hm xp x $\\\\mu_\\\\theta(s) = \\\\arg max_a Q_\\\\phi(s,a)$, by gi ta tm b s $\\\\theta$ sao cho: $\\\\theta \\\\leftarrow  \\\\arg max_\\\\theta Q_\\\\phi(s,\\\\mu_\\\\theta(s))$. Php ti u ny xem xt s thay i ca $Q_\\\\phi$ theo bin $\\\\theta$. Ta c th tnh c s thay i ny da trn chain rule nh sau:\\n$\\\\frac{dQ_\\\\phi}{d\\\\theta} = \\\\frac{dQ_\\\\phi}{d\\\\mu} \\\\frac{d\\\\mu}{d\\\\theta}$.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"  rng, $\\\\mu_\\\\theta(s)$ l mt Deterministic Policy, chnh v vy phng php ny gi l Deep Deterministic Policy Gradient.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Thut ton DDPG nh sau:\")]),_vm._v(\" \"),_vm._m(33),_vm._v(\" \"),_vm._m(34),_vm._v(\" \"),_c('h1',[_vm._v(\"10 - Kt bi\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Nh vy, chng ta  di qua phn c bn t thut ton Policy Gradient n DQN v DDPG.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"Tm gn:\")]),_vm._v(\" \"),_vm._m(35)])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Reinforcement Learning hay hc cng c/tng cng, l lnh vc lin quan\\nn vic dy cho my \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"agent\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" thc hin tt mt nhim v \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"task\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" bng cch\\ntng tc vi mi trng \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"environment\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" thng qua hnh ng \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"action\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" v\\nnhn c phn thng \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"reward\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\". Cch hc ny rt ging vi cch con ngi\\nhc t mi trng bng cch th sai. Ly v d 1 a vo ma ng n gn\\nla th thy m, a tr s c xu hng n gn la nhiu hn\\n\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"v nhn c phn thng l m p\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\",\\nnhng chm vo la th nng, a tr s c xu hng trnh chm vo la \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"v\\nb bng tay\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\".\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Trong v d trn, phn thng xut hin ngay, vic iu chnh hnh ng l\\ntng i d. Tuy nhin, trong cc tnh hung phc tp hn khi m phn thng\\n xa trong tng lai, iu ny tr nn phc tp hn. Lm sao  t c tng\\nphn thng cao nht trong sut c qu trnh? Reinforcement Learning \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"RL\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" l\\ncc thut ton  gii bi ton ti u ny.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_c('em',[_vm._v(\"Environment\")]),_vm._v(\" \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"mi trng\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\": l khng gian m my tng tc.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Agent\")]),_vm._v(\" \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"my\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\": my quan st mi trng v sinh ra hnh ng tng ng.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Policy\")]),_vm._v(\" \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"chin thut\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\": my s theo chin thut nh th no  t c mc ch.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Reward\")]),_vm._v(\" \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"phn thng\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\": phn thng tng ng t mi trng m my nhn c khi thc hin mt hnh ng.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"State\")]),_vm._v(\" \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"trng thi\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\": trng thi ca mi trng m my nhn c.\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Episode\")]),_vm._v(\" \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"tp\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\": mt chui cc trng thi v hnh ng cho n trng thi kt thc $s_1,a_1,s_2,a_2,...s_T, a_T$\")]),_vm._v(\" \"),_c('li',[_c('em',[_vm._v(\"Accumulative Reward\")]),_vm._v(\" \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"phn thng tch ly\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\": tng phn thng tch ly t 1 state n state cui cng.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{attrs:{\"src\":\"https://i.imgur.com/nIUdsIm.jpg\",\"align\":\"center\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Hnh 1: Vng lp tng tc gia agent v environment.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Xem v d di y t openAI Gym, environment c tn\\n\"),_c('a',{attrs:{\"href\":\"https://github.com/openai/gym/wiki/MountainCarContinuous-v0\"}},[_vm._v(\"MountaincontinuousCar-v0\")]),_vm._v(\".\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{staticStyle:{\"padding-bottom\":\"0.5em\"},attrs:{\"src\":\"https://i.imgur.com/yGWmDei.jpg\",\"alt\":\"MountaincontinuousCar-v0\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Hnh 2: Mt hnh nh t MountaincontinuousCar-v0.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{attrs:{\"src\":\"https://laptrinhcuocsong.com/images/game-hung-trung.png\",\"align\":\"center\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Hnh 3: Tr chi Hng Trng.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Trong game Hng Trng, gi s ta c 3 action: qua tri, qua phi, ng yn.\\nTng ng vi state $s$ hin ti \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"v tr ca thng hng, v tr ca trng ri so vi thng,\\ntc  ca bia ri...\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" ta s c 1 phn b xc sut ca 3 action tng ng,\\nv d $[0.1, 0.3, 0.5]$. Tng xc sut ca tt c cc hnh ng ti state $s$ bng $1$, ta c: $\\\\sum_{a}\\\\pi_\\\\theta(a|s) = 1$.\\nGi $p(s_{t+1}|a_t, s_t)$ l hm phn b xc sut ca state tip theo khi agent ti state $s$ v thc hin action $a$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_c('strong',[_vm._v(\"Mc tiu ca reinforcement learning l tm $\\\\theta$ sao cho:\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"T cng thc ta c th thy $\\\\theta^*$ l b tham s sao cho expectation ca accumulative reward t rt\\nnhiu cc mu $\\\\tau$ khc nhau c c t vic thc thi theo policy $\\\\pi_\\\\theta$ l ln nht.\"),_c('br'),_vm._v(\"\\nSau khi tri qua $N$ episodes khc nhau ta thu c $N$ mu $\\\\tau$ khc nhau. Hm s mc tiu ca bi ton lc ny:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$J(\\\\theta)$ chnh l trung bnh cng ca accumulative reward ca episodes khc nhau.\"),_c('br'),_vm._v(\"\\nChng ta cng c th biu din $J(\\\\theta)$ theo phn b ca xc sut phn b $p_\\\\theta(\\\\tau)$ nh sau:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\sum_t r(a_t, s_t)\\\\bigg] \\\\\\\\\\n&=& \\\\int \\\\nabla_\\\\theta p_\\\\theta(\\\\tau) r(\\\\tau) dr\\n\\\\end{eqnarray}\\n$$\\nM chng ta li c:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta p_\\\\theta(\\\\tau) &=&  p_\\\\theta(\\\\tau) \\\\frac{\\\\nabla_\\\\theta p_\\\\theta(\\\\tau)} {p_\\\\theta(\\\\tau)} \\\\\\\\\\n&=& p_\\\\theta(\\\\tau)\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau)\\n\\\\end{eqnarray}\\n$$\\n\"),_c('strong',[_vm._v(\"Lu \")]),_vm._v(\" trick ny rt thng xuyn c s dng, do :\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) &=& \\\\int p_\\\\theta(\\\\tau) \\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) r(\\\\tau) dr \\\\\\\\\\n&=& E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau)}\\\\bigg[\\\\nabla_\\\\theta \\\\log p_\\\\theta(\\\\tau) r(\\\\tau)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Ly 1 tp N chui {$\\\\tau^i$} da theo policy $\\\\pi_\\\\theta$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Tnh gradient: $\\\\nabla_\\\\theta J(\\\\theta) = \\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\bigg(\\\\sum_{t=1}^{t=T}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(a_{i,t}|s_{i,t})\\\\bigg)\\\\bigg(\\\\sum_{t=1}^{t=T} r(a_{i,t}, s_{i,t})\\\\bigg) $\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Update $\\\\theta \\\\leftarrow \\\\theta + \\\\nabla_\\\\theta J(\\\\theta)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) = \\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\nabla_\\\\theta \\\\log \\\\pi_\\\\theta(\\\\tau_i)r(\\\\tau_i)\\n\\\\end{eqnarray}\\n$$\\ny chnh l maximum likelihood estimation \"),_c('a',{attrs:{\"href\":\"https://vi.wikipedia.org/wiki/H%E1%BB%A3p_l%C3%BD_c%E1%BB%B1c_%C4%91%E1%BA%A1i\"}},[_vm._v(\"MLE\")]),_vm._v(\" tch vi accumulative reward.\\nVic ti u hm mc tiu cng ng ngha vi vic tng xc sut  i theo chui $\\\\tau$ cho accumulative reward cao.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$V^\\\\pi(s)$: accumulative reward mong i ti state $s$ nu i theo policy $\\\\pi$.\"),_c('br'),_vm._v(\"\\n$Q^\\\\pi(s,a)$: accumulative reward mong i nu thc hin action $a$ ti state $s$ nu i theo policy $\\\\pi$.\"),_c('br'),_vm._v(\"\\nQuan h gia $V^\\\\pi(s)$ v $Q^\\\\pi(s,a)$: $V^\\\\pi(s) = \\\\sum_{a \\\\in A}\\\\pi_\\\\theta(s,a)Q^\\\\pi(s,a)$ - iu ny l hp l v $\\\\pi_\\\\theta(s,a)$ l xc sut thc hin action $a$ ti $s$.\"),_c('br'),_vm._v(\"\\nTa cng c nh sau:\\n$$\\n\\\\begin{eqnarray}\\nV^\\\\pi(s_t) &=& E_\\\\pi[G_t | S=s_t] \\\\\\\\\\nQ^\\\\pi(s_t,a_t) &=& E_\\\\pi[G_t|S=s_t, A=a_t]\\n\\\\end{eqnarray}\\n$$\\nTrong :\"),_c('br'),_vm._v(\"\\n$G_t=\\\\sum^{\\\\infty}_{k=0}\\\\gamma^kR_{k+t+1}$: tng tt c cc reward nhn c k t state $s_t$ n tng lai, vi i lng $\\\\gamma$ gi l discount factor: $0 < \\\\gamma < 1$. Cng xa hin ti, reward cng b discount nhiu, agent quan tm nhiu hn n reward  gn hn l  xa.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('h1',[_vm._v(\"5 - Advantage \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"li th\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)Q^\\\\pi(s,a)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\\nGradient ca hm mc tiu cho thy vic tng kh nng thc hin action $a$ nu nhn c $Q^\\\\pi(s,a)$ cao. Gi s agent  ti state $s$, vic  ti state $s$ l  c li cho agent ri, thc hin action $a$ no cng cho ra gi tr $Q^\\\\pi(s,a)$ cao th ta khng th phn tch \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"discriminate\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" cc action $a$ vi nhau v t  khng bit c action $a$ no l ti u. Do  ta cn c 1 baseline  so snh cc gi tr $Q^\\\\pi(s,a)$.\"),_c('br'),_vm._v(\"\\nNh trong phn 4, ta c $V^\\\\pi(s)$ l expectation ca accumulative reward ti state $s$, khng quan trng ti $s$ agent thc hin action g, chng ta mong i 1 accumulative reward l $V^\\\\pi(s)$.\\nDo , 1 action $a_m$ c nh gi l t nu nh $Q^\\\\pi(s,a_m)$ < $V^\\\\pi(s)$ v 1 action $a_n$ c nh gi l tt nu nh $Q^\\\\pi(s,a_n)$ > $V^\\\\pi(s)$. T y ta c c 1 baseline  so snh $Q^\\\\pi(s,a)$  l $V^\\\\pi(s)$. Gradient ca objective function by gi c th vit li c nh sau:\\n$$\\n\\\\begin{eqnarray}\\n\\\\nabla_\\\\theta J(\\\\theta) =  E_{\\\\tau\\\\sim p_\\\\theta(\\\\tau), a\\\\sim\\\\pi_\\\\theta}\\\\bigg[\\\\nabla_\\\\theta \\\\log\\\\pi_\\\\theta(a|s)\\\\Big(Q^\\\\pi(s,a)-V^\\\\pi(s)\\\\Big)\\\\bigg]\\n\\\\end{eqnarray}\\n$$\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Nu $Q^\\\\pi(s,a)-V^\\\\pi(s) < 0$, 2 gradient ngc du vi nhau, ti u hm mc tiu s lm gim gradient ca vic thc thi hnh ng $a$ ti $s$.\"),_c('br'),_vm._v(\"\\nTa gi $A^\\\\pi(s,a)=Q^\\\\pi(s,a)-V^\\\\pi(s)$ l Advantage ca action $a$ ti state $s$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Stochastic Actor \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"ngu nhin Actor\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\"  ch policy $\\\\pi_\\\\theta(a|s)$ l mt hm phn phi xc sut ca action $a$ ti $s$. Ta gi Stochastic Actor  phn bit vi Deterministic Actor \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"hay Deterministic Policy\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" mang  ch policy khng cn l mt hm phn phi xc sut ca cc action $a$ ti $s$, m di $s$ ta ch thc hin chnh xc mt action nht nh m thi $a=\\\\mu_\\\\theta(s)$, hay ni cch khc xc sut thc hin $a$ ti $s$ by gi l 1.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Hm mc tiu ph thuc vo 2 th: policy $\\\\pi_\\\\theta$ v value function $V^\\\\pi$. Gi s ta c mt hm xp x cho $V^\\\\pi(s)$ l $V_\\\\phi(s)$ ph thuc vo b tham s $\\\\phi$.\"),_c('br'),_vm._v(\"\\nTa gi hm xp x cho policy $\\\\pi_\\\\theta$ l Actor v hm xp x cho value function $V_\\\\phi$ l Critic.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Batch Actor-Critic:\"),_c('br'),_vm._v(\"\\n1. Ly 1 chui $\\\\tau$ n terminal state da theo policy $\\\\pi_\\\\theta$\"),_c('br'),_vm._v(\"\\n2. Fit $V_\\\\phi$ vi $y = \\\\sum_{i}^{T} r_i$\"),_c('br'),_vm._v(\"\\n3. Tnh $A(s_t,a_t) = r(s_t, a_t) + \\\\gamma V_\\\\phi(s_{t+1}) - V_\\\\phi(s_{t})$\"),_c('br'),_vm._v(\"\\n4. Tnh $\\\\nabla_\\\\theta J(\\\\theta) = \\\\sum_i \\\\nabla \\\\log \\\\pi_\\\\theta (a_i|s_i) A^\\\\pi (s_i, a_i)$\"),_c('br'),_vm._v(\"\\n5. Update $\\\\theta \\\\leftarrow \\\\theta  + \\\\alpha \\\\nabla_\\\\theta J(\\\\theta)$\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nM ta c  trn, ta c th biu din $V_\\\\phi(s) = r + V_\\\\phi(s')$ theo Bellman Equation, do  ta c th update model m ch cn 1 step v pha trc.\"),_c('br'),_vm._v(\"\\nOnline Actor-Critic:\"),_c('br'),_vm._v(\"\\n1. Da theo policy $\\\\pi_\\\\theta$, thc hin 1 action $a \\\\sim \\\\pi_\\\\theta(a|s)$  c $(s,a,s',r)$\"),_c('br'),_vm._v(\"\\n2. Fit $V_\\\\phi (s)$ vi $r + V_\\\\phi(s')$\"),_c('br'),_vm._v(\"\\n3. Tnh $A(s_t,a_t) = r(s_t, a_t) + \\\\gamma V_\\\\phi(s_{t+1}) - V_\\\\phi(s_{t})$\"),_c('br'),_vm._v(\"\\n4. Tnh $\\\\nabla_\\\\theta J(\\\\theta) = \\\\sum_i \\\\nabla \\\\log \\\\pi_\\\\theta (a_i|s_i) A (s_i, a_i)$\"),_c('br'),_vm._v(\"\\n5. Update $\\\\theta \\\\leftarrow \\\\theta  + \\\\alpha \\\\nabla_\\\\theta J(\\\\theta)$\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nNh vy, chng ta cng lc update c 2 hm xp x $V_\\\\phi$ v $\\\\pi_\\\\theta$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Xt mt policy nh sau:\\n$$\\n\\\\begin{eqnarray}\\n\\\\pi'(a_t|s_t) = 1 \\\\ \\\\text{if}\\\\  a_t = \\\\arg \\\\max_{a_t} A^\\\\pi(s_t, a_t)\\n\\\\end{eqnarray}\\n$$\\nPolicy $\\\\pi'$ ny l mt Deterministic Policy: cho trc mt policy $\\\\pi$ v gi s ta bit c Advantage ca cc action ti state $s_t$ di policy $\\\\pi$, ta lun chn action cho ra gi tr Advantage ln nht ti state $s_t$ , probability ca action  l 1, tt c cc action khc ti $s_t$ bng 0.\\nPolicy $\\\\pi'$ s lun tt hn hoc t nht l tng ng vi policy $\\\\pi$. Mt policy c nh gi l tng ng hay tt hn khi ta c:\\n$V^\\\\pi(s) \\\\leq V^{\\\\pi'} (s) \\\\forall s \\\\in S$ : vi mi state $s$ trong min state $S$, gi tr return  $V^\\\\pi(s)$ lun nh hn hoc bng gi tr return $V^{\\\\pi'} (s)$.\"),_c('br'),_vm._v(\"\\nV d ta c nh sau: ti state $s$, ta c 4 cch i sang state $s'$ ng vi 4 action v ng vi $A^\\\\pi_1$, $A^\\\\pi_2$, $A^\\\\pi_3$, $A^\\\\pi_4$. K t state $s'$, ta li i theo policy $\\\\pi$. T $s$ sang $s'$, nu chn action theo stochastic policy $\\\\pi$, Expected Advantage l $\\\\sum_{a \\\\in A} p(a)A^\\\\pi_a$, lng ny chc chn nh hn $\\\\max_a A^\\\\pi_a$.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticStyle:{\"width\":\"image width px\",\"font-size\":\"80%\",\"text-align\":\"center\"}},[_c('img',{attrs:{\"src\":\"https://i.imgur.com/yMtTahR.jpg\",\"align\":\"center\"}}),_vm._v(\" \"),_c('div',[_vm._v(\"Hnh 4: Thay i t trng thi $s$ sang $s'$.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"M nh gi $A^\\\\pi(s,a)$ th cng tng ng nh gi $Q^\\\\pi(s,a)$ v $A^\\\\pi(s,a) =  Q^\\\\pi(s,a) - V^\\\\pi(s) = r(s,a)  + \\\\gamma V^\\\\pi(s') - V^\\\\pi(s)$, m lng $V^\\\\pi(s)$ th li khng i gia cc action $a$ ti state $s$.\"),_c('br'),_vm._v(\"\\nNh vy, thut ton tr thnh:\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"nh gi $Q^\\\\pi(s,a) \\\\leftarrow r(s,a)  + \\\\gamma V^\\\\pi(s') $ vi cc action $a$ khc nhau\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Ti u $\\\\pi \\\\leftarrow \\\\pi'$ : chn ra action cho $A$ cao nht, hay cng chnh l $Q$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"nh gi $Q^\\\\pi(s,a) \\\\leftarrow r(s,a)  + \\\\gamma V^\\\\pi(s') $ vi cc action $a$ khc nhau\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$V^\\\\pi(s) \\\\leftarrow \\\\max_a Q^\\\\pi(s,a)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"nh gi $V^\\\\pi(s) \\\\leftarrow \\\\max_a \\\\big(r(s,a)  + \\\\gamma V^\\\\pi(s')\\\\big)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\arg min_\\\\phi \\\\big(V^\\\\pi(s) - V_\\\\phi(s)\\\\big)^2$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"nh gi $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma \\\\max_{a'} Q_\\\\phi(s', a') $\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\arg min_\\\\phi \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)^2$ $(*)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Thc hin action $a$  c $(s, a, s', r)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"nh gi $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma max_{a'} Q_\\\\phi(s', a') $\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\phi - \\\\alpha \\\\frac{dQ_\\\\phi}{d\\\\phi}(s,a) \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)$\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Cc bn   bc 3,  c phi l gradient descent nh  trn ch mnh nh du $(*)$ khng? Khng, thc ra chng ta  l i phn thay i ca $y_i$ theo $\\\\phi$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"$y_i$ cng ph thuc vo $\\\\phi$\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\". Nh vy, mi khi update $\\\\phi$ theo thut ton ny, th gi tr ca mc tiu $y_i$ cng b thay i theo! Mc tiu lun thay i khi ta c gng tin gn li n, iu ny lm cho thut ton tr nn khng n nh.\"),_c('br'),_vm._v(\"\\n gii quyt iu ny, ta cn mt hm xp x khc gi l target network, khc vi train network chng ta vn chy. Target network s c gi c nh  tnh $y$ v update dn dn.\"),_c('br'),_vm._v(\"\\nMt vn  khc l cc sample sinh ra lin tc nn n rt lin quan \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"correlation\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" vi nhau. Thut ton trn cng ging nh Supervised Learning - ta map Q-value vi gi tr mc tiu, ta mun cc sample l c lp \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"i.i.d\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" vi nhau.  ph v correlation gia cc sample, ta c th dng 1 experience buffer: 1 list cha rt nhiu sample $(s,a,r,s')$ khc nhau, v ta chn ngu nhin 1 batch t buffer  train thut ton.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_vm._v(\"Hm target network ring bit, gi  l $Q_{\\\\phi'}$.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Experience buffer.\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Thc hin action $a_i$  c $(s_i, a_i, s_i', r_i)$ v b n vo buffer.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Ly ngu nhin 1 batch $N$ sample t buffer $(s_i, a_i, s_i', r_i)$.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"nh gi $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma max_{a'} Q_{\\\\phi'}(s', a')$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"dng target network  y\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")])]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\phi - \\\\alpha \\\\frac{1}{N}\\\\sum_i^N \\\\frac{dQ_\\\\phi}{d\\\\phi}(s,a_i) \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Update target network $\\\\phi' \\\\leftarrow (1-\\\\tau)\\\\phi' + \\\\tau \\\\phi$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"s dng $\\\\tau %$ ca train network mi  update target network\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" \"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nThut ton ny chnh l Deep Q-Network \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"DQN\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\".\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Deep Deterministic Policy Gradient \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"DDPG\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" c mt cch tip cn tinh t nh sau,   rng:\\n$$\\n\\\\begin{eqnarray}\\nmax_{a} Q_{\\\\phi}(s, a) = Q_\\\\phi\\\\big(s, \\\\arg max_a Q_\\\\phi(s,a)\\\\big)\\n\\\\end{eqnarray}\\n$$\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ol',[_c('li',[_vm._v(\"Thc hin action $a_i$  c $(s_i, a_i, s_i', r_i)$ v b n vo buffer.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Ly ngu nhin 1 batch $N$ sample t buffer $(s_i, a_i, s_i', r_i)$.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"nh gi $y_i \\\\leftarrow r(s,a_i)  + \\\\gamma Q_{\\\\phi'}\\\\big(s', \\\\mu_{\\\\theta'}(s')\\\\big)$ \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"dng c policy v Q target network  y\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")])]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\phi \\\\leftarrow \\\\phi - \\\\alpha \\\\frac{1}{N}\\\\sum_i^N \\\\frac{dQ_\\\\phi}{d\\\\phi}(s,a_i) \\\\big(Q_\\\\phi(s, a_i) - y_i\\\\big)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"$\\\\theta \\\\leftarrow \\\\theta - \\\\beta \\\\frac{1}{N}\\\\sum_i^N \\\\frac{d\\\\mu_\\\\theta}{d\\\\theta}(s) \\\\frac{dQ_\\\\phi}{da}(s, a_i)$\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Update target network $\\\\phi' \\\\leftarrow (1-\\\\tau)\\\\phi' + \\\\tau \\\\phi$ v $\\\\theta' \\\\leftarrow (1-\\\\tau)\\\\theta' + \\\\tau \\\\theta$\\n\"),_c('br'),_vm._v(\" \"),_c('br'),_vm._v(\"\\nLu  trong implement DDPG:\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_vm._v(\"V action trong DDPG lun l deterministic, do   c th khm ph mi trng \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"ta khng mun agent lun khai khc ch 1 ng i tt nht trong nhng ng i m n bit, c th c ng i khc tt hn m n cha bit\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\", chng ta s thm vo action mt lng noise nh vo action.\\nLng noise ny trong \"),_c('a',{attrs:{\"href\":\"https://arxiv.org/abs/1509.02971\"}},[_vm._v(\"bi bo gc\")]),_vm._v(\" l mt stochastic process c tn OrnsteinUhlenbeck process \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\"OU process\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\".\\nNgi vit chn process ny v khi lm th nghim cho kt qu tt, tuy nhin mt vi th nghim khc s dng nhng noise khc nh l 1\\nGaussian Noise th cng cho kt qu tng ng.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Implementation ca action noise trong cc th vin nh \"),_c('a',{attrs:{\"href\":\"https://github.com/keras-rl/keras-rl\"}},[_vm._v(\"keras-rl\")]),_vm._v(\" l OU process, tuy nhin khi chy th th noise ny khng decay theo thi gian. M chng ta cn noise ln lc ban u \"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\"(\")]),_vm._v(\" khm ph mi trng nhiu\"),_c('span',{staticClass:\"tex2jax_ignore\"},[_vm._v(\")\")]),_vm._v(\" sau  gim dn khi  tri qua nhiu episode.\\nVic ny c th thc hin nu trc khi thm noise vo action, ta nhn n vi mt lng epsilon, m epsilon gim v xp x 0 theo thi gian.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Ngoi vic thm noise vo action trc khi thc hin n trn environment, ngi ta cn c th thm Gaussian Noise vo cc nt mng trong actor network.\\nBi bo reference \"),_c('a',{attrs:{\"href\":\"https://openai.com/blog/better-exploration-with-parameter-noise/\"}},[_vm._v(\"ti y\")]),_vm._v(\". Bn c c th tm thy implementation ca actor network noise ti th vin \"),_c('a',{attrs:{\"href\":\"https://stable-baselines.readthedocs.io/en/master/modules/ddpg.html#action-and-parameters-noise\"}},[_vm._v(\"stable baselines\")]),_vm._v(\".\")])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('ul',[_c('li',[_vm._v(\"Policy Gradient l mt thut ton on-policy v l mt stochastic policy.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Q-learning, DQN, DDPG l cc thut ton off-policy v l deterministic policy.\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Lun c mt deterministic policy tt hn mt stochastic policy hin c.\")])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-6c6d8ace\",\"hasScoped\":false,\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/vi/theoricalRL/Vi1DDPG.md\n// module id = null\n// module chunks = ","var normalizeComponent = require(\"!../../../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-6c6d8ace\\\",\\\"hasScoped\\\":false,\\\"buble\\\":{\\\"transforms\\\":{}}}!../../../../node_modules/vue-loader/lib/selector?type=template&index=0!../../../../node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./Vi1DDPG.md\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = null\n/* scopeId */\nvar __vue_scopeId__ = null\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader!./node_modules/vue-markdown-loader/lib/markdown-compiler.js?raw!./src/pages/vi/theoricalRL/Vi1DDPG.md\n// module id = null\n// module chunks = "],"sourceRoot":""}